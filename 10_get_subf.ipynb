{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_cols = ['cplfw_rank', 'market1501_rank', 'dukemtmc_rank', 'msmt17_rank', 'veri_rank', 'vehicleid_rank', 'veriwild_rank', 'sop_rank']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/CVPR_2022_NAS_Track2_test.json', 'r') as f:\n",
    "    test_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df(train_data):\n",
    "    ret = []\n",
    "    for k, v in train_data.items():\n",
    "        tmp = list(v['arch'])\n",
    "        tmp1 = []\n",
    "        for c in target_cols:\n",
    "            tmp1.append(v[c])\n",
    "        ret.append(tmp+tmp1+[k])\n",
    "    retf = pd.DataFrame(ret,columns=[f'col{_}' for _ in range(len(tmp))]+target_cols+['id'])\n",
    "    retf['col0'] = retf['col0'].map({'l':1, 'j':2, 'k':3})\n",
    "    int_cols = [x for x in retf.columns if x not in ['id']]\n",
    "    retf[int_cols] = retf[int_cols].astype(float)\n",
    "    return retf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lgb \n",
    "# 0.7917\t0.30304\t0.88216\t0.89852\t0.96327\t0.89229\t0.66823\t0.91991\t0.80477\n",
    "with open('./sub/CVPR_2022_lgb_score.json', 'r') as f:\n",
    "    test_data_7917 = json.load(f)\n",
    "test_data_7917 = get_df(test_data_7917)\n",
    "\n",
    "# pp super lr\n",
    "# 0.79251\t0.30632\t0.88203\t0.89841\t0.96363\t0.89552\t0.66735\t0.92054\t0.80633\n",
    "with open('./sub/CVPR_2022_paddle_superliner_score.json', 'r') as f:\n",
    "    test_data_79251 = json.load(f)\n",
    "test_data_79251 = get_df(test_data_79251)\n",
    "\n",
    "# nn MLP+lstm2y+MLP 加权层，bc400,001lr\n",
    "# 0.79253\t0.29919\t0.8823\t0.89703\t0.96335\t0.89861\t0.6753\t0.92263\t0.80182\n",
    "with open('./sub/CVPR_2022_torch_ohe_2lstm_4logits_weight_kednall_tanh1.json', 'r') as f:\n",
    "    test_data_79253 = json.load(f)\n",
    "test_data_79253 = get_df(test_data_79253)\n",
    "\n",
    "# nn MLP+transformer decoder encoder\n",
    "# 0.79282\t0.32\t0.87896\t0.89657\t0.96108\t0.89295\t0.66939\t0.92099\t0.8026\n",
    "with open('./sub/CVPR_2022_transformer_encoder_decoder_tanh.json', 'r') as f:\n",
    "    test_data_79282 = json.load(f)\n",
    "test_data_79282 = get_df(test_data_79282)\n",
    "\n",
    "# nn lstm2y_bc400_lr001_20220512.json\n",
    "# 0.79351\t0.30797\t0.88162\t0.89854\t0.96421\t0.89542\t0.67249\t0.92281\t0.80505\n",
    "with open('./sub/CVPR_2022_lstm2y_catall_tanh.json', 'r') as f:\n",
    "    test_data_79351 = json.load(f)\n",
    "test_data_79351 = get_df(test_data_79351)\n",
    "\n",
    "# nn 7937 target 8 best tanh\n",
    "# 0.79353\t0.29968\t0.88367\t0.89992\t0.96528\t0.89853\t0.67058\t0.92237\t0.80825\n",
    "with open('./sub/CVPR_2022_lstm2y_catall_tanh_sig.json', 'r') as f:\n",
    "    test_data_79353 = json.load(f)\n",
    "test_data_79353 = get_df(test_data_79353)\n",
    "\n",
    "#nn 79066 8target 同步建模，取sig best\n",
    "# 0.79395\t0.29616\t0.88538\t0.90162\t0.96621\t0.9011\t0.67295\t0.92239\t0.80579\t已完成\t2022/5/14 16:45\n",
    "with open('./sub/CVPR_2022_lstm2y_catall_pair_sig.json', 'r') as f:\n",
    "    test_data_79395 = json.load(f)\n",
    "test_data_79395 = get_df(test_data_79395)\n",
    "\n",
    "# nn 79395 取tanh1\n",
    "# 0.79414\t0.31042\t0.88253\t0.89818\t0.96561\t0.89796\t0.67172\t0.92211\t0.80456\t已完成\t2022/5/14 19:51\n",
    "with open('./sub/CVPR_2022_lstm2y_catall_tanh1_sig.json', 'r') as f:\n",
    "    test_data_79414 = json.load(f)\n",
    "test_data_79414 = get_df(test_data_79414)\n",
    "\n",
    "# nn 79414 ohe step 37*93, lstm2y稠密_bc400_lr001_tanh1_ohe_20220515\n",
    "# 0.79455\t0.31011\t0.8841\t0.89642\t0.96365\t0.90124\t0.67184\t0.92352\t0.80555\t已完成\t2022/5/15 16:49\n",
    "with open('./sub/CVPR_2022_ohe_lstm2y_catall_tanh1_sig.json', 'r') as f:\n",
    "    test_data_79455 = json.load(f)\n",
    "test_data_79455 = get_df(test_data_79455)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = pd.merge(test_data_7917[['id']+target_cols].rename(columns={x:x+'_7917' for x in target_cols}),\n",
    "               test_data_79251[['id']+target_cols].rename(columns={x:x+'_79251' for x in target_cols}),\n",
    "               on='id')\n",
    "out = pd.merge(out,\n",
    "               test_data_79253[['id']+target_cols].rename(columns={x:x+'_79253' for x in target_cols}),\n",
    "               on='id')\n",
    "out = pd.merge(out,\n",
    "               test_data_79282[['id']+target_cols].rename(columns={x:x+'_79282' for x in target_cols}),\n",
    "               on='id')\n",
    "out = pd.merge(out,\n",
    "               test_data_79351[['id']+target_cols].rename(columns={x:x+'_79351' for x in target_cols}),\n",
    "               on='id')\n",
    "out = pd.merge(out,\n",
    "               test_data_79353[['id']+target_cols].rename(columns={x:x+'_79353' for x in target_cols}),\n",
    "               on='id')\n",
    "out = pd.merge(out,\n",
    "               test_data_79395[['id']+target_cols].rename(columns={x:x+'_79395' for x in target_cols}),\n",
    "               on='id')\n",
    "out = pd.merge(out,\n",
    "               test_data_79414[['id']+target_cols].rename(columns={x:x+'_79414' for x in target_cols}),\n",
    "               on='id')\n",
    "out = pd.merge(out,\n",
    "               test_data_79455[['id']+target_cols].rename(columns={x:x+'_79455' for x in target_cols}),\n",
    "               on='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for y_ in target_cols:\n",
    "    if y_ == target_cols[0]:\n",
    "        out[y_] = (out[f'{y_}_79282']).rank().astype(int)-1\n",
    "    elif y_ == target_cols[1]:\n",
    "        out[y_] = (out[f'{y_}_79395']*0.8+out[f'{y_}_79455']*0.05 + out[f'{y_}_79353']*0.05 + out[f'{y_}_79414']*0.05 + out[f'{y_}_7917']*0.05).rank().astype(int)-1\n",
    "    elif y_ == target_cols[2]:\n",
    "        out[y_] = (out[f'{y_}_79395']*1).rank().astype(int)-1\n",
    "    elif y_ == target_cols[3]:\n",
    "        out[y_] = (out[f'{y_}_79395']*0.8+out[f'{y_}_79353']*0.05 + out[f'{y_}_79414']*0.05 + out[f'{y_}_79251']*0.05 + out[f'{y_}_79351']*0.05).rank().astype(int)-1\n",
    "    elif y_ == target_cols[4]:\n",
    "        out[y_] = (out[f'{y_}_79455']*0.45+out[f'{y_}_79353']*0.02 + out[f'{y_}_79414']*0.02 + out[f'{y_}_79395']*0.45 + out[f'{y_}_79253']*0.02).rank().astype(int)-1\n",
    "    elif y_ == target_cols[5]:\n",
    "        out[y_] = (out[f'{y_}_79253']*1).rank().astype(int)-1\n",
    "    elif y_ == target_cols[6]:\n",
    "        out[y_] = (out[f'{y_}_79351']*0.1+out[f'{y_}_79455']*0.6 + out[f'{y_}_79353']*0.1 + out[f'{y_}_79414']*0.1 + out[f'{y_}_79253']*0.1).rank().astype(int)-1\n",
    "    elif y_ == target_cols[7]:\n",
    "        out[y_] = (out[f'{y_}_79455']*0.05+out[f'{y_}_79353']*0.7 + out[f'{y_}_79395']*0.05 + out[f'{y_}_79251']*0.2).rank().astype(int)-1\n",
    "    else:\n",
    "        print('error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\45928\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b5273fb46d445aa829678a0602f8cd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/99500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def to_sub(test_df, test_data, name='CVPR_2022_lgb_base_log1p_grid'):\n",
    "    for i in tqdm(test_df[['id']+target_cols].values):\n",
    "        id_ = i[0]\n",
    "        for k,v in enumerate(target_cols):\n",
    "            k += 1\n",
    "            test_data[id_][v] = i[k]\n",
    "            \n",
    "    with open(f'./sub/{name}.json', 'w') as f:\n",
    "        json.dump(test_data, f)\n",
    "\n",
    "#第一个提交，对应a榜 0.79806，第一个提交对较强的模型有很高的权重\n",
    "to_sub(out, test_data, name='sub0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for y_ in target_cols:\n",
    "    if y_ == target_cols[0]:\n",
    "        out[y_] = (out[f'{y_}_7917']*0.1+out[f'{y_}_79251']*0.1+out[f'{y_}_79253']*0.03+\\\n",
    "                   out[f'{y_}_79282']*0.4+out[f'{y_}_79351']*0.1+out[f'{y_}_79353']*0.03+\\\n",
    "                   out[f'{y_}_79395']*0.03+out[f'{y_}_79414']*0.1+out[f'{y_}_79455']*0.1).rank().astype(int)-1\n",
    "    elif y_ == target_cols[1]:\n",
    "        out[y_] = (out[f'{y_}_7917']*0.1+out[f'{y_}_79251']*0.1+out[f'{y_}_79253']*0.08+\\\n",
    "                   out[f'{y_}_79282']*0+out[f'{y_}_79351']*0.08+out[f'{y_}_79353']*0.08+\\\n",
    "                   out[f'{y_}_79395']*0.4+out[f'{y_}_79414']*0.08+out[f'{y_}_79455']*0.08).rank().astype(int)-1\n",
    "    elif y_ == target_cols[2]:\n",
    "        out[y_] = (out[f'{y_}_7917']*0.1+out[f'{y_}_79251']*0.1+out[f'{y_}_79253']*0.08+\\\n",
    "                   out[f'{y_}_79282']*0+out[f'{y_}_79351']*0.08+out[f'{y_}_79353']*0.08+\\\n",
    "                   out[f'{y_}_79395']*0.4+out[f'{y_}_79414']*0.08+out[f'{y_}_79455']*0.08).rank().astype(int)-1\n",
    "    elif y_ == target_cols[3]:\n",
    "        out[y_] = (out[f'{y_}_7917']*0.1+out[f'{y_}_79251']*0.1+out[f'{y_}_79253']*0.08+\\\n",
    "                   out[f'{y_}_79282']*0+out[f'{y_}_79351']*0.08+out[f'{y_}_79353']*0.08+\\\n",
    "                   out[f'{y_}_79395']*0.4+out[f'{y_}_79414']*0.08+out[f'{y_}_79455']*0.08).rank().astype(int)-1\n",
    "    elif y_ == target_cols[4]:\n",
    "        out[y_] = (out[f'{y_}_7917']*0.1+out[f'{y_}_79251']*0.1+out[f'{y_}_79253']*0.08+\\\n",
    "                   out[f'{y_}_79282']*0+out[f'{y_}_79351']*0.08+out[f'{y_}_79353']*0.08+\\\n",
    "                   out[f'{y_}_79395']*0.08+out[f'{y_}_79414']*0.08+out[f'{y_}_79455']*0.4).rank().astype(int)-1\n",
    "        \n",
    "    elif y_ == target_cols[5]:\n",
    "        out[y_] = (out[f'{y_}_7917']*0.1+out[f'{y_}_79251']*0.1+out[f'{y_}_79253']*0.4+\\\n",
    "                   out[f'{y_}_79282']*0+out[f'{y_}_79351']*0.08+out[f'{y_}_79353']*0.08+\\\n",
    "                   out[f'{y_}_79395']*0.08+out[f'{y_}_79414']*0.08+out[f'{y_}_79455']*0.08).rank().astype(int)-1\n",
    "    elif y_ == target_cols[6]:\n",
    "        out[y_] = (out[f'{y_}_7917']*0.1+out[f'{y_}_79251']*0.1+out[f'{y_}_79253']*0.08+\\\n",
    "                   out[f'{y_}_79282']*0+out[f'{y_}_79351']*0.08+out[f'{y_}_79353']*0.08+\\\n",
    "                   out[f'{y_}_79395']*0.08+out[f'{y_}_79414']*0.08+out[f'{y_}_79455']*0.4).rank().astype(int)-1\n",
    "    elif y_ == target_cols[7]:\n",
    "        out[y_] = (out[f'{y_}_7917']*0.1+out[f'{y_}_79251']*0.1+out[f'{y_}_79253']*0.08+\\\n",
    "                   out[f'{y_}_79282']*0+out[f'{y_}_79351']*0.08+out[f'{y_}_79353']*0.4+\\\n",
    "                   out[f'{y_}_79395']*0.08+out[f'{y_}_79414']*0.08+out[f'{y_}_79455']*0.08).rank().astype(int)-1\n",
    "    else:\n",
    "        print('error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\45928\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0da168b322b4197b13441e73404886e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/99500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 第二个提交，对应a榜 0.79727，第二个提交，强模型，打分模型，nn编码模型分别给4：2：4的权重\n",
    "to_sub(out, test_data, name='sub1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
