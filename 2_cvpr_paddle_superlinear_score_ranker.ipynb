{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\45928\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\socks.py:58: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import Callable\n",
      "C:\\Users\\45928\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\paddle\\vision\\transforms\\functional_pil.py:36: DeprecationWarning: NEAREST is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.NEAREST or Dither.NONE instead.\n",
      "  'nearest': Image.NEAREST,\n",
      "C:\\Users\\45928\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\paddle\\vision\\transforms\\functional_pil.py:37: DeprecationWarning: BILINEAR is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.BILINEAR instead.\n",
      "  'bilinear': Image.BILINEAR,\n",
      "C:\\Users\\45928\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\paddle\\vision\\transforms\\functional_pil.py:38: DeprecationWarning: BICUBIC is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.BICUBIC instead.\n",
      "  'bicubic': Image.BICUBIC,\n",
      "C:\\Users\\45928\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\paddle\\vision\\transforms\\functional_pil.py:39: DeprecationWarning: BOX is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.BOX instead.\n",
      "  'box': Image.BOX,\n",
      "C:\\Users\\45928\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\paddle\\vision\\transforms\\functional_pil.py:40: DeprecationWarning: LANCZOS is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.LANCZOS instead.\n",
      "  'lanczos': Image.LANCZOS,\n",
      "C:\\Users\\45928\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\paddle\\vision\\transforms\\functional_pil.py:41: DeprecationWarning: HAMMING is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.HAMMING instead.\n",
      "  'hamming': Image.HAMMING\n"
     ]
    }
   ],
   "source": [
    "import paddle\n",
    "from paddle import nn\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.special import erfinv \n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load train data\n",
    "with open('./data/CVPR_2022_NAS_Track2_train.json', 'r') as f:\n",
    "    train_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_cols = ['cplfw_rank', 'market1501_rank', 'dukemtmc_rank', 'msmt17_rank', 'veri_rank', 'vehicleid_rank', 'veriwild_rank', 'sop_rank']\n",
    "\n",
    "def get_df(train_data):\n",
    "    ret = []\n",
    "    for k, v in train_data.items():\n",
    "        tmp = list(v['arch'])\n",
    "        tmp1 = []\n",
    "        for c in target_cols:\n",
    "            tmp1.append(v[c])\n",
    "        ret.append(tmp+tmp1+[k,v['arch']])\n",
    "    retf = pd.DataFrame(ret,columns=[f'col{_}' for _ in range(len(tmp))]+target_cols+['id','arch'])\n",
    "    retf['col0'] = retf['col0'].map({'l':1, 'j':2, 'k':3})\n",
    "    int_cols = [x for x in retf.columns if x not in ['id','arch']]\n",
    "    retf[int_cols] = retf[int_cols].astype(float)\n",
    "    return retf\n",
    "\n",
    "train_df = get_df(train_data)\n",
    "\n",
    "base_cols = [x for x in train_df.columns if x[:3]=='col']\n",
    "len(base_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# erfinv trans\n",
    "for c in target_cols:\n",
    "    train_y = train_df[c]\n",
    "    mmin = np.min(train_y)+1\n",
    "    mmax = np.max(train_y)+1\n",
    "    train_y = np.sqrt(2) * erfinv(2 * (train_y+mmin)/(mmin+mmax)-1)\n",
    "    train_df[c+'_trans_y'] = train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_ohe(train_df, use_cols):\n",
    "    for c in use_cols:\n",
    "        for j in sorted(train_df[c].unique()):\n",
    "            train_df[f'ohe_{c}_{int(j)}'] = np.where(train_df[c]==j, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ohe(train_df, base_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(base_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe_cols = [x for x in train_df.columns if 'ohe' in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "93"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ohe_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from tqdm import tqdm\n",
    "\n",
    "#定义数据\n",
    "class MyDataset(paddle.io.Dataset):\n",
    "    def __init__(self, df, use_cols, target_cols, show=0, is_val=0):\n",
    "        self.df = df\n",
    "        self.show = show\n",
    "        self.use_cols = use_cols\n",
    "        self.target_cols = target_cols\n",
    "        self.is_val = is_val\n",
    "\n",
    "        self.prepare_data()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "    \n",
    "    def prepare_data(self):\n",
    "        self.inputs = self.df[self.use_cols].values\n",
    "        if self.is_val==0:\n",
    "            self.y = self.df[self.target_cols].values\n",
    "        \n",
    "        if self.show==1:\n",
    "            print('inputs_shape',self.inputs.shape)\n",
    "            if self.is_val==0:\n",
    "                print('y_shape',self.y.shape)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        if self.is_val==0:\n",
    "            data = {\n",
    "                \"input\": paddle.to_tensor(self.inputs[idx], dtype='float32'),\n",
    "                \"y\": paddle.to_tensor(self.y[idx], dtype='float32'),\n",
    "            }\n",
    "        else:\n",
    "            data = {\n",
    "                \"input\": paddle.to_tensor(self.inputs[idx], dtype='float32')\n",
    "            }\n",
    "        \n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cols = ohe_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "93"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(use_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cplfw_rank_trans_y',\n",
       " 'market1501_rank_trans_y',\n",
       " 'dukemtmc_rank_trans_y',\n",
       " 'msmt17_rank_trans_y',\n",
       " 'veri_rank_trans_y',\n",
       " 'vehicleid_rank_trans_y',\n",
       " 'veriwild_rank_trans_y',\n",
       " 'sop_rank_trans_y']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_cols = [x+'_trans_y' for x in target_cols]\n",
    "target_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import paddle\n",
    "from paddle import nn\n",
    "from paddle.io import DataLoader\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    paddle.seed(seed)\n",
    "    \n",
    "def count_parameters(model, all=False):\n",
    "    if all:\n",
    "        return sum(p.numel() for p in model.parameters())\n",
    "    else:\n",
    "        return sum(p.numel() for p in model.parameters() if p.stop_gradient==False)\n",
    "\n",
    "\n",
    "def save_model_weights(model, modelpath, filename):\n",
    "    paddle.save(model.state_dict(), modelpath+filename)\n",
    "    return f\"\\n -> Save weights to {modelpath+filename}\\n\"\n",
    "\n",
    "from paddle.optimizer.lr import LRScheduler\n",
    "#自定义warmup，warmup到达lr后再线性衰减\n",
    "class LinearWarmup(LRScheduler):\n",
    "    def __init__(self,\n",
    "                 learning_rate,\n",
    "                 warmup_steps,\n",
    "                 num_training_steps,\n",
    "                 end_lr=0.1,\n",
    "                 start_lr=0.,\n",
    "                 last_epoch=-1,\n",
    "                 verbose=False):\n",
    "        type_check = isinstance(learning_rate, float) or isinstance(\n",
    "            learning_rate, int) or isinstance(learning_rate, LRScheduler)\n",
    "        if not type_check:\n",
    "            raise TypeError(\n",
    "                \"the type of learning_rate should be [int, float or LRScheduler], the current type is {}\".\n",
    "                format(learning_rate))\n",
    "        self.learning_rate = learning_rate\n",
    "        assert warmup_steps > 0 and isinstance(\n",
    "            warmup_steps, int), \" 'warmup_steps' must be a positive integer.\"\n",
    "        self.warmup_steps = warmup_steps\n",
    "        self.start_lr = start_lr\n",
    "        self.end_lr = learning_rate\n",
    "        assert end_lr > start_lr, \"end_lr {} must be greater than start_lr {}\".format(\n",
    "            end_lr, start_lr)\n",
    "        super(LinearWarmup, self).__init__(start_lr, last_epoch, verbose)\n",
    "        self.num_training_steps = num_training_steps\n",
    "\n",
    "    def state_dict(self):\n",
    "        \"\"\"\n",
    "        Returns the state of the LinearWarmup scheduler as a :class:`dict`.\n",
    "        It is a subset of ``self.__dict__`` .\n",
    "        \"\"\"\n",
    "        state_dict = super(LinearWarmup, self).state_dict()\n",
    "        if isinstance(self.learning_rate, LRScheduler):\n",
    "            state_dict[\"LinearWarmup_LR\"] = self.learning_rate.state_dict()\n",
    "        return state_dict\n",
    "\n",
    "    def set_state_dict(self, state_dict):\n",
    "        \"\"\"\n",
    "        Loads state_dict for LinearWarmup scheduler.\n",
    "        \"\"\"\n",
    "        super(LinearWarmup, self).set_state_dict(state_dict)\n",
    "        if isinstance(self.learning_rate, LRScheduler):\n",
    "            self.learning_rate.set_state_dict(state_dict[\"LinearWarmup_LR\"])\n",
    "\n",
    "    def get_lr(self):\n",
    "        if self.last_epoch < self.warmup_steps:\n",
    "            return (self.end_lr - self.start_lr) * float(\n",
    "                self.last_epoch) / float(self.warmup_steps) + self.start_lr\n",
    "        else:\n",
    "            return (self.end_lr - self.start_lr) * max(\n",
    "            0.0, float(self.num_training_steps - self.last_epoch) / float(max(1, self.num_training_steps - self.warmup_steps))\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "\n",
    "def compute_metric(pred, y):\n",
    "    corr = []\n",
    "    if pred.shape[1]>2:\n",
    "        for i in range(8):\n",
    "            corr.append(scipy.stats.stats.kendalltau(pred[:, i], y[:, i])[0])\n",
    "    else:\n",
    "        corr.append(scipy.stats.stats.kendalltau(pred, y)[0])\n",
    "    return np.array(corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, \n",
    "        train_dataset, \n",
    "        val_dataset, \n",
    "        verbose=20, \n",
    "        fold_=0,\n",
    "        modelname='MLP_base',\n",
    "        modelpath=r'./model'+'//',\n",
    "        input='input',\n",
    "        y='y',\n",
    "        early_stop_round=60,\n",
    "        debug=False):\n",
    "    \n",
    "    print(f'Model parameters count: {count_parameters(model)}')\n",
    "    #data loader\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=False,\n",
    "        drop_last=True,\n",
    "    )\n",
    "\n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=BATCH_SIZE_TEST,\n",
    "        shuffle=False,\n",
    "        drop_last=False,\n",
    "    )\n",
    "    print(f'train batch num: {len(train_loader)}')\n",
    "    print(f'val batch num: {len(val_loader)}')\n",
    "            \n",
    "\n",
    "    # Scheduler\n",
    "    num_warmup_steps = int(0.1 * EPOCHS * len(train_loader))\n",
    "    num_training_steps = int(EPOCHS * len(train_loader))\n",
    "    \n",
    "    scheduler = LinearWarmup(\n",
    "        learning_rate=LR,\n",
    "        warmup_steps=num_warmup_steps,\n",
    "        num_training_steps=num_training_steps\n",
    "    )\n",
    "    # Optimizer\n",
    "    optimizer = getattr(paddle.optimizer, optim)(learning_rate=scheduler, parameters=model.parameters())\n",
    "    print(f'optim: {optim}, lr: {LR}, warmup_steps: {num_warmup_steps}, training steps: {num_training_steps}')\n",
    "    \n",
    "    print(f'early stopping round: {early_stop_round}\\n')\n",
    "    #train\n",
    "    bst_epoch=0\n",
    "    score_best=0\n",
    "    first_epoch_eval=0\n",
    "    for epoch in range(EPOCHS):\n",
    "        if epoch > early_stop_round and (epoch - bst_epoch > early_stop_round):\n",
    "            print(f'early stopping.')\n",
    "            break\n",
    "        \n",
    "        model.train()\n",
    "        optimizer.clear_grad()\n",
    "        start_time = time.time()\n",
    "\n",
    "        avg_loss = 0\n",
    "        for data in train_loader:\n",
    "            pred = model(data[input])\n",
    "\n",
    "            loss = loss_fct(\n",
    "                pred,\n",
    "                data[y]\n",
    "            ).mean()\n",
    "\n",
    "            loss.backward()\n",
    "            avg_loss += loss.item() / len(train_loader)\n",
    "\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "            optimizer.clear_grad()\n",
    "\n",
    "        #VAL\n",
    "        model.eval()\n",
    "        mae, avg_val_loss = 0, 0\n",
    "        preds = []\n",
    "\n",
    "        with paddle.no_grad():\n",
    "            for data in val_loader:\n",
    "                pred = model(data[input])\n",
    "\n",
    "                loss = loss_fct(\n",
    "                    pred,\n",
    "                    data[y]\n",
    "                ).mean()\n",
    "\n",
    "                avg_val_loss += loss.item() / len(val_loader)\n",
    "\n",
    "                preds.append(pred.numpy())\n",
    "\n",
    "        preds = np.concatenate(preds, 0)\n",
    "        if y=='y':\n",
    "            mae = compute_metric(preds,val_dataset.df[target_cols].values).mean()\n",
    "        else:\n",
    "            mae = compute_metric(preds,val_dataset.df[[target_cols[int(y.replace('y',''))]]].values).mean()\n",
    "        \n",
    "        elapsed_time = time.time() - start_time\n",
    "        if (epoch + 1) % verbose == 0:\n",
    "            elapsed_time = elapsed_time * verbose\n",
    "            lr = scheduler.get_lr()\n",
    "            \n",
    "            print(\n",
    "                f\"Epoch {epoch + 1:02d}/{ EPOCHS:02d} \\t lr={lr:.1e}\\t t={elapsed_time:.0f}s \\t\"\n",
    "                f\"loss={avg_loss:.4f}\",\n",
    "                end=\"\\t\",\n",
    "            )\n",
    "\n",
    "            if (epoch + 1 >= first_epoch_eval) or (epoch + 1 == EPOCHS):\n",
    "                print(f\"val_loss={avg_val_loss:.4f}\\tcorr={mae:.4f}\")\n",
    "            else:\n",
    "                print(\"\")\n",
    "                \n",
    "        #保存最优模型\n",
    "        if mae>score_best:\n",
    "            bst = save_model_weights(model, modelpath, f'{modelname}_{fold_}.pt')\n",
    "            score_best = mae\n",
    "            bst_epoch = epoch\n",
    "            if y=='y':\n",
    "                bst_list = compute_metric(preds,val_dataset.df[target_cols].values)\n",
    "            else:\n",
    "                bst_list = compute_metric(preds,val_dataset.df[[target_cols[int(y.replace('y',''))]]].values).mean()\n",
    "            bst_preds = preds\n",
    "    print(f'best score {score_best}, best epoch: {bst_epoch}, {bst} ' )\n",
    "    print(np.mean(bst_list),bst_list,'\\n\\n')\n",
    "    del (val_loader, train_loader, loss, data, pred)\n",
    "    gc.collect()\n",
    "    paddle.device.cuda.empty_cache()\n",
    "    \n",
    "    return bst_preds, bst_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CVPRModel(nn.Layer):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim=3,\n",
    "        num_classes=8,\n",
    "    ):\n",
    "        super(CVPRModel, self).__init__()\n",
    "        \n",
    "        self.SuperLinear = nn.Linear(input_dim, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        pred = self.SuperLinear(x)\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "train size: 400, val size: 100\n",
      "Model parameters count: Tensor(shape=[1], dtype=int64, place=CUDAPlace(0), stop_gradient=False,\n",
      "       [752])\n",
      "train batch num: 1\n",
      "val batch num: 1\n",
      "optim: Adam, lr: 0.1, warmup_steps: 30, training steps: 300\n",
      "early stopping round: 60\n",
      "\n",
      "Epoch 20/300 \t lr=6.7e-02\t t=1s \tloss=0.3333\tval_loss=0.4005\tcorr=0.6499\n",
      "Epoch 40/300 \t lr=9.6e-02\t t=1s \tloss=0.1816\tval_loss=0.2423\tcorr=0.7374\n",
      "Epoch 60/300 \t lr=8.9e-02\t t=1s \tloss=0.1364\tval_loss=0.1754\tcorr=0.7774\n",
      "Epoch 80/300 \t lr=8.1e-02\t t=1s \tloss=0.1311\tval_loss=0.1725\tcorr=0.7855\n",
      "Epoch 100/300 \t lr=7.4e-02\t t=1s \tloss=0.1305\tval_loss=0.1709\tcorr=0.7886\n",
      "Epoch 120/300 \t lr=6.7e-02\t t=1s \tloss=0.1304\tval_loss=0.1707\tcorr=0.7878\n",
      "Epoch 140/300 \t lr=5.9e-02\t t=1s \tloss=0.1304\tval_loss=0.1706\tcorr=0.7885\n",
      "Epoch 160/300 \t lr=5.2e-02\t t=1s \tloss=0.1304\tval_loss=0.1706\tcorr=0.7881\n",
      "early stopping.\n",
      "best score 0.788888888888889, best epoch: 106, \n",
      " -> Save weights to ./model/paddle_superlinear_ranker_0.pt\n",
      " \n",
      "0.788888888888889 [0.3010101  0.90020202 0.89494949 0.95111111 0.87878788 0.67555556\n",
      " 0.91636364 0.79313131] \n",
      "\n",
      "\n",
      "FOLD 1\n",
      "train size: 400, val size: 100\n",
      "Model parameters count: Tensor(shape=[1], dtype=int64, place=CUDAPlace(0), stop_gradient=False,\n",
      "       [752])\n",
      "train batch num: 1\n",
      "val batch num: 1\n",
      "optim: Adam, lr: 0.1, warmup_steps: 30, training steps: 300\n",
      "early stopping round: 60\n",
      "\n",
      "Epoch 20/300 \t lr=6.7e-02\t t=2s \tloss=0.3362\tval_loss=0.3375\tcorr=0.6671\n",
      "Epoch 40/300 \t lr=9.6e-02\t t=2s \tloss=0.1797\tval_loss=0.2213\tcorr=0.7294\n",
      "Epoch 60/300 \t lr=8.9e-02\t t=1s \tloss=0.1368\tval_loss=0.1752\tcorr=0.7652\n",
      "Epoch 80/300 \t lr=8.1e-02\t t=2s \tloss=0.1322\tval_loss=0.1738\tcorr=0.7741\n",
      "Epoch 100/300 \t lr=7.4e-02\t t=2s \tloss=0.1316\tval_loss=0.1713\tcorr=0.7754\n",
      "Epoch 120/300 \t lr=6.7e-02\t t=2s \tloss=0.1315\tval_loss=0.1711\tcorr=0.7760\n",
      "Epoch 140/300 \t lr=5.9e-02\t t=1s \tloss=0.1315\tval_loss=0.1712\tcorr=0.7763\n",
      "early stopping.\n",
      "best score 0.7767033100618026, best epoch: 93, \n",
      " -> Save weights to ./model/paddle_superlinear_ranker_1.pt\n",
      " \n",
      "0.7767033100618026 [0.26262626 0.87191919 0.89818182 0.96646465 0.88686869 0.6440404\n",
      " 0.90211133 0.78141414] \n",
      "\n",
      "\n",
      "FOLD 2\n",
      "train size: 400, val size: 100\n",
      "Model parameters count: Tensor(shape=[1], dtype=int64, place=CUDAPlace(0), stop_gradient=False,\n",
      "       [752])\n",
      "train batch num: 1\n",
      "val batch num: 1\n",
      "optim: Adam, lr: 0.1, warmup_steps: 30, training steps: 300\n",
      "early stopping round: 60\n",
      "\n",
      "Epoch 20/300 \t lr=6.7e-02\t t=1s \tloss=0.3426\tval_loss=0.4060\tcorr=0.6444\n",
      "Epoch 40/300 \t lr=9.6e-02\t t=1s \tloss=0.1784\tval_loss=0.2177\tcorr=0.7412\n",
      "Epoch 60/300 \t lr=8.9e-02\t t=1s \tloss=0.1355\tval_loss=0.1866\tcorr=0.7713\n",
      "Epoch 80/300 \t lr=8.1e-02\t t=1s \tloss=0.1303\tval_loss=0.1793\tcorr=0.7828\n",
      "Epoch 100/300 \t lr=7.4e-02\t t=1s \tloss=0.1295\tval_loss=0.1777\tcorr=0.7844\n",
      "Epoch 120/300 \t lr=6.7e-02\t t=1s \tloss=0.1288\tval_loss=0.1776\tcorr=0.7842\n",
      "Epoch 140/300 \t lr=5.9e-02\t t=2s \tloss=0.1288\tval_loss=0.1779\tcorr=0.7846\n",
      "early stopping.\n",
      "best score 0.7850000000000001, best epoch: 94, \n",
      " -> Save weights to ./model/paddle_superlinear_ranker_2.pt\n",
      " \n",
      "0.7850000000000001 [0.24525253 0.84848485 0.8969697  0.96242424 0.90626263 0.71676768\n",
      " 0.91717172 0.78666667] \n",
      "\n",
      "\n",
      "FOLD 3\n",
      "train size: 400, val size: 100\n",
      "Model parameters count: Tensor(shape=[1], dtype=int64, place=CUDAPlace(0), stop_gradient=False,\n",
      "       [752])\n",
      "train batch num: 1\n",
      "val batch num: 1\n",
      "optim: Adam, lr: 0.1, warmup_steps: 30, training steps: 300\n",
      "early stopping round: 60\n",
      "\n",
      "Epoch 20/300 \t lr=6.7e-02\t t=1s \tloss=0.3495\tval_loss=0.3425\tcorr=0.6612\n",
      "Epoch 40/300 \t lr=9.6e-02\t t=2s \tloss=0.1788\tval_loss=0.2412\tcorr=0.7185\n",
      "Epoch 60/300 \t lr=8.9e-02\t t=2s \tloss=0.1342\tval_loss=0.1948\tcorr=0.7548\n",
      "Epoch 80/300 \t lr=8.1e-02\t t=1s \tloss=0.1287\tval_loss=0.1847\tcorr=0.7642\n",
      "Epoch 100/300 \t lr=7.4e-02\t t=1s \tloss=0.1279\tval_loss=0.1841\tcorr=0.7621\n",
      "Epoch 120/300 \t lr=6.7e-02\t t=1s \tloss=0.1280\tval_loss=0.1842\tcorr=0.7629\n",
      "Epoch 140/300 \t lr=5.9e-02\t t=2s \tloss=0.1278\tval_loss=0.1842\tcorr=0.7628\n",
      "early stopping.\n",
      "best score 0.7653030303030304, best epoch: 83, \n",
      " -> Save weights to ./model/paddle_superlinear_ranker_3.pt\n",
      " \n",
      "0.7653030303030304 [0.24606061 0.86464646 0.88363636 0.96606061 0.88121212 0.59878788\n",
      " 0.90262626 0.77939394] \n",
      "\n",
      "\n",
      "FOLD 4\n",
      "train size: 400, val size: 100\n",
      "Model parameters count: Tensor(shape=[1], dtype=int64, place=CUDAPlace(0), stop_gradient=False,\n",
      "       [752])\n",
      "train batch num: 1\n",
      "val batch num: 1\n",
      "optim: Adam, lr: 0.1, warmup_steps: 30, training steps: 300\n",
      "early stopping round: 60\n",
      "\n",
      "Epoch 20/300 \t lr=6.7e-02\t t=1s \tloss=0.3447\tval_loss=0.3485\tcorr=0.6782\n",
      "Epoch 40/300 \t lr=9.6e-02\t t=2s \tloss=0.1813\tval_loss=0.2089\tcorr=0.7445\n",
      "Epoch 60/300 \t lr=8.9e-02\t t=1s \tloss=0.1385\tval_loss=0.1741\tcorr=0.7769\n",
      "Epoch 80/300 \t lr=8.1e-02\t t=1s \tloss=0.1338\tval_loss=0.1648\tcorr=0.7863\n",
      "Epoch 100/300 \t lr=7.4e-02\t t=1s \tloss=0.1322\tval_loss=0.1632\tcorr=0.7876\n",
      "Epoch 120/300 \t lr=6.7e-02\t t=2s \tloss=0.1321\tval_loss=0.1635\tcorr=0.7881\n",
      "early stopping.\n",
      "best score 0.7884343434343435, best epoch: 71, \n",
      " -> Save weights to ./model/paddle_superlinear_ranker_4.pt\n",
      " \n",
      "0.7884343434343435 [0.26666667 0.85373737 0.90868687 0.95515152 0.90828283 0.69494949\n",
      " 0.92808081 0.79191919] \n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.78087,\n",
       " [0.26432, 0.8678, 0.89648, 0.96024, 0.89228, 0.66602, 0.91327, 0.78651])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed = 666\n",
    "BATCH_SIZE = 400\n",
    "BATCH_SIZE_TEST = 128\n",
    "EPOCHS = 300\n",
    "LR = 0.1\n",
    "optim = \"Adam\"\n",
    "paddle.set_device(\"gpu\")\n",
    "modelpath = r'./model/'\n",
    "\n",
    "# K折，对做了目标变换及ohe的8目标同时训练\n",
    "loss_fct = nn.MSELoss()\n",
    "k=5\n",
    "scoref = []\n",
    "skf = KFold(n_splits=k, shuffle=False)\n",
    "for index, (train_index, test_index) in enumerate(skf.split(train_df)):   \n",
    "    print(f'FOLD {index}')\n",
    "    train0 = train_df.iloc[train_index]\n",
    "    val0 = train_df.iloc[test_index]   \n",
    "    train_dataset = MyDataset(train0, use_cols, target_cols)\n",
    "    val_dataset = MyDataset(val0, use_cols, target_cols)\n",
    "    print(f'train size: {len(train0)}, val size: {len(val0)}')\n",
    "\n",
    "    modelname = f'paddle_superlinear_ranker'\n",
    "    seed_everything(seed)\n",
    "    model = CVPRModel(input_dim=len(use_cols),\n",
    "                    num_classes=8,\n",
    "                   )\n",
    "    preds,_ = train(model, \n",
    "                train_dataset, \n",
    "                val_dataset, \n",
    "                verbose=20, \n",
    "                fold_=index,\n",
    "                modelname=modelname,\n",
    "                modelpath=modelpath,\n",
    "                input='input',\n",
    "                y='y',\n",
    "                early_stop_round=60,\n",
    "                debug=False\n",
    "                 )\n",
    "    scoref.append(_)\n",
    "scoreff = scoref\n",
    "np.round(np.array(scoreff).mean(1).mean(), 5), [round(x, 5) for x in np.array(scoreff).mean(0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.78087,\n",
       " [0.26432, 0.8678, 0.89648, 0.96024, 0.89228, 0.66602, 0.91327, 0.78651])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(np.array(scoreff).mean(1).mean(), 5), [round(x, 5) for x in np.array(scoreff).mean(0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "加载test\n",
    "______________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/CVPR_2022_NAS_Track2_test.json', 'r') as f:\n",
    "    test_data = json.load(f)\n",
    "    \n",
    "target_cols = ['cplfw_rank', 'market1501_rank', 'dukemtmc_rank', 'msmt17_rank', 'veri_rank', 'vehicleid_rank', 'veriwild_rank', 'sop_rank']\n",
    "test_df = get_df(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(base_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ohe(test_df, base_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "93"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([x for x in test_df if x[:3]=='ohe'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_cuda(test_df, model):\n",
    "    #获得预测\n",
    "    test_dataset = MyDataset(test_df, use_cols, target_cols, 0)\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=1024*128,\n",
    "        shuffle=False,\n",
    "        drop_last=False\n",
    "    )\n",
    "\n",
    "    preds = []\n",
    "    model.eval()\n",
    "    with paddle.no_grad():\n",
    "        for data in tqdm(test_loader):\n",
    "            pred = model(data['input'])\n",
    "            preds.append(pred.numpy())\n",
    "    preds = np.concatenate(preds, 0)\n",
    "    print(preds.shape)\n",
    "    \n",
    "    del test_dataset, test_loader, model;\n",
    "    gc.collect()\n",
    "    paddle.device.cuda.empty_cache()\n",
    "    return preds\n",
    "\n",
    "def predict_all(test_df, k=5, modelname = f'paddle_7937_LSTM_2layer_hardtanh'):\n",
    "    print(f'Model {modelname}')\n",
    "    #pred\n",
    "    cols = []\n",
    "    for fold_ in range(k):\n",
    "        model = CVPRModel(input_dim=93,\n",
    "                    num_classes=8,\n",
    "                   )\n",
    "        state_dict = paddle.load(modelpath+f'{modelname}_{fold_}.pt')\n",
    "        model.set_state_dict(state_dict)\n",
    "        \n",
    "        pred_ = pred_cuda(test_df, model)\n",
    "        tmp_c = [f'{target}_{fold_}' for target in target_cols]\n",
    "        test_df[tmp_c] = pred_\n",
    "        cols += tmp_c\n",
    "    #get rank\n",
    "    print(cols)\n",
    "    test_df[cols] = test_df[cols].rank()\n",
    "    for c in target_cols:\n",
    "        test_df[c] = test_df[[f'{c}_{fold_}' for fold_ in range(k)]].mean(axis=1)\n",
    "        test_df[c] = test_df[c].rank()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 'paddle_superlinear_ranker')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k, modelname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model paddle_superlinear_ranker\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:14<00:00, 14.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(99500, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:13<00:00, 13.71s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(99500, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:13<00:00, 13.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(99500, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:13<00:00, 13.72s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(99500, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:13<00:00, 13.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(99500, 8)\n",
      "['cplfw_rank_0', 'market1501_rank_0', 'dukemtmc_rank_0', 'msmt17_rank_0', 'veri_rank_0', 'vehicleid_rank_0', 'veriwild_rank_0', 'sop_rank_0', 'cplfw_rank_1', 'market1501_rank_1', 'dukemtmc_rank_1', 'msmt17_rank_1', 'veri_rank_1', 'vehicleid_rank_1', 'veriwild_rank_1', 'sop_rank_1', 'cplfw_rank_2', 'market1501_rank_2', 'dukemtmc_rank_2', 'msmt17_rank_2', 'veri_rank_2', 'vehicleid_rank_2', 'veriwild_rank_2', 'sop_rank_2', 'cplfw_rank_3', 'market1501_rank_3', 'dukemtmc_rank_3', 'msmt17_rank_3', 'veri_rank_3', 'vehicleid_rank_3', 'veriwild_rank_3', 'sop_rank_3', 'cplfw_rank_4', 'market1501_rank_4', 'dukemtmc_rank_4', 'msmt17_rank_4', 'veri_rank_4', 'vehicleid_rank_4', 'veriwild_rank_4', 'sop_rank_4']\n"
     ]
    }
   ],
   "source": [
    "model_dt = predict_all(test_df, k=k, modelname='paddle_superlinear_ranker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df[target_cols] = test_df[target_cols].astype(int)-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to_sub\n",
    "def to_sub(test_df, test_data, name='CVPR_2022_lgb_score'):\n",
    "    for i in tqdm(test_df[['id']+target_cols].values):\n",
    "        id_ = i[0]\n",
    "        for k,v in enumerate(target_cols):\n",
    "            k += 1\n",
    "            test_data[id_][v] = i[k]\n",
    "            \n",
    "    with open(f'./sub/{name}.json', 'w') as f:\n",
    "        json.dump(test_data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 99500/99500 [00:00<00:00, 705032.22it/s]\n"
     ]
    }
   ],
   "source": [
    "to_sub(test_df, test_data, name='CVPR_2022_paddle_superliner_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
