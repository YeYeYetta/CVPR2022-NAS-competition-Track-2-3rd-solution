{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('./data/CVPR_2022_NAS_Track2_train.json', 'r') as f:\n",
    "    train_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_cols = ['cplfw_rank', 'market1501_rank', 'dukemtmc_rank', 'msmt17_rank', 'veri_rank', 'vehicleid_rank', 'veriwild_rank', 'sop_rank']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df(train_data):\n",
    "    ret = []\n",
    "    for k, v in train_data.items():\n",
    "        tmp = list(v['arch'])\n",
    "        tmp1 = []\n",
    "        for c in target_cols:\n",
    "            tmp1.append(v[c])\n",
    "        ret.append(tmp+tmp1+[k,v['arch']])\n",
    "    retf = pd.DataFrame(ret,columns=[f'col{_}' for _ in range(len(tmp))]+target_cols+['id','arch'])\n",
    "    retf['col0'] = retf['col0'].map({'l':1, 'j':2, 'k':3})\n",
    "    int_cols = [x for x in retf.columns if x not in ['id','arch']]\n",
    "    retf[int_cols] = retf[int_cols].astype(float)\n",
    "    return retf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = get_df(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import erfinv \n",
    "\n",
    "for c in target_cols:\n",
    "\n",
    "    train_y=train_df[c]\n",
    "    mmin=np.min(train_y)+1\n",
    "    mmax=np.max(train_y)+1\n",
    "    train_y=np.sqrt(2) * erfinv(2 * (train_y+mmin)/(mmin+mmax)-1)\n",
    "    train_df[c+'_trans_y'] = train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_step(train_df):\n",
    "    res0 = []\n",
    "    res1 = []\n",
    "    res2 = []\n",
    "    res3 = []\n",
    "    res4 = []\n",
    "    map_={'l':1, 'j':2, 'k':3}\n",
    "    time_step=12\n",
    "    head_ = set([1+_*3 for _ in range(12)])\n",
    "    mlp_ = set([2+_*3 for _ in range(12)])\n",
    "    emb_ = set([3+_*3 for _ in range(12)])\n",
    "    depth_ = set([0])\n",
    "    for item in train_df.arch:\n",
    "        ret = np.array(list(item[1:]),dtype=np.float32).reshape(-1,3)\n",
    "        res0.append([1 if x in head_ else 0 for x in range(37)])\n",
    "        res1.append([1 if x in mlp_ else 0 for x in range(37)])\n",
    "        res2.append([1 if x in emb_ else 0 for x in range(37)])\n",
    "        res3.append([1 if x in depth_ else 0 for x in range(37)])\n",
    "        res4.append([map_[item[0]]]+list(np.array(list(item[1:]),dtype=np.float32)))\n",
    "        \n",
    "    train_df['head'] = res0\n",
    "    train_df['mlp'] = res1\n",
    "    train_df['emb'] = res2\n",
    "    train_df['depth'] = res3\n",
    "    train_df['all_emb'] = res4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_step(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义数据\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self,df,use_cols,target_cols,show=0):\n",
    "        self.df = df\n",
    "        self.show = show\n",
    "        self.use_cols = use_cols\n",
    "        self.target_cols = target_cols\n",
    "\n",
    "        self.prepare_data()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "    \n",
    "    def prepare_data(self):\n",
    "        self.y = self.df[self.target_cols].values\n",
    "        self.y0 = self.df[[self.target_cols[0]]].values\n",
    "        self.y1 = self.df[[self.target_cols[1]]].values\n",
    "        self.y2 = self.df[[self.target_cols[2]]].values\n",
    "        self.y3 = self.df[[self.target_cols[3]]].values\n",
    "        self.y4 = self.df[[self.target_cols[4]]].values\n",
    "        self.y5 = self.df[[self.target_cols[5]]].values\n",
    "        self.y6 = self.df[[self.target_cols[6]]].values\n",
    "        self.y7 = self.df[[self.target_cols[7]]].values\n",
    "        \n",
    "        uc = ['all_emb']\n",
    "        tmp_dt = {}\n",
    "        for c in uc:\n",
    "            tmp_dt[c] = np.array(self.df[c].tolist())\n",
    "        self.inputs = np.concatenate([tmp_dt[c][:, None] for c in uc], 1).transpose(0, 2, 1)\n",
    "\n",
    "        uc= ['all_emb','depth','head','mlp','emb']\n",
    "        tmp_dt = {}\n",
    "        for c in uc:\n",
    "            tmp_dt[c] = np.array(self.df[c].tolist())\n",
    "        self.inputs1= np.concatenate([tmp_dt[c][:, None] for c in uc], 1).transpose(0, 2, 1)\n",
    "        \n",
    "        \n",
    "        if self.show==1:\n",
    "            print('inputs_shape',self.inputs.shape)\n",
    "            print('inputs1_shape',self.inputs1.shape)\n",
    "            print('y_shape',self.y.shape)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        data = {\n",
    "            \"input\": torch.tensor(self.inputs[idx], dtype=torch.float),\n",
    "            \"input1\": torch.tensor(self.inputs1[idx], dtype=torch.float),\n",
    "            \"y\": torch.tensor(self.y[idx], dtype=torch.float),\n",
    "            \"y0\": torch.tensor(self.y0[idx], dtype=torch.float),\n",
    "            \"y1\": torch.tensor(self.y1[idx], dtype=torch.float),\n",
    "            \"y2\": torch.tensor(self.y2[idx], dtype=torch.float),\n",
    "            \"y3\": torch.tensor(self.y3[idx], dtype=torch.float),\n",
    "            \"y4\": torch.tensor(self.y4[idx], dtype=torch.float),\n",
    "            \"y5\": torch.tensor(self.y5[idx], dtype=torch.float),\n",
    "            \"y6\": torch.tensor(self.y6[idx], dtype=torch.float),\n",
    "            \"y7\": torch.tensor(self.y7[idx], dtype=torch.float),\n",
    "        }\n",
    "        \n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cols = [x for x in train_df.columns if 'col' in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(use_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    \n",
    "    \n",
    "def count_parameters(model, all=False):\n",
    "    if all:\n",
    "        return sum(p.numel() for p in model.parameters())\n",
    "    else:\n",
    "        return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "\n",
    "def save_model_weights(model, modelpath, filename):\n",
    "    torch.save(model.state_dict(), modelpath+filename)\n",
    "    return f\"\\n -> Save weights to {modelpath+filename}\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metric(pred, y):\n",
    "    corr = []\n",
    "    if pred.shape[1]>2:\n",
    "        for i in range(8):\n",
    "            corr.append(scipy.stats.stats.kendalltau(pred[:, i], y[:, i])[0])\n",
    "    else:\n",
    "        corr.append(scipy.stats.stats.kendalltau(pred, y)[0])\n",
    "    return np.array(corr)\n",
    "    \n",
    "class CVPRLoss_pair(nn.Module):\n",
    "    def __call__(self, pred, y):\n",
    "        return torch.cat(\n",
    "            [self.pair_loss(pred[:,i], y[:,i]).reshape(1) for i in range(y.shape[1])]\n",
    "        ).reshape(1,-1)\n",
    "    \n",
    "    def pair_loss(self, outputs, labels):\n",
    "        output = outputs.unsqueeze(1)\n",
    "        output1 = output.repeat(1,outputs.shape[0])\n",
    "        label = labels.unsqueeze(1)\n",
    "        label1 = label.repeat(1,labels.shape[0])\n",
    "\n",
    "        tmp = (output1-output1.t())*torch.sign(label1-label1.t())\n",
    "        tmp = torch.log(1+torch.exp(-tmp))\n",
    "        eye_tmp = tmp*torch.eye(len(tmp)).cuda()\n",
    "        new_tmp = tmp - eye_tmp\n",
    "        loss = torch.sum(new_tmp)/(outputs.shape[0]*(outputs.shape[0]-1))\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CVPRModel(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim=3,\n",
    "        num_classes=8,\n",
    "        time_step=12,\n",
    "        bi=True\n",
    "    ):\n",
    "        super(CVPRModel,self).__init__()\n",
    "        \n",
    "        self.bi_num = 2 if bi else 1\n",
    "        self.time_step = time_step\n",
    "        \n",
    "        self.MLP = nn.Sequential(\n",
    "            nn.Linear(input_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 256),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.LSTM0 = nn.LSTM(256, 256, \n",
    "                    batch_first=True, \n",
    "                    bidirectional=bi, \n",
    "                    num_layers=1,\n",
    "                    dropout=0)\n",
    "                                 \n",
    "        \n",
    "        self.LSTM1 = nn.LSTM(512, 256, \n",
    "                    batch_first=True, \n",
    "                    bidirectional=bi, \n",
    "                    num_layers=1,\n",
    "                    dropout=0\n",
    "                            )    \n",
    "\n",
    "        self.Logits = nn.Sequential(\n",
    "            nn.Flatten(start_dim=1),\n",
    "            nn.Linear((512+512+256+1)*self.time_step, 2048),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(2048, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x1 = self.MLP(x)\n",
    "        x2, (h0, c0) = self.LSTM0(x1)\n",
    "        x3, (h1, c1) = self.LSTM1(x2, (h0, c0))\n",
    "\n",
    "        c1 = torch.cat([x3, x2, x1, x], -1)\n",
    "        pred = self.Logits(c1)\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_sig(model, \n",
    "        train_dataset, \n",
    "        val_dataset, \n",
    "        verbose=20, \n",
    "        fold_=0,\n",
    "        modelname='MLP_base',\n",
    "        modelpath=r'./model'+'//',\n",
    "        input='input',\n",
    "        y='y',\n",
    "        early_stop_round=60,\n",
    "        debug=False):\n",
    "    \n",
    "    print(f'Model parameters count: {count_parameters(model)}')\n",
    "    #数据加载\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=False,\n",
    "        drop_last=True,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=BATCH_SIZE_TEST,\n",
    "        shuffle=False,\n",
    "        drop_last=False,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    print(f'train batch num: {len(train_loader)}')\n",
    "    print(f'val batch num: {len(val_loader)}')\n",
    "            \n",
    "    # Optimizer\n",
    "    optimizer = getattr(torch.optim, optim)(model.parameters(), lr=LR)\n",
    "    # Scheduler\n",
    "    num_warmup_steps = int(0.1 * EPOCHS * len(train_loader))\n",
    "    num_training_steps = int(EPOCHS * len(train_loader))\n",
    "    scheduler = get_linear_schedule_with_warmup(\n",
    "        optimizer, num_warmup_steps, num_training_steps\n",
    "    )\n",
    "    print(f'optim: {optim}, lr: {LR}, warmup_steps: {num_warmup_steps}')\n",
    "    \n",
    "    \n",
    "    #train\n",
    "    bst_epoch={_:0 for _ in range(8)}\n",
    "    score_best={_:0 for _ in range(8)}\n",
    "    first_epoch_eval=0\n",
    "    for epoch in range(EPOCHS):\n",
    "        \n",
    "        model.train()\n",
    "        model.zero_grad()\n",
    "        start_time = time.time()\n",
    "\n",
    "        avg_loss = 0\n",
    "        for data in train_loader:\n",
    "            pred = model(data[input].to(device))\n",
    "#             print(pred.shape,data['y'].shape)\n",
    "\n",
    "            loss = loss_fct(\n",
    "                pred,\n",
    "                data[y].to(device)\n",
    "            ).mean()\n",
    "\n",
    "            loss.backward()\n",
    "            avg_loss += loss.item() / len(train_loader)\n",
    "\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "        #VAL\n",
    "        model.eval()\n",
    "        mae, avg_val_loss = 0, 0\n",
    "        preds = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for data in val_loader:\n",
    "                pred = model(data[input].to(device))\n",
    "\n",
    "                loss = loss_fct(\n",
    "                    pred,\n",
    "                    data[y].to(device)\n",
    "                ).mean()\n",
    "\n",
    "                avg_val_loss += loss.item() / len(val_loader)\n",
    "\n",
    "                preds.append(pred.detach().cpu().numpy())\n",
    "\n",
    "        preds = np.concatenate(preds, 0)\n",
    "        if y=='y':\n",
    "            mae = compute_metric(preds,val_dataset.df[target_cols].values).mean()\n",
    "        else:\n",
    "            mae = compute_metric(preds,val_dataset.df[[target_cols[int(y.replace('y',''))]]].values).mean()\n",
    "        \n",
    "        elapsed_time = time.time() - start_time\n",
    "        if (epoch + 1) % verbose == 0:\n",
    "            elapsed_time = elapsed_time * verbose\n",
    "            lr = scheduler.get_last_lr()[0]\n",
    "    #         lr=LR\n",
    "            print(\n",
    "                f\"Epoch {epoch + 1:02d}/{ EPOCHS:02d} \\t lr={lr:.1e}\\t t={elapsed_time:.0f}s \\t\"\n",
    "                f\"loss={avg_loss:.4f}\",\n",
    "                end=\"\\t\",\n",
    "            )\n",
    "\n",
    "            if (epoch + 1 >= first_epoch_eval) or (epoch + 1 == EPOCHS):\n",
    "                print(f\"val_loss={avg_val_loss:.4f}\\tcorr={mae:.4f}\")\n",
    "            else:\n",
    "                print(\"\")\n",
    "                \n",
    "        #保存最优模型\n",
    "        score1 = compute_metric(preds,val_dataset.df[target_cols].values)\n",
    "        for i in range(8):\n",
    "            if score1[i] > score_best[i]:\n",
    "                bst = save_model_weights(model, modelpath, f'{modelname}_target{i}_{fold_}.pt')\n",
    "                score_best[i] = score1[i]\n",
    "                bst_epoch[i] = epoch\n",
    "#                 print(f'target{i} best score {score_best[i]}, best epoch: {bst_epoch[i]}, {bst} ' )\n",
    "                \n",
    "        bst_list = [score_best[i] for i in range(8)]\n",
    "    print(bst_list,'\\n\\n')\n",
    "    del (val_loader, train_loader, loss, data, pred)\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    return bst_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "train size: 400, val size: 100\n",
      "Model parameters count: 102162440\n",
      "train batch num: 1\n",
      "val batch num: 1\n",
      "optim: Adam, lr: 0.001, warmup_steps: 30\n",
      "Epoch 10/300 \t lr=3.3e-04\t t=1s \tloss=0.6578\tval_loss=0.6490\tcorr=0.3370\n",
      "Epoch 20/300 \t lr=6.7e-04\t t=2s \tloss=0.4211\tval_loss=0.4428\tcorr=0.5451\n",
      "Epoch 30/300 \t lr=1.0e-03\t t=4s \tloss=0.3339\tval_loss=0.3501\tcorr=0.6557\n",
      "Epoch 40/300 \t lr=9.6e-04\t t=1s \tloss=0.2827\tval_loss=0.3048\tcorr=0.7022\n",
      "Epoch 50/300 \t lr=9.3e-04\t t=2s \tloss=0.2271\tval_loss=0.2449\tcorr=0.7660\n",
      "Epoch 60/300 \t lr=8.9e-04\t t=3s \tloss=0.2102\tval_loss=0.2255\tcorr=0.7820\n",
      "Epoch 70/300 \t lr=8.5e-04\t t=1s \tloss=0.1947\tval_loss=0.2205\tcorr=0.7887\n",
      "Epoch 80/300 \t lr=8.1e-04\t t=1s \tloss=0.1902\tval_loss=0.2197\tcorr=0.7870\n",
      "Epoch 90/300 \t lr=7.8e-04\t t=1s \tloss=0.1855\tval_loss=0.2199\tcorr=0.7882\n",
      "Epoch 100/300 \t lr=7.4e-04\t t=1s \tloss=0.1802\tval_loss=0.2218\tcorr=0.7885\n",
      "Epoch 110/300 \t lr=7.0e-04\t t=1s \tloss=0.1737\tval_loss=0.2310\tcorr=0.7829\n",
      "Epoch 120/300 \t lr=6.7e-04\t t=1s \tloss=0.1689\tval_loss=0.2406\tcorr=0.7757\n",
      "Epoch 130/300 \t lr=6.3e-04\t t=1s \tloss=0.1572\tval_loss=0.2455\tcorr=0.7776\n",
      "Epoch 140/300 \t lr=5.9e-04\t t=1s \tloss=0.1472\tval_loss=0.2648\tcorr=0.7739\n",
      "Epoch 150/300 \t lr=5.6e-04\t t=1s \tloss=0.1331\tval_loss=0.2932\tcorr=0.7649\n",
      "Epoch 160/300 \t lr=5.2e-04\t t=1s \tloss=0.1210\tval_loss=0.3203\tcorr=0.7654\n",
      "Epoch 170/300 \t lr=4.8e-04\t t=1s \tloss=0.1154\tval_loss=0.3739\tcorr=0.7568\n",
      "Epoch 180/300 \t lr=4.4e-04\t t=1s \tloss=0.0925\tval_loss=0.4108\tcorr=0.7598\n",
      "Epoch 190/300 \t lr=4.1e-04\t t=1s \tloss=0.0809\tval_loss=0.4639\tcorr=0.7606\n",
      "Epoch 200/300 \t lr=3.7e-04\t t=1s \tloss=0.0685\tval_loss=0.5255\tcorr=0.7599\n",
      "Epoch 210/300 \t lr=3.3e-04\t t=1s \tloss=0.0571\tval_loss=0.6052\tcorr=0.7573\n",
      "Epoch 220/300 \t lr=3.0e-04\t t=1s \tloss=0.0494\tval_loss=0.6725\tcorr=0.7586\n",
      "Epoch 230/300 \t lr=2.6e-04\t t=1s \tloss=0.0406\tval_loss=0.7472\tcorr=0.7587\n",
      "Epoch 240/300 \t lr=2.2e-04\t t=1s \tloss=0.0348\tval_loss=0.8223\tcorr=0.7586\n",
      "Epoch 250/300 \t lr=1.9e-04\t t=1s \tloss=0.0295\tval_loss=0.8946\tcorr=0.7585\n",
      "Epoch 260/300 \t lr=1.5e-04\t t=1s \tloss=0.0260\tval_loss=0.9631\tcorr=0.7580\n",
      "Epoch 270/300 \t lr=1.1e-04\t t=1s \tloss=0.0234\tval_loss=1.0158\tcorr=0.7584\n",
      "Epoch 280/300 \t lr=7.4e-05\t t=1s \tloss=0.0217\tval_loss=1.0547\tcorr=0.7585\n",
      "Epoch 290/300 \t lr=3.7e-05\t t=1s \tloss=0.0208\tval_loss=1.0794\tcorr=0.7584\n",
      "Epoch 300/300 \t lr=0.0e+00\t t=1s \tloss=0.0204\tval_loss=1.0882\tcorr=0.7582\n",
      "[0.31232323232323234, 0.9046464646464647, 0.9006060606060607, 0.9571717171717172, 0.8852525252525254, 0.6836363636363638, 0.9272727272727275, 0.8165656565656567] \n",
      "\n",
      "\n",
      "FOLD 1\n",
      "train size: 400, val size: 100\n",
      "Model parameters count: 102162440\n",
      "train batch num: 1\n",
      "val batch num: 1\n",
      "optim: Adam, lr: 0.001, warmup_steps: 30\n",
      "Epoch 10/300 \t lr=3.3e-04\t t=2s \tloss=0.6620\tval_loss=0.6420\tcorr=0.4625\n",
      "Epoch 20/300 \t lr=6.7e-04\t t=3s \tloss=0.4201\tval_loss=0.4312\tcorr=0.5759\n",
      "Epoch 30/300 \t lr=1.0e-03\t t=3s \tloss=0.3378\tval_loss=0.3738\tcorr=0.6291\n",
      "Epoch 40/300 \t lr=9.6e-04\t t=3s \tloss=0.2811\tval_loss=0.3216\tcorr=0.6860\n",
      "Epoch 50/300 \t lr=9.3e-04\t t=4s \tloss=0.2277\tval_loss=0.2588\tcorr=0.7424\n",
      "Epoch 60/300 \t lr=8.9e-04\t t=4s \tloss=0.2075\tval_loss=0.2541\tcorr=0.7575\n",
      "Epoch 70/300 \t lr=8.5e-04\t t=1s \tloss=0.1934\tval_loss=0.2314\tcorr=0.7748\n",
      "Epoch 80/300 \t lr=8.1e-04\t t=1s \tloss=0.1872\tval_loss=0.2305\tcorr=0.7753\n",
      "Epoch 90/300 \t lr=7.8e-04\t t=1s \tloss=0.1823\tval_loss=0.2287\tcorr=0.7778\n",
      "Epoch 100/300 \t lr=7.4e-04\t t=1s \tloss=0.1768\tval_loss=0.2336\tcorr=0.7751\n",
      "Epoch 110/300 \t lr=7.0e-04\t t=2s \tloss=0.1701\tval_loss=0.2405\tcorr=0.7716\n",
      "Epoch 120/300 \t lr=6.7e-04\t t=1s \tloss=0.1626\tval_loss=0.2478\tcorr=0.7716\n",
      "Epoch 130/300 \t lr=6.3e-04\t t=1s \tloss=0.1530\tval_loss=0.2525\tcorr=0.7723\n",
      "Epoch 140/300 \t lr=5.9e-04\t t=1s \tloss=0.1457\tval_loss=0.2661\tcorr=0.7728\n",
      "Epoch 150/300 \t lr=5.6e-04\t t=1s \tloss=0.1327\tval_loss=0.2842\tcorr=0.7726\n",
      "Epoch 160/300 \t lr=5.2e-04\t t=1s \tloss=0.1249\tval_loss=0.3172\tcorr=0.7663\n",
      "Epoch 170/300 \t lr=4.8e-04\t t=1s \tloss=0.1106\tval_loss=0.3402\tcorr=0.7678\n",
      "Epoch 180/300 \t lr=4.4e-04\t t=1s \tloss=0.1056\tval_loss=0.3814\tcorr=0.7608\n",
      "Epoch 190/300 \t lr=4.1e-04\t t=1s \tloss=0.0866\tval_loss=0.4209\tcorr=0.7583\n",
      "Epoch 200/300 \t lr=3.7e-04\t t=1s \tloss=0.0727\tval_loss=0.4834\tcorr=0.7547\n",
      "Epoch 210/300 \t lr=3.3e-04\t t=1s \tloss=0.0670\tval_loss=0.5657\tcorr=0.7493\n",
      "Epoch 220/300 \t lr=3.0e-04\t t=1s \tloss=0.0543\tval_loss=0.6025\tcorr=0.7516\n",
      "Epoch 230/300 \t lr=2.6e-04\t t=1s \tloss=0.0470\tval_loss=0.6673\tcorr=0.7512\n",
      "Epoch 240/300 \t lr=2.2e-04\t t=1s \tloss=0.0407\tval_loss=0.7390\tcorr=0.7498\n",
      "Epoch 250/300 \t lr=1.9e-04\t t=1s \tloss=0.0360\tval_loss=0.8022\tcorr=0.7484\n",
      "Epoch 260/300 \t lr=1.5e-04\t t=1s \tloss=0.0324\tval_loss=0.8627\tcorr=0.7471\n",
      "Epoch 270/300 \t lr=1.1e-04\t t=1s \tloss=0.0296\tval_loss=0.9107\tcorr=0.7471\n",
      "Epoch 280/300 \t lr=7.4e-05\t t=1s \tloss=0.0277\tval_loss=0.9468\tcorr=0.7468\n",
      "Epoch 290/300 \t lr=3.7e-05\t t=1s \tloss=0.0265\tval_loss=0.9696\tcorr=0.7466\n",
      "Epoch 300/300 \t lr=0.0e+00\t t=1s \tloss=0.0261\tval_loss=0.9779\tcorr=0.7463\n",
      "[0.296969696969697, 0.8747474747474749, 0.9094949494949497, 0.9684848484848486, 0.9010101010101011, 0.6452525252525253, 0.9103030303030304, 0.808888888888889] \n",
      "\n",
      "\n",
      "FOLD 2\n",
      "train size: 400, val size: 100\n",
      "Model parameters count: 102162440\n",
      "train batch num: 1\n",
      "val batch num: 1\n",
      "optim: Adam, lr: 0.001, warmup_steps: 30\n",
      "Epoch 10/300 \t lr=3.3e-04\t t=2s \tloss=0.6603\tval_loss=0.6513\tcorr=0.3630\n",
      "Epoch 20/300 \t lr=6.7e-04\t t=2s \tloss=0.4248\tval_loss=0.4087\tcorr=0.5998\n",
      "Epoch 30/300 \t lr=1.0e-03\t t=3s \tloss=0.3354\tval_loss=0.3302\tcorr=0.6794\n",
      "Epoch 40/300 \t lr=9.6e-04\t t=4s \tloss=0.2838\tval_loss=0.2890\tcorr=0.7217\n",
      "Epoch 50/300 \t lr=9.3e-04\t t=3s \tloss=0.2333\tval_loss=0.2568\tcorr=0.7504\n",
      "Epoch 60/300 \t lr=8.9e-04\t t=1s \tloss=0.2016\tval_loss=0.2209\tcorr=0.7855\n",
      "Epoch 70/300 \t lr=8.5e-04\t t=1s \tloss=0.1950\tval_loss=0.2221\tcorr=0.7814\n",
      "Epoch 80/300 \t lr=8.1e-04\t t=1s \tloss=0.1901\tval_loss=0.2266\tcorr=0.7766\n",
      "Epoch 90/300 \t lr=7.8e-04\t t=1s \tloss=0.1882\tval_loss=0.2361\tcorr=0.7659\n",
      "Epoch 100/300 \t lr=7.4e-04\t t=1s \tloss=0.1842\tval_loss=0.2306\tcorr=0.7695\n",
      "Epoch 110/300 \t lr=7.0e-04\t t=1s \tloss=0.1776\tval_loss=0.2363\tcorr=0.7692\n",
      "Epoch 120/300 \t lr=6.7e-04\t t=1s \tloss=0.1730\tval_loss=0.2372\tcorr=0.7772\n",
      "Epoch 130/300 \t lr=6.3e-04\t t=1s \tloss=0.1640\tval_loss=0.2512\tcorr=0.7696\n",
      "Epoch 140/300 \t lr=5.9e-04\t t=1s \tloss=0.1607\tval_loss=0.2654\tcorr=0.7653\n",
      "Epoch 150/300 \t lr=5.6e-04\t t=1s \tloss=0.1452\tval_loss=0.2794\tcorr=0.7609\n",
      "Epoch 160/300 \t lr=5.2e-04\t t=1s \tloss=0.1306\tval_loss=0.3070\tcorr=0.7556\n",
      "Epoch 170/300 \t lr=4.8e-04\t t=1s \tloss=0.1180\tval_loss=0.3604\tcorr=0.7521\n",
      "Epoch 180/300 \t lr=4.4e-04\t t=1s \tloss=0.1034\tval_loss=0.3837\tcorr=0.7570\n",
      "Epoch 190/300 \t lr=4.1e-04\t t=1s \tloss=0.0970\tval_loss=0.4465\tcorr=0.7522\n",
      "Epoch 200/300 \t lr=3.7e-04\t t=1s \tloss=0.0786\tval_loss=0.4764\tcorr=0.7524\n",
      "Epoch 210/300 \t lr=3.3e-04\t t=1s \tloss=0.0662\tval_loss=0.5459\tcorr=0.7512\n",
      "Epoch 220/300 \t lr=3.0e-04\t t=1s \tloss=0.0567\tval_loss=0.6320\tcorr=0.7494\n",
      "Epoch 230/300 \t lr=2.6e-04\t t=1s \tloss=0.0519\tval_loss=0.7015\tcorr=0.7470\n",
      "Epoch 240/300 \t lr=2.2e-04\t t=1s \tloss=0.0436\tval_loss=0.7603\tcorr=0.7456\n",
      "Epoch 250/300 \t lr=1.9e-04\t t=1s \tloss=0.0384\tval_loss=0.8296\tcorr=0.7436\n",
      "Epoch 260/300 \t lr=1.5e-04\t t=1s \tloss=0.0344\tval_loss=0.8931\tcorr=0.7435\n",
      "Epoch 270/300 \t lr=1.1e-04\t t=1s \tloss=0.0314\tval_loss=0.9436\tcorr=0.7425\n",
      "Epoch 280/300 \t lr=7.4e-05\t t=1s \tloss=0.0293\tval_loss=0.9807\tcorr=0.7423\n",
      "Epoch 290/300 \t lr=3.7e-05\t t=1s \tloss=0.0280\tval_loss=1.0042\tcorr=0.7420\n",
      "Epoch 300/300 \t lr=0.0e+00\t t=1s \tloss=0.0275\tval_loss=1.0132\tcorr=0.7419\n",
      "[0.31232323232323234, 0.8533333333333334, 0.9054545454545456, 0.9632323232323234, 0.9131313131313133, 0.7155555555555557, 0.9252525252525253, 0.7979797979797981] \n",
      "\n",
      "\n",
      "FOLD 3\n",
      "train size: 400, val size: 100\n",
      "Model parameters count: 102162440\n",
      "train batch num: 1\n",
      "val batch num: 1\n",
      "optim: Adam, lr: 0.001, warmup_steps: 30\n",
      "Epoch 10/300 \t lr=3.3e-04\t t=3s \tloss=0.6619\tval_loss=0.6441\tcorr=0.4365\n",
      "Epoch 20/300 \t lr=6.7e-04\t t=1s \tloss=0.4191\tval_loss=0.4606\tcorr=0.5295\n",
      "Epoch 30/300 \t lr=1.0e-03\t t=3s \tloss=0.3278\tval_loss=0.3769\tcorr=0.6189\n",
      "Epoch 40/300 \t lr=9.6e-04\t t=4s \tloss=0.2773\tval_loss=0.3261\tcorr=0.6750\n",
      "Epoch 50/300 \t lr=9.3e-04\t t=4s \tloss=0.2234\tval_loss=0.2681\tcorr=0.7364\n",
      "Epoch 60/300 \t lr=8.9e-04\t t=2s \tloss=0.1993\tval_loss=0.2567\tcorr=0.7537\n",
      "Epoch 70/300 \t lr=8.5e-04\t t=1s \tloss=0.1891\tval_loss=0.2483\tcorr=0.7608\n",
      "Epoch 80/300 \t lr=8.1e-04\t t=4s \tloss=0.1840\tval_loss=0.2472\tcorr=0.7643\n",
      "Epoch 90/300 \t lr=7.8e-04\t t=1s \tloss=0.1851\tval_loss=0.2575\tcorr=0.7572\n",
      "Epoch 100/300 \t lr=7.4e-04\t t=1s \tloss=0.1745\tval_loss=0.2599\tcorr=0.7561\n",
      "Epoch 110/300 \t lr=7.0e-04\t t=1s \tloss=0.1707\tval_loss=0.2738\tcorr=0.7478\n",
      "Epoch 120/300 \t lr=6.7e-04\t t=1s \tloss=0.1598\tval_loss=0.2791\tcorr=0.7476\n",
      "Epoch 130/300 \t lr=6.3e-04\t t=1s \tloss=0.1521\tval_loss=0.2995\tcorr=0.7408\n",
      "Epoch 140/300 \t lr=5.9e-04\t t=1s \tloss=0.1424\tval_loss=0.3264\tcorr=0.7325\n",
      "Epoch 150/300 \t lr=5.6e-04\t t=1s \tloss=0.1287\tval_loss=0.3537\tcorr=0.7321\n",
      "Epoch 160/300 \t lr=5.2e-04\t t=1s \tloss=0.1160\tval_loss=0.3811\tcorr=0.7307\n",
      "Epoch 170/300 \t lr=4.8e-04\t t=1s \tloss=0.1011\tval_loss=0.4257\tcorr=0.7286\n",
      "Epoch 180/300 \t lr=4.4e-04\t t=1s \tloss=0.0897\tval_loss=0.4844\tcorr=0.7243\n",
      "Epoch 190/300 \t lr=4.1e-04\t t=1s \tloss=0.0779\tval_loss=0.5577\tcorr=0.7242\n",
      "Epoch 200/300 \t lr=3.7e-04\t t=1s \tloss=0.0654\tval_loss=0.6334\tcorr=0.7248\n",
      "Epoch 210/300 \t lr=3.3e-04\t t=1s \tloss=0.0597\tval_loss=0.7120\tcorr=0.7194\n",
      "Epoch 220/300 \t lr=3.0e-04\t t=1s \tloss=0.0499\tval_loss=0.7773\tcorr=0.7219\n",
      "Epoch 230/300 \t lr=2.6e-04\t t=1s \tloss=0.0431\tval_loss=0.8636\tcorr=0.7201\n",
      "Epoch 240/300 \t lr=2.2e-04\t t=1s \tloss=0.0374\tval_loss=0.9453\tcorr=0.7206\n",
      "Epoch 250/300 \t lr=1.9e-04\t t=1s \tloss=0.0332\tval_loss=1.0233\tcorr=0.7200\n",
      "Epoch 260/300 \t lr=1.5e-04\t t=1s \tloss=0.0297\tval_loss=1.0896\tcorr=0.7197\n",
      "Epoch 270/300 \t lr=1.1e-04\t t=1s \tloss=0.0271\tval_loss=1.1467\tcorr=0.7192\n",
      "Epoch 280/300 \t lr=7.4e-05\t t=1s \tloss=0.0253\tval_loss=1.1906\tcorr=0.7191\n",
      "Epoch 290/300 \t lr=3.7e-05\t t=1s \tloss=0.0242\tval_loss=1.2174\tcorr=0.7193\n",
      "Epoch 300/300 \t lr=0.0e+00\t t=1s \tloss=0.0238\tval_loss=1.2273\tcorr=0.7198\n",
      "[0.24323232323232327, 0.880808080808081, 0.8965656565656567, 0.9664646464646466, 0.8880808080808081, 0.6020202020202021, 0.9103030303030304, 0.7834343434343436] \n",
      "\n",
      "\n",
      "FOLD 4\n",
      "train size: 400, val size: 100\n",
      "Model parameters count: 102162440\n",
      "train batch num: 1\n",
      "val batch num: 1\n",
      "optim: Adam, lr: 0.001, warmup_steps: 30\n",
      "Epoch 10/300 \t lr=3.3e-04\t t=1s \tloss=0.6596\tval_loss=0.6329\tcorr=0.4605\n",
      "Epoch 20/300 \t lr=6.7e-04\t t=4s \tloss=0.4151\tval_loss=0.4133\tcorr=0.5892\n",
      "Epoch 30/300 \t lr=1.0e-03\t t=2s \tloss=0.3266\tval_loss=0.3357\tcorr=0.6717\n",
      "Epoch 40/300 \t lr=9.6e-04\t t=4s \tloss=0.2780\tval_loss=0.2915\tcorr=0.7191\n",
      "Epoch 50/300 \t lr=9.3e-04\t t=2s \tloss=0.2189\tval_loss=0.2402\tcorr=0.7655\n",
      "Epoch 60/300 \t lr=8.9e-04\t t=3s \tloss=0.2023\tval_loss=0.2186\tcorr=0.7842\n",
      "Epoch 70/300 \t lr=8.5e-04\t t=1s \tloss=0.1879\tval_loss=0.2165\tcorr=0.7876\n",
      "Epoch 80/300 \t lr=8.1e-04\t t=1s \tloss=0.1798\tval_loss=0.2175\tcorr=0.7867\n",
      "Epoch 90/300 \t lr=7.8e-04\t t=1s \tloss=0.1731\tval_loss=0.2289\tcorr=0.7816\n",
      "Epoch 100/300 \t lr=7.4e-04\t t=1s \tloss=0.1606\tval_loss=0.2431\tcorr=0.7736\n",
      "Epoch 110/300 \t lr=7.0e-04\t t=1s \tloss=0.1431\tval_loss=0.2591\tcorr=0.7693\n",
      "Epoch 120/300 \t lr=6.7e-04\t t=1s \tloss=0.1284\tval_loss=0.2892\tcorr=0.7629\n",
      "Epoch 130/300 \t lr=6.3e-04\t t=1s \tloss=0.1126\tval_loss=0.3316\tcorr=0.7603\n",
      "Epoch 140/300 \t lr=5.9e-04\t t=1s \tloss=0.0985\tval_loss=0.3798\tcorr=0.7615\n",
      "Epoch 150/300 \t lr=5.6e-04\t t=1s \tloss=0.0816\tval_loss=0.4280\tcorr=0.7605\n",
      "Epoch 160/300 \t lr=5.2e-04\t t=1s \tloss=0.0700\tval_loss=0.4996\tcorr=0.7611\n",
      "Epoch 170/300 \t lr=4.8e-04\t t=1s \tloss=0.0568\tval_loss=0.5769\tcorr=0.7630\n",
      "Epoch 180/300 \t lr=4.4e-04\t t=1s \tloss=0.0484\tval_loss=0.6643\tcorr=0.7628\n",
      "Epoch 190/300 \t lr=4.1e-04\t t=1s \tloss=0.0386\tval_loss=0.7600\tcorr=0.7598\n",
      "Epoch 200/300 \t lr=3.7e-04\t t=1s \tloss=0.0318\tval_loss=0.8677\tcorr=0.7583\n",
      "Epoch 210/300 \t lr=3.3e-04\t t=1s \tloss=0.0276\tval_loss=0.9596\tcorr=0.7606\n",
      "Epoch 220/300 \t lr=3.0e-04\t t=1s \tloss=0.0223\tval_loss=1.0562\tcorr=0.7584\n",
      "Epoch 230/300 \t lr=2.6e-04\t t=1s \tloss=0.0195\tval_loss=1.1488\tcorr=0.7596\n",
      "Epoch 240/300 \t lr=2.2e-04\t t=1s \tloss=0.0172\tval_loss=1.2322\tcorr=0.7591\n",
      "Epoch 250/300 \t lr=1.9e-04\t t=1s \tloss=0.0156\tval_loss=1.3059\tcorr=0.7593\n",
      "Epoch 260/300 \t lr=1.5e-04\t t=1s \tloss=0.0144\tval_loss=1.3676\tcorr=0.7592\n",
      "Epoch 270/300 \t lr=1.1e-04\t t=1s \tloss=0.0136\tval_loss=1.4169\tcorr=0.7591\n",
      "Epoch 280/300 \t lr=7.4e-05\t t=1s \tloss=0.0130\tval_loss=1.4533\tcorr=0.7592\n",
      "Epoch 290/300 \t lr=3.7e-05\t t=1s \tloss=0.0127\tval_loss=1.4752\tcorr=0.7592\n",
      "Epoch 300/300 \t lr=0.0e+00\t t=1s \tloss=0.0126\tval_loss=1.4831\tcorr=0.7593\n",
      "[0.3272727272727273, 0.8565656565656566, 0.9212121212121214, 0.9692929292929294, 0.9103030303030304, 0.7050505050505051, 0.9321212121212122, 0.8072727272727275] \n",
      "\n",
      "\n",
      "0.79222 [0.29842, 0.87402, 0.90667, 0.96493, 0.89956, 0.6703, 0.92105, 0.80283]\n"
     ]
    }
   ],
   "source": [
    "# K折训练，同时\n",
    "seed = 666\n",
    "BATCH_SIZE = 400\n",
    "BATCH_SIZE_TEST = 128\n",
    "EPOCHS = 300\n",
    "LR = 0.001\n",
    "optim = \"Adam\"\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "modelpath = r'./model'+'//'\n",
    "\n",
    "loss_fct = CVPRLoss_pair()\n",
    "k=5\n",
    "scoref = []\n",
    "skf = KFold(n_splits=k, shuffle=False)\n",
    "for index, (train_index, test_index) in enumerate(skf.split(train_df)):   \n",
    "    print(f'FOLD {index}')\n",
    "    train0 = train_df.iloc[train_index]\n",
    "    val0 = train_df.iloc[test_index]   \n",
    "    train_dataset = MyDataset(train0, use_cols, target_cols)\n",
    "    val_dataset = MyDataset(val0, use_cols, target_cols)\n",
    "    print(f'train size: {len(train0)}, val size: {len(val0)}')\n",
    "\n",
    "    modelname = f'CVPR_2022_lstm2y_catall_pair_sig'\n",
    "    seed_everything(seed)\n",
    "    model = CVPRModel(input_dim=1,\n",
    "                    num_classes=8,\n",
    "                    bi=True,\n",
    "                    time_step=37\n",
    "                   ).to(device)\n",
    "\n",
    "    _ = train_sig(model, \n",
    "                train_dataset, \n",
    "                val_dataset, \n",
    "                verbose=10, \n",
    "                fold_=index,\n",
    "                modelname=modelname,\n",
    "                modelpath=modelpath,\n",
    "                input='input',\n",
    "                y='y',\n",
    "                debug=False\n",
    "                 )\n",
    "    scoref.append(_)\n",
    "scoreff = scoref\n",
    "print(np.round(np.array(scoreff).mean(1).mean(), 5), [round(x, 5) for x in np.array(scoreff).mean(0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#加载test\n",
    "with open('./data/CVPR_2022_NAS_Track2_test.json', 'r') as f:\n",
    "    test_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = get_df(test_data)\n",
    "get_step(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_cuda(test_df, model):\n",
    "    #获得预测\n",
    "    test_dataset = MyDataset(test_df, use_cols, target_cols, 0)\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=1024*8,\n",
    "        shuffle=False,\n",
    "        drop_last=False,\n",
    "        pin_memory=True\n",
    "    )\n",
    "\n",
    "    preds = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for data in tqdm(test_loader):\n",
    "            pred = model(data['input'].to(device))\n",
    "            preds.append(pred.detach().cpu().numpy())\n",
    "    preds = np.concatenate(preds, 0)\n",
    "    print(preds.shape)\n",
    "\n",
    "    del test_dataset, test_loader, model;\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    return preds\n",
    "        \n",
    "def predict_sig(test_df, k=5, modelname=''):\n",
    "    for target in range(8):        \n",
    "        cols = []\n",
    "        for fold_ in range(k):\n",
    "            modelname1 = f'{modelname}_target{target}_{fold_}.pt'\n",
    "            print(f'Model {modelname1}')\n",
    "            model = CVPRModel(input_dim=1,\n",
    "                        num_classes=8,\n",
    "                        bi=True,\n",
    "                        time_step=37\n",
    "                       ).to(device)\n",
    "            model.load_state_dict(torch.load(modelpath+modelname1))\n",
    "\n",
    "            pred_ = pred_cuda(test_df, model)[:, target]\n",
    "            tmp_c = f'{target_cols[target]}_{fold_}'\n",
    "            test_df[tmp_c] = pred_\n",
    "            cols.append(tmp_c)\n",
    "            print(f'Done {tmp_c}')\n",
    "            \n",
    "        print(cols)\n",
    "        test_df[cols] = test_df[cols].rank()\n",
    "        test_df[target_cols[target]] = test_df[cols].mean(axis=1).rank()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 'CVPR_2022_lstm2y_catall_pair_sig')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k, modelname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model CVPR_2022_lstm2y_catall_pair_sig_target0_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 13/13 [00:09<00:00,  1.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(99500, 8)\n",
      "Done cplfw_rank_0\n",
      "Model CVPR_2022_lstm2y_catall_pair_sig_target0_1.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 13/13 [00:08<00:00,  1.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(99500, 8)\n",
      "Done cplfw_rank_1\n",
      "Model CVPR_2022_lstm2y_catall_pair_sig_target0_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 13/13 [00:08<00:00,  1.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(99500, 8)\n",
      "Done cplfw_rank_2\n",
      "Model CVPR_2022_lstm2y_catall_pair_sig_target0_3.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 13/13 [00:08<00:00,  1.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(99500, 8)\n",
      "Done cplfw_rank_3\n",
      "Model CVPR_2022_lstm2y_catall_pair_sig_target0_4.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 13/13 [00:08<00:00,  1.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(99500, 8)\n",
      "Done cplfw_rank_4\n",
      "['cplfw_rank_0', 'cplfw_rank_1', 'cplfw_rank_2', 'cplfw_rank_3', 'cplfw_rank_4']\n",
      "Model CVPR_2022_lstm2y_catall_pair_sig_target1_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 13/13 [00:08<00:00,  1.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(99500, 8)\n",
      "Done market1501_rank_0\n",
      "Model CVPR_2022_lstm2y_catall_pair_sig_target1_1.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 13/13 [00:08<00:00,  1.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(99500, 8)\n",
      "Done market1501_rank_1\n",
      "Model CVPR_2022_lstm2y_catall_pair_sig_target1_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 13/13 [00:08<00:00,  1.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(99500, 8)\n",
      "Done market1501_rank_2\n",
      "Model CVPR_2022_lstm2y_catall_pair_sig_target1_3.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 13/13 [00:08<00:00,  1.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(99500, 8)\n",
      "Done market1501_rank_3\n",
      "Model CVPR_2022_lstm2y_catall_pair_sig_target1_4.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 13/13 [00:08<00:00,  1.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(99500, 8)\n",
      "Done market1501_rank_4\n",
      "['market1501_rank_0', 'market1501_rank_1', 'market1501_rank_2', 'market1501_rank_3', 'market1501_rank_4']\n",
      "Model CVPR_2022_lstm2y_catall_pair_sig_target2_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 13/13 [00:08<00:00,  1.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(99500, 8)\n",
      "Done dukemtmc_rank_0\n",
      "Model CVPR_2022_lstm2y_catall_pair_sig_target2_1.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 13/13 [00:08<00:00,  1.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(99500, 8)\n",
      "Done dukemtmc_rank_1\n",
      "Model CVPR_2022_lstm2y_catall_pair_sig_target2_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 13/13 [00:08<00:00,  1.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(99500, 8)\n",
      "Done dukemtmc_rank_2\n",
      "Model CVPR_2022_lstm2y_catall_pair_sig_target2_3.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 13/13 [00:08<00:00,  1.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(99500, 8)\n",
      "Done dukemtmc_rank_3\n",
      "Model CVPR_2022_lstm2y_catall_pair_sig_target2_4.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 13/13 [00:08<00:00,  1.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(99500, 8)\n",
      "Done dukemtmc_rank_4\n",
      "['dukemtmc_rank_0', 'dukemtmc_rank_1', 'dukemtmc_rank_2', 'dukemtmc_rank_3', 'dukemtmc_rank_4']\n",
      "Model CVPR_2022_lstm2y_catall_pair_sig_target3_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 13/13 [00:08<00:00,  1.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(99500, 8)\n",
      "Done msmt17_rank_0\n",
      "Model CVPR_2022_lstm2y_catall_pair_sig_target3_1.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 13/13 [00:08<00:00,  1.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(99500, 8)\n",
      "Done msmt17_rank_1\n",
      "Model CVPR_2022_lstm2y_catall_pair_sig_target3_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 13/13 [00:08<00:00,  1.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(99500, 8)\n",
      "Done msmt17_rank_2\n",
      "Model CVPR_2022_lstm2y_catall_pair_sig_target3_3.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 13/13 [00:08<00:00,  1.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(99500, 8)\n",
      "Done msmt17_rank_3\n",
      "Model CVPR_2022_lstm2y_catall_pair_sig_target3_4.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 13/13 [00:08<00:00,  1.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(99500, 8)\n",
      "Done msmt17_rank_4\n",
      "['msmt17_rank_0', 'msmt17_rank_1', 'msmt17_rank_2', 'msmt17_rank_3', 'msmt17_rank_4']\n",
      "Model CVPR_2022_lstm2y_catall_pair_sig_target4_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 13/13 [00:08<00:00,  1.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(99500, 8)\n",
      "Done veri_rank_0\n",
      "Model CVPR_2022_lstm2y_catall_pair_sig_target4_1.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 13/13 [00:08<00:00,  1.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(99500, 8)\n",
      "Done veri_rank_1\n",
      "Model CVPR_2022_lstm2y_catall_pair_sig_target4_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 13/13 [00:08<00:00,  1.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(99500, 8)\n",
      "Done veri_rank_2\n",
      "Model CVPR_2022_lstm2y_catall_pair_sig_target4_3.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 13/13 [00:08<00:00,  1.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(99500, 8)\n",
      "Done veri_rank_3\n",
      "Model CVPR_2022_lstm2y_catall_pair_sig_target4_4.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 13/13 [00:08<00:00,  1.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(99500, 8)\n",
      "Done veri_rank_4\n",
      "['veri_rank_0', 'veri_rank_1', 'veri_rank_2', 'veri_rank_3', 'veri_rank_4']\n",
      "Model CVPR_2022_lstm2y_catall_pair_sig_target5_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 13/13 [00:08<00:00,  1.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(99500, 8)\n",
      "Done vehicleid_rank_0\n",
      "Model CVPR_2022_lstm2y_catall_pair_sig_target5_1.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 13/13 [00:08<00:00,  1.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(99500, 8)\n",
      "Done vehicleid_rank_1\n",
      "Model CVPR_2022_lstm2y_catall_pair_sig_target5_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 13/13 [00:08<00:00,  1.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(99500, 8)\n",
      "Done vehicleid_rank_2\n",
      "Model CVPR_2022_lstm2y_catall_pair_sig_target5_3.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 13/13 [00:08<00:00,  1.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(99500, 8)\n",
      "Done vehicleid_rank_3\n",
      "Model CVPR_2022_lstm2y_catall_pair_sig_target5_4.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 13/13 [00:08<00:00,  1.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(99500, 8)\n",
      "Done vehicleid_rank_4\n",
      "['vehicleid_rank_0', 'vehicleid_rank_1', 'vehicleid_rank_2', 'vehicleid_rank_3', 'vehicleid_rank_4']\n",
      "Model CVPR_2022_lstm2y_catall_pair_sig_target6_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 13/13 [00:08<00:00,  1.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(99500, 8)\n",
      "Done veriwild_rank_0\n",
      "Model CVPR_2022_lstm2y_catall_pair_sig_target6_1.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 13/13 [00:08<00:00,  1.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(99500, 8)\n",
      "Done veriwild_rank_1\n",
      "Model CVPR_2022_lstm2y_catall_pair_sig_target6_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 13/13 [00:08<00:00,  1.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(99500, 8)\n",
      "Done veriwild_rank_2\n",
      "Model CVPR_2022_lstm2y_catall_pair_sig_target6_3.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 13/13 [00:08<00:00,  1.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(99500, 8)\n",
      "Done veriwild_rank_3\n",
      "Model CVPR_2022_lstm2y_catall_pair_sig_target6_4.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 13/13 [00:08<00:00,  1.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(99500, 8)\n",
      "Done veriwild_rank_4\n",
      "['veriwild_rank_0', 'veriwild_rank_1', 'veriwild_rank_2', 'veriwild_rank_3', 'veriwild_rank_4']\n",
      "Model CVPR_2022_lstm2y_catall_pair_sig_target7_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 13/13 [00:08<00:00,  1.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(99500, 8)\n",
      "Done sop_rank_0\n",
      "Model CVPR_2022_lstm2y_catall_pair_sig_target7_1.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 13/13 [00:08<00:00,  1.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(99500, 8)\n",
      "Done sop_rank_1\n",
      "Model CVPR_2022_lstm2y_catall_pair_sig_target7_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 13/13 [00:08<00:00,  1.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(99500, 8)\n",
      "Done sop_rank_2\n",
      "Model CVPR_2022_lstm2y_catall_pair_sig_target7_3.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 13/13 [00:08<00:00,  1.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(99500, 8)\n",
      "Done sop_rank_3\n",
      "Model CVPR_2022_lstm2y_catall_pair_sig_target7_4.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 13/13 [00:08<00:00,  1.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(99500, 8)\n",
      "Done sop_rank_4\n",
      "['sop_rank_0', 'sop_rank_1', 'sop_rank_2', 'sop_rank_3', 'sop_rank_4']\n"
     ]
    }
   ],
   "source": [
    "predict_sig(test_df, k=5, modelname='CVPR_2022_lstm2y_catall_pair_sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df[target_cols] = test_df[target_cols].astype(int)-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cplfw_rank</th>\n",
       "      <th>market1501_rank</th>\n",
       "      <th>dukemtmc_rank</th>\n",
       "      <th>msmt17_rank</th>\n",
       "      <th>veri_rank</th>\n",
       "      <th>vehicleid_rank</th>\n",
       "      <th>veriwild_rank</th>\n",
       "      <th>sop_rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>99500.00000</td>\n",
       "      <td>99500.000000</td>\n",
       "      <td>99500.000000</td>\n",
       "      <td>99500.00000</td>\n",
       "      <td>99500.000000</td>\n",
       "      <td>99500.000000</td>\n",
       "      <td>99500.000000</td>\n",
       "      <td>99500.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>49749.42206</td>\n",
       "      <td>49749.428794</td>\n",
       "      <td>49749.428663</td>\n",
       "      <td>49749.42601</td>\n",
       "      <td>49749.430593</td>\n",
       "      <td>49749.430241</td>\n",
       "      <td>49749.435015</td>\n",
       "      <td>49749.425518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>28723.31971</td>\n",
       "      <td>28723.320054</td>\n",
       "      <td>28723.321037</td>\n",
       "      <td>28723.31993</td>\n",
       "      <td>28723.322594</td>\n",
       "      <td>28723.320378</td>\n",
       "      <td>28723.320590</td>\n",
       "      <td>28723.322126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>24874.00000</td>\n",
       "      <td>24874.750000</td>\n",
       "      <td>24874.750000</td>\n",
       "      <td>24874.75000</td>\n",
       "      <td>24874.750000</td>\n",
       "      <td>24874.750000</td>\n",
       "      <td>24874.750000</td>\n",
       "      <td>24874.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>49749.50000</td>\n",
       "      <td>49749.500000</td>\n",
       "      <td>49749.500000</td>\n",
       "      <td>49749.00000</td>\n",
       "      <td>49749.000000</td>\n",
       "      <td>49749.500000</td>\n",
       "      <td>49749.500000</td>\n",
       "      <td>49749.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>74624.25000</td>\n",
       "      <td>74624.250000</td>\n",
       "      <td>74624.250000</td>\n",
       "      <td>74624.25000</td>\n",
       "      <td>74624.250000</td>\n",
       "      <td>74624.250000</td>\n",
       "      <td>74624.250000</td>\n",
       "      <td>74624.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>99499.00000</td>\n",
       "      <td>99499.000000</td>\n",
       "      <td>99499.000000</td>\n",
       "      <td>99499.00000</td>\n",
       "      <td>99499.000000</td>\n",
       "      <td>99499.000000</td>\n",
       "      <td>99499.000000</td>\n",
       "      <td>99499.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        cplfw_rank  market1501_rank  dukemtmc_rank  msmt17_rank     veri_rank  \\\n",
       "count  99500.00000     99500.000000   99500.000000  99500.00000  99500.000000   \n",
       "mean   49749.42206     49749.428794   49749.428663  49749.42601  49749.430593   \n",
       "std    28723.31971     28723.320054   28723.321037  28723.31993  28723.322594   \n",
       "min        0.00000         0.000000       0.000000      0.00000      0.000000   \n",
       "25%    24874.00000     24874.750000   24874.750000  24874.75000  24874.750000   \n",
       "50%    49749.50000     49749.500000   49749.500000  49749.00000  49749.000000   \n",
       "75%    74624.25000     74624.250000   74624.250000  74624.25000  74624.250000   \n",
       "max    99499.00000     99499.000000   99499.000000  99499.00000  99499.000000   \n",
       "\n",
       "       vehicleid_rank  veriwild_rank      sop_rank  \n",
       "count    99500.000000   99500.000000  99500.000000  \n",
       "mean     49749.430241   49749.435015  49749.425518  \n",
       "std      28723.320378   28723.320590  28723.322126  \n",
       "min          0.000000       0.000000      0.000000  \n",
       "25%      24874.750000   24874.750000  24874.750000  \n",
       "50%      49749.500000   49749.500000  49749.500000  \n",
       "75%      74624.250000   74624.250000  74624.250000  \n",
       "max      99499.000000   99499.000000  99499.000000  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df[target_cols].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cplfw_rank         90650\n",
       "market1501_rank    91532\n",
       "dukemtmc_rank      91534\n",
       "msmt17_rank        91261\n",
       "veri_rank          91798\n",
       "vehicleid_rank     91757\n",
       "veriwild_rank      92238\n",
       "sop_rank           91211\n",
       "dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df[target_cols].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CVPR_2022_lstm2y_catall_pair_sig'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to_sub\n",
    "def to_sub(test_df, test_data, name='CVPR_2022_lgb_score'):\n",
    "    for i in tqdm(test_df[['id']+target_cols].values):\n",
    "        id_ = i[0]\n",
    "        for k,v in enumerate(target_cols):\n",
    "            k += 1\n",
    "            test_data[id_][v] = i[k]\n",
    "            \n",
    "    with open(f'./sub/{name}.json', 'w') as f:\n",
    "        json.dump(test_data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 99500/99500 [00:00<00:00, 715146.86it/s]\n"
     ]
    }
   ],
   "source": [
    "to_sub(test_df, test_data, name='CVPR_2022_lstm2y_catall_pair_sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
