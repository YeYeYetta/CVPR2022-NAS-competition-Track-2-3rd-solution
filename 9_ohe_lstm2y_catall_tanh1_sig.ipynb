{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('./data/CVPR_2022_NAS_Track2_train.json', 'r') as f:\n",
    "    train_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_cols = ['cplfw_rank', 'market1501_rank', 'dukemtmc_rank', 'msmt17_rank', 'veri_rank', 'vehicleid_rank', 'veriwild_rank', 'sop_rank']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df(train_data):\n",
    "    ret = []\n",
    "    for k, v in train_data.items():\n",
    "        tmp = list(v['arch'])\n",
    "        tmp1 = []\n",
    "        for c in target_cols:\n",
    "            tmp1.append(v[c])\n",
    "        ret.append(tmp+tmp1+[k,v['arch']])\n",
    "    retf = pd.DataFrame(ret,columns=[f'col{_}' for _ in range(len(tmp))]+target_cols+['id','arch'])\n",
    "    retf['col0'] = retf['col0'].map({'l':1, 'j':2, 'k':3})\n",
    "    int_cols = [x for x in retf.columns if x not in ['id','arch']]\n",
    "    retf[int_cols] = retf[int_cols].astype(float)\n",
    "    return retf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = get_df(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import erfinv \n",
    "\n",
    "for c in target_cols:\n",
    "    train_y=train_df[c]\n",
    "    mmin=np.min(train_y)+1\n",
    "    mmax=np.max(train_y)+1\n",
    "    train_y=np.sqrt(2) * erfinv(2 * (train_y+mmin)/(mmin+mmax)-1)\n",
    "    train_df[c+'_trans_y'] = train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_step(train_df):\n",
    "    res0 = []\n",
    "    res1 = []\n",
    "    res2 = []\n",
    "    res3 = []\n",
    "    res4 = []\n",
    "    map_={'l':1, 'j':2, 'k':3}\n",
    "    time_step=12\n",
    "    head_ = set([1+_*3 for _ in range(12)])\n",
    "    mlp_ = set([2+_*3 for _ in range(12)])\n",
    "    emb_ = set([3+_*3 for _ in range(12)])\n",
    "    depth_ = set([0])\n",
    "    for item in train_df.arch:\n",
    "        ret = np.array(list(item[1:]),dtype=np.float32).reshape(-1,3)\n",
    "        res0.append([1 if x in head_ else 0 for x in range(37)])\n",
    "        res1.append([1 if x in mlp_ else 0 for x in range(37)])\n",
    "        res2.append([1 if x in emb_ else 0 for x in range(37)])\n",
    "        res3.append([1 if x in depth_ else 0 for x in range(37)])\n",
    "        res4.append([map_[item[0]]]+list(np.array(list(item[1:]),dtype=np.float32)))\n",
    "        \n",
    "    train_df['head'] = res0\n",
    "    train_df['mlp'] = res1\n",
    "    train_df['emb'] = res2\n",
    "    train_df['depth'] = res3\n",
    "    train_df['all_emb'] = res4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_step(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base cols len: 37\n",
      "embedding size: 93\n"
     ]
    }
   ],
   "source": [
    "#获取col级别的ohe映射\n",
    "base_cols = [x for x in train_df.columns if x[:3]=='col']\n",
    "print(f'base cols len: {len(base_cols)}')\n",
    "cnt=0\n",
    "emb_map={}\n",
    "for i, c in enumerate(base_cols):\n",
    "    nunique = sorted(train_df[c].unique())\n",
    "    emb_map[i] = {}\n",
    "    for v in nunique:\n",
    "        emb_map[i][v]=cnt\n",
    "        cnt+=1\n",
    "emb_size = 0\n",
    "for k, v in emb_map.items():\n",
    "    emb_size += len(v)\n",
    "print(f'embedding size: {emb_size}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_emb_trans(x, emb_map):\n",
    "    ret=[]\n",
    "    for i, v in enumerate(x):\n",
    "        ret.append(emb_map[i][v])\n",
    "    return ret\n",
    "    \n",
    "def ohe_trans(train_df, emb_map):\n",
    "    train_df['all_emb_vec'] = train_df['all_emb'].map(lambda x: all_emb_trans(x, emb_map))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe_trans(train_df, emb_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义数据\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self,df,use_cols,target_cols,show=0):\n",
    "        self.df = df\n",
    "        self.show = show\n",
    "        self.use_cols = use_cols\n",
    "        self.target_cols = target_cols\n",
    "\n",
    "        self.prepare_data()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "    \n",
    "    def prepare_data(self):\n",
    "        self.y = self.df[self.target_cols].values\n",
    "        self.y0 = self.df[[self.target_cols[0]]].values\n",
    "        self.y1 = self.df[[self.target_cols[1]]].values\n",
    "        self.y2 = self.df[[self.target_cols[2]]].values\n",
    "        self.y3 = self.df[[self.target_cols[3]]].values\n",
    "        self.y4 = self.df[[self.target_cols[4]]].values\n",
    "        self.y5 = self.df[[self.target_cols[5]]].values\n",
    "        self.y6 = self.df[[self.target_cols[6]]].values\n",
    "        self.y7 = self.df[[self.target_cols[7]]].values\n",
    "        \n",
    "        self.inputs = np.array(self.df['all_emb_vec'].tolist())\n",
    "\n",
    "        \n",
    "        if self.show==1:\n",
    "            print('inputs_shape',self.inputs.shape)\n",
    "            print('y_shape',self.y.shape)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        data = {\n",
    "            \"input\": F.one_hot(torch.tensor(self.inputs[idx]).long(), num_classes=emb_size).float(),\n",
    "            \"y\": torch.tensor(self.y[idx], dtype=torch.float),\n",
    "            \"y0\": torch.tensor(self.y0[idx], dtype=torch.float),\n",
    "            \"y1\": torch.tensor(self.y1[idx], dtype=torch.float),\n",
    "            \"y2\": torch.tensor(self.y2[idx], dtype=torch.float),\n",
    "            \"y3\": torch.tensor(self.y3[idx], dtype=torch.float),\n",
    "            \"y4\": torch.tensor(self.y4[idx], dtype=torch.float),\n",
    "            \"y5\": torch.tensor(self.y5[idx], dtype=torch.float),\n",
    "            \"y6\": torch.tensor(self.y6[idx], dtype=torch.float),\n",
    "            \"y7\": torch.tensor(self.y7[idx], dtype=torch.float),\n",
    "        }\n",
    "        \n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cols = [x for x in train_df.columns if 'col' in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(use_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    \n",
    "    \n",
    "def count_parameters(model, all=False):\n",
    "    if all:\n",
    "        return sum(p.numel() for p in model.parameters())\n",
    "    else:\n",
    "        return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "\n",
    "def save_model_weights(model, modelpath, filename):\n",
    "    torch.save(model.state_dict(), modelpath+filename)\n",
    "    return f\"\\n -> Save weights to {modelpath+filename}\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metric(pred, y):\n",
    "    corr = []\n",
    "    if pred.shape[1]>2:\n",
    "        for i in range(8):\n",
    "            corr.append(scipy.stats.stats.kendalltau(pred[:, i], y[:, i])[0])\n",
    "    else:\n",
    "        corr.append(scipy.stats.stats.kendalltau(pred, y)[0])\n",
    "    return np.array(corr)\n",
    "    \n",
    "class CVPRLoss_tanh1(nn.Module):\n",
    "    # kendall tanh\n",
    "    def __call__(self, pred, y):\n",
    "        return 1-torch.cat(\n",
    "            [self.get_score(pred[:,i], y[:,i]).reshape(1) for i in range(y.shape[1])]\n",
    "        ).reshape(1,-1)\n",
    "    \n",
    "    def get_score(self, outputs, labels):\n",
    "        output1 = outputs.unsqueeze(1).repeat(1,outputs.shape[0])\n",
    "        label1 = labels.unsqueeze(1).repeat(1,labels.shape[0])\n",
    "\n",
    "        tmp = ((output1-output1.t())*torch.sign(label1-label1.t())).tanh()\n",
    "        eye_tmp = tmp*torch.eye(tmp.shape[0]).cuda()\n",
    "        new_tmp = tmp - eye_tmp\n",
    "        \n",
    "        loss = torch.sum(new_tmp)/(outputs.shape[0]*(outputs.shape[0]-1))\n",
    "\n",
    "        return loss\n",
    "    \n",
    "class CVPRLoss_tanh(nn.Module):\n",
    "    # kendall tanh\n",
    "    def __call__(self, pred, y):\n",
    "        return 1-torch.cat(\n",
    "            [self.get_score(y[:,i].reshape(1,-1), \n",
    "                           pred[:,i].reshape(1,-1)).reshape(1,-1) for i in range(y.shape[1])]\n",
    "        ).reshape(1, -1)\n",
    "    \n",
    "    def get_score(self, actuals, preds):\n",
    "        sa = actuals.argsort()[0]\n",
    "        tmp = preds.index_select(1, sa.int())[0]\n",
    "        score = torch.cat([((tmp[i:]-tmp[i-1])).tanh() for i in range(1, tmp.shape[0])]).sum()\n",
    "        score1 = score/sum(list(range(1,len(tmp))))\n",
    "        return score1\n",
    "    \n",
    "class CVPRLoss_pair(nn.Module):\n",
    "    def __call__(self, pred, y):\n",
    "        return torch.cat(\n",
    "            [self.pair_loss(pred[:,i], y[:,i]).reshape(1) for i in range(y.shape[1])]\n",
    "        ).reshape(1,-1)\n",
    "    \n",
    "    def pair_loss(self, outputs, labels):\n",
    "        output = outputs.unsqueeze(1)\n",
    "        output1 = output.repeat(1,outputs.shape[0])\n",
    "        label = labels.unsqueeze(1)\n",
    "        label1 = label.repeat(1,labels.shape[0])\n",
    "\n",
    "        tmp = (output1-output1.t())*torch.sign(label1-label1.t())\n",
    "        tmp = torch.log(1+torch.exp(-tmp))\n",
    "        eye_tmp = tmp*torch.eye(len(tmp)).cuda()\n",
    "        new_tmp = tmp - eye_tmp\n",
    "        loss = torch.sum(new_tmp)/(outputs.shape[0]*(outputs.shape[0]-1))\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CVPRModel(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim=3,\n",
    "        num_classes=8,\n",
    "        time_step=12,\n",
    "        bi=True\n",
    "    ):\n",
    "        super(CVPRModel,self).__init__()\n",
    "        \n",
    "        self.bi_num = 2 if bi else 1\n",
    "        self.time_step = time_step\n",
    "        \n",
    "        self.MLP = nn.Sequential(\n",
    "            nn.Linear(input_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 256),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        self.LSTM0 = nn.LSTM(256, 256, \n",
    "                    batch_first=True, \n",
    "                    bidirectional=bi, \n",
    "                    num_layers=1,\n",
    "                    dropout=0)\n",
    "                                 \n",
    "        \n",
    "        self.LSTM1 = nn.LSTM(512, 256, \n",
    "                    batch_first=True, \n",
    "                    bidirectional=bi, \n",
    "                    num_layers=1,\n",
    "                    dropout=0\n",
    "                            )    \n",
    "        \n",
    "        self.Logits = nn.Sequential(\n",
    "            nn.Flatten(start_dim=1),\n",
    "            nn.Linear((512+512+256+93)*self.time_step, 2048),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(2048, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x1 = self.MLP(x)\n",
    "        x2, (h0, c0) = self.LSTM0(x1)\n",
    "        x3, (h1, c1) = self.LSTM1(x2, (h0, c0))\n",
    "\n",
    "        c1 = torch.cat([x3, x2, x1, x], -1)\n",
    "        \n",
    "        pred = self.Logits(c1)\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_sig(model, \n",
    "        train_dataset, \n",
    "        val_dataset, \n",
    "        verbose=20, \n",
    "        fold_=0,\n",
    "        modelname='MLP_base',\n",
    "        modelpath=r'./model'+'//',\n",
    "        input='input',\n",
    "        y='y',\n",
    "        early_stop_round=60,\n",
    "        debug=False):\n",
    "    \n",
    "    print(f'Model parameters count: {count_parameters(model)}')\n",
    "    #数据加载\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=False,\n",
    "        drop_last=True,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=BATCH_SIZE_TEST,\n",
    "        shuffle=False,\n",
    "        drop_last=False,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    print(f'train batch num: {len(train_loader)}')\n",
    "    print(f'val batch num: {len(val_loader)}')\n",
    "            \n",
    "    # Optimizer\n",
    "    optimizer = getattr(torch.optim, optim)(model.parameters(), lr=LR)\n",
    "    # Scheduler\n",
    "    num_warmup_steps = int(0.1 * EPOCHS * len(train_loader))\n",
    "    num_training_steps = int(EPOCHS * len(train_loader))\n",
    "    scheduler = get_linear_schedule_with_warmup(\n",
    "        optimizer, num_warmup_steps, num_training_steps\n",
    "    )\n",
    "    print(f'optim: {optim}, lr: {LR}, warmup_steps: {num_warmup_steps}')\n",
    "    \n",
    "    \n",
    "    #train\n",
    "    bst_epoch={_:0 for _ in range(8)}\n",
    "    score_best={_:0 for _ in range(8)}\n",
    "    first_epoch_eval=0\n",
    "    for epoch in range(EPOCHS):\n",
    "        \n",
    "        model.train()\n",
    "        model.zero_grad()\n",
    "        start_time = time.time()\n",
    "\n",
    "        avg_loss = 0\n",
    "        for data in train_loader:\n",
    "            pred = model(data[input].to(device))\n",
    "#             print(pred.shape,data['y'].shape)\n",
    "\n",
    "            loss = loss_fct(\n",
    "                pred,\n",
    "                data[y].to(device)\n",
    "            ).mean()\n",
    "\n",
    "            loss.backward()\n",
    "            avg_loss += loss.item() / len(train_loader)\n",
    "\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "        #VAL\n",
    "        model.eval()\n",
    "        mae, avg_val_loss = 0, 0\n",
    "        preds = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for data in val_loader:\n",
    "                pred = model(data[input].to(device))\n",
    "\n",
    "                loss = loss_fct(\n",
    "                    pred,\n",
    "                    data[y].to(device)\n",
    "                ).mean()\n",
    "\n",
    "                avg_val_loss += loss.item() / len(val_loader)\n",
    "\n",
    "                preds.append(pred.detach().cpu().numpy())\n",
    "\n",
    "        preds = np.concatenate(preds, 0)\n",
    "        if y=='y':\n",
    "            mae = compute_metric(preds,val_dataset.df[target_cols].values).mean()\n",
    "        else:\n",
    "            mae = compute_metric(preds,val_dataset.df[[target_cols[int(y.replace('y',''))]]].values).mean()\n",
    "        \n",
    "        elapsed_time = time.time() - start_time\n",
    "        if (epoch + 1) % verbose == 0:\n",
    "            elapsed_time = elapsed_time * verbose\n",
    "            lr = scheduler.get_last_lr()[0]\n",
    "    #         lr=LR\n",
    "            print(\n",
    "                f\"Epoch {epoch + 1:02d}/{ EPOCHS:02d} \\t lr={lr:.1e}\\t t={elapsed_time:.0f}s \\t\"\n",
    "                f\"loss={avg_loss:.4f}\",\n",
    "                end=\"\\t\",\n",
    "            )\n",
    "\n",
    "            if (epoch + 1 >= first_epoch_eval) or (epoch + 1 == EPOCHS):\n",
    "                print(f\"val_loss={avg_val_loss:.4f}\\tcorr={mae:.4f}\")\n",
    "            else:\n",
    "                print(\"\")\n",
    "                \n",
    "        #保存最优模型\n",
    "        score1 = compute_metric(preds,val_dataset.df[target_cols].values)\n",
    "        for i in range(8):\n",
    "            if score1[i] > score_best[i]:\n",
    "                bst = save_model_weights(model, modelpath, f'{modelname}_target{i}_{fold_}.pt')\n",
    "                score_best[i] = score1[i]\n",
    "                bst_epoch[i] = epoch\n",
    "#                 print(f'target{i} best score {score_best[i]}, best epoch: {bst_epoch[i]}, {bst} ' )\n",
    "                \n",
    "    bst_list = [score_best[i] for i in range(8)]\n",
    "    print(bst_list,'\\n\\n')\n",
    "    del (val_loader, train_loader, loss, data, pred)\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    return bst_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K折训练，同时\n",
    "seed = 666\n",
    "BATCH_SIZE = 400\n",
    "BATCH_SIZE_TEST = 128\n",
    "EPOCHS = 300\n",
    "LR = 0.001\n",
    "optim = \"Adam\"\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "modelpath = r'./model/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "train size: 400, val size: 100\n",
      "Model parameters count: 109145608\n",
      "train batch num: 1\n",
      "val batch num: 1\n",
      "optim: Adam, lr: 0.001, warmup_steps: 30\n",
      "Epoch 10/300 \t lr=3.3e-04\t t=2s \tloss=0.9928\tval_loss=0.9916\tcorr=0.4314\n",
      "Epoch 20/300 \t lr=6.7e-04\t t=1s \tloss=0.7029\tval_loss=0.7412\tcorr=0.3856\n",
      "Epoch 30/300 \t lr=1.0e-03\t t=3s \tloss=0.4464\tval_loss=0.4801\tcorr=0.5277\n",
      "Epoch 40/300 \t lr=9.6e-04\t t=2s \tloss=0.3709\tval_loss=0.3958\tcorr=0.6046\n",
      "Epoch 50/300 \t lr=9.3e-04\t t=2s \tloss=0.3171\tval_loss=0.3471\tcorr=0.6540\n",
      "Epoch 60/300 \t lr=8.9e-04\t t=2s \tloss=0.2664\tval_loss=0.2936\tcorr=0.7076\n",
      "Epoch 70/300 \t lr=8.5e-04\t t=3s \tloss=0.2464\tval_loss=0.2767\tcorr=0.7249\n",
      "Epoch 80/300 \t lr=8.1e-04\t t=1s \tloss=0.2358\tval_loss=0.2640\tcorr=0.7370\n",
      "Epoch 90/300 \t lr=7.8e-04\t t=3s \tloss=0.2247\tval_loss=0.2513\tcorr=0.7507\n",
      "Epoch 100/300 \t lr=7.4e-04\t t=1s \tloss=0.2156\tval_loss=0.2407\tcorr=0.7603\n",
      "Epoch 110/300 \t lr=7.0e-04\t t=1s \tloss=0.2054\tval_loss=0.2351\tcorr=0.7665\n",
      "Epoch 120/300 \t lr=6.7e-04\t t=2s \tloss=0.1954\tval_loss=0.2246\tcorr=0.7773\n",
      "Epoch 130/300 \t lr=6.3e-04\t t=3s \tloss=0.1864\tval_loss=0.2210\tcorr=0.7796\n",
      "Epoch 140/300 \t lr=5.9e-04\t t=2s \tloss=0.1829\tval_loss=0.2194\tcorr=0.7819\n",
      "Epoch 150/300 \t lr=5.6e-04\t t=1s \tloss=0.1806\tval_loss=0.2191\tcorr=0.7824\n",
      "Epoch 160/300 \t lr=5.2e-04\t t=1s \tloss=0.1784\tval_loss=0.2191\tcorr=0.7813\n",
      "Epoch 170/300 \t lr=4.8e-04\t t=1s \tloss=0.1763\tval_loss=0.2197\tcorr=0.7812\n",
      "Epoch 180/300 \t lr=4.4e-04\t t=1s \tloss=0.1739\tval_loss=0.2211\tcorr=0.7794\n",
      "Epoch 190/300 \t lr=4.1e-04\t t=1s \tloss=0.1712\tval_loss=0.2224\tcorr=0.7784\n",
      "Epoch 200/300 \t lr=3.7e-04\t t=1s \tloss=0.1685\tval_loss=0.2228\tcorr=0.7780\n",
      "Epoch 210/300 \t lr=3.3e-04\t t=1s \tloss=0.1641\tval_loss=0.2236\tcorr=0.7776\n",
      "Epoch 220/300 \t lr=3.0e-04\t t=1s \tloss=0.1585\tval_loss=0.2247\tcorr=0.7765\n",
      "Epoch 230/300 \t lr=2.6e-04\t t=1s \tloss=0.1544\tval_loss=0.2279\tcorr=0.7724\n",
      "Epoch 240/300 \t lr=2.2e-04\t t=1s \tloss=0.1464\tval_loss=0.2293\tcorr=0.7720\n",
      "Epoch 250/300 \t lr=1.9e-04\t t=1s \tloss=0.1416\tval_loss=0.2292\tcorr=0.7714\n",
      "Epoch 260/300 \t lr=1.5e-04\t t=1s \tloss=0.1362\tval_loss=0.2308\tcorr=0.7702\n",
      "Epoch 270/300 \t lr=1.1e-04\t t=1s \tloss=0.1323\tval_loss=0.2307\tcorr=0.7693\n",
      "Epoch 280/300 \t lr=7.4e-05\t t=1s \tloss=0.1290\tval_loss=0.2306\tcorr=0.7701\n",
      "Epoch 290/300 \t lr=3.7e-05\t t=1s \tloss=0.1269\tval_loss=0.2311\tcorr=0.7690\n",
      "Epoch 300/300 \t lr=0.0e+00\t t=1s \tloss=0.1260\tval_loss=0.2312\tcorr=0.7688\n",
      "[0.2763636363636364, 0.8977777777777779, 0.9010101010101011, 0.9575757575757579, 0.8852525252525254, 0.6905050505050506, 0.9179797979797981, 0.7951515151515153] \n",
      "\n",
      "\n",
      "FOLD 1\n",
      "train size: 400, val size: 100\n",
      "Model parameters count: 109145608\n",
      "train batch num: 1\n",
      "val batch num: 1\n",
      "optim: Adam, lr: 0.001, warmup_steps: 30\n",
      "Epoch 10/300 \t lr=3.3e-04\t t=1s \tloss=0.9920\tval_loss=0.9894\tcorr=0.4565\n",
      "Epoch 20/300 \t lr=6.7e-04\t t=3s \tloss=0.7136\tval_loss=0.6531\tcorr=0.4961\n",
      "Epoch 30/300 \t lr=1.0e-03\t t=3s \tloss=0.4459\tval_loss=0.4379\tcorr=0.5665\n",
      "Epoch 40/300 \t lr=9.6e-04\t t=3s \tloss=0.3404\tval_loss=0.3515\tcorr=0.6508\n",
      "Epoch 50/300 \t lr=9.3e-04\t t=2s \tloss=0.2887\tval_loss=0.3281\tcorr=0.6748\n",
      "Epoch 60/300 \t lr=8.9e-04\t t=2s \tloss=0.2580\tval_loss=0.2967\tcorr=0.7064\n",
      "Epoch 70/300 \t lr=8.5e-04\t t=1s \tloss=0.2287\tval_loss=0.2730\tcorr=0.7284\n",
      "Epoch 80/300 \t lr=8.1e-04\t t=2s \tloss=0.2160\tval_loss=0.2617\tcorr=0.7403\n",
      "Epoch 90/300 \t lr=7.8e-04\t t=3s \tloss=0.2091\tval_loss=0.2529\tcorr=0.7479\n",
      "Epoch 100/300 \t lr=7.4e-04\t t=4s \tloss=0.2000\tval_loss=0.2437\tcorr=0.7580\n",
      "Epoch 110/300 \t lr=7.0e-04\t t=4s \tloss=0.1911\tval_loss=0.2348\tcorr=0.7667\n",
      "Epoch 120/300 \t lr=6.7e-04\t t=1s \tloss=0.1837\tval_loss=0.2314\tcorr=0.7703\n",
      "Epoch 130/300 \t lr=6.3e-04\t t=1s \tloss=0.1797\tval_loss=0.2311\tcorr=0.7701\n",
      "Epoch 140/300 \t lr=5.9e-04\t t=1s \tloss=0.1769\tval_loss=0.2296\tcorr=0.7711\n",
      "Epoch 150/300 \t lr=5.6e-04\t t=1s \tloss=0.1748\tval_loss=0.2288\tcorr=0.7725\n",
      "Epoch 160/300 \t lr=5.2e-04\t t=1s \tloss=0.1725\tval_loss=0.2293\tcorr=0.7712\n",
      "Epoch 170/300 \t lr=4.8e-04\t t=1s \tloss=0.1695\tval_loss=0.2297\tcorr=0.7707\n",
      "Epoch 180/300 \t lr=4.4e-04\t t=1s \tloss=0.1670\tval_loss=0.2305\tcorr=0.7697\n",
      "Epoch 190/300 \t lr=4.1e-04\t t=1s \tloss=0.1633\tval_loss=0.2296\tcorr=0.7706\n",
      "Epoch 200/300 \t lr=3.7e-04\t t=1s \tloss=0.1572\tval_loss=0.2283\tcorr=0.7716\n",
      "Epoch 210/300 \t lr=3.3e-04\t t=1s \tloss=0.1519\tval_loss=0.2285\tcorr=0.7731\n",
      "Epoch 220/300 \t lr=3.0e-04\t t=1s \tloss=0.1446\tval_loss=0.2280\tcorr=0.7725\n",
      "Epoch 230/300 \t lr=2.6e-04\t t=1s \tloss=0.1390\tval_loss=0.2288\tcorr=0.7711\n",
      "Epoch 240/300 \t lr=2.2e-04\t t=1s \tloss=0.1342\tval_loss=0.2266\tcorr=0.7739\n",
      "Epoch 250/300 \t lr=1.9e-04\t t=1s \tloss=0.1273\tval_loss=0.2260\tcorr=0.7742\n",
      "Epoch 260/300 \t lr=1.5e-04\t t=1s \tloss=0.1231\tval_loss=0.2267\tcorr=0.7731\n",
      "Epoch 270/300 \t lr=1.1e-04\t t=1s \tloss=0.1182\tval_loss=0.2254\tcorr=0.7751\n",
      "Epoch 280/300 \t lr=7.4e-05\t t=1s \tloss=0.1150\tval_loss=0.2257\tcorr=0.7745\n",
      "Epoch 290/300 \t lr=3.7e-05\t t=1s \tloss=0.1129\tval_loss=0.2253\tcorr=0.7756\n",
      "Epoch 300/300 \t lr=0.0e+00\t t=1s \tloss=0.1121\tval_loss=0.2252\tcorr=0.7757\n",
      "[0.2686868686868687, 0.8775757575757577, 0.9123232323232325, 0.9664646464646466, 0.8941414141414142, 0.6537373737373738, 0.9111111111111113, 0.7967676767676769] \n",
      "\n",
      "\n",
      "FOLD 2\n",
      "train size: 400, val size: 100\n",
      "Model parameters count: 109145608\n",
      "train batch num: 1\n",
      "val batch num: 1\n",
      "optim: Adam, lr: 0.001, warmup_steps: 30\n",
      "Epoch 10/300 \t lr=3.3e-04\t t=3s \tloss=0.9918\tval_loss=0.9923\tcorr=0.3549\n",
      "Epoch 20/300 \t lr=6.7e-04\t t=1s \tloss=0.7160\tval_loss=0.7317\tcorr=0.3348\n",
      "Epoch 30/300 \t lr=1.0e-03\t t=4s \tloss=0.4650\tval_loss=0.4308\tcorr=0.5734\n",
      "Epoch 40/300 \t lr=9.6e-04\t t=3s \tloss=0.3610\tval_loss=0.3466\tcorr=0.6579\n",
      "Epoch 50/300 \t lr=9.3e-04\t t=3s \tloss=0.3094\tval_loss=0.3029\tcorr=0.7003\n",
      "Epoch 60/300 \t lr=8.9e-04\t t=1s \tloss=0.2788\tval_loss=0.2672\tcorr=0.7344\n",
      "Epoch 70/300 \t lr=8.5e-04\t t=3s \tloss=0.2498\tval_loss=0.2562\tcorr=0.7464\n",
      "Epoch 80/300 \t lr=8.1e-04\t t=2s \tloss=0.2285\tval_loss=0.2409\tcorr=0.7628\n",
      "Epoch 90/300 \t lr=7.8e-04\t t=3s \tloss=0.2149\tval_loss=0.2349\tcorr=0.7666\n",
      "Epoch 100/300 \t lr=7.4e-04\t t=2s \tloss=0.1994\tval_loss=0.2260\tcorr=0.7758\n",
      "Epoch 110/300 \t lr=7.0e-04\t t=1s \tloss=0.1872\tval_loss=0.2219\tcorr=0.7810\n",
      "Epoch 120/300 \t lr=6.7e-04\t t=1s \tloss=0.1814\tval_loss=0.2203\tcorr=0.7812\n",
      "Epoch 130/300 \t lr=6.3e-04\t t=1s \tloss=0.1789\tval_loss=0.2208\tcorr=0.7814\n",
      "Epoch 140/300 \t lr=5.9e-04\t t=1s \tloss=0.1751\tval_loss=0.2222\tcorr=0.7780\n",
      "Epoch 150/300 \t lr=5.6e-04\t t=1s \tloss=0.1715\tval_loss=0.2233\tcorr=0.7773\n",
      "Epoch 160/300 \t lr=5.2e-04\t t=1s \tloss=0.1678\tval_loss=0.2251\tcorr=0.7749\n",
      "Epoch 170/300 \t lr=4.8e-04\t t=1s \tloss=0.1636\tval_loss=0.2256\tcorr=0.7755\n",
      "Epoch 180/300 \t lr=4.4e-04\t t=1s \tloss=0.1577\tval_loss=0.2283\tcorr=0.7720\n",
      "Epoch 190/300 \t lr=4.1e-04\t t=1s \tloss=0.1492\tval_loss=0.2278\tcorr=0.7722\n",
      "Epoch 200/300 \t lr=3.7e-04\t t=1s \tloss=0.1415\tval_loss=0.2309\tcorr=0.7699\n",
      "Epoch 210/300 \t lr=3.3e-04\t t=1s \tloss=0.1329\tval_loss=0.2281\tcorr=0.7725\n",
      "Epoch 220/300 \t lr=3.0e-04\t t=1s \tloss=0.1240\tval_loss=0.2315\tcorr=0.7696\n",
      "Epoch 230/300 \t lr=2.6e-04\t t=1s \tloss=0.1144\tval_loss=0.2353\tcorr=0.7649\n",
      "Epoch 240/300 \t lr=2.2e-04\t t=1s \tloss=0.1075\tval_loss=0.2336\tcorr=0.7672\n",
      "Epoch 250/300 \t lr=1.9e-04\t t=1s \tloss=0.1035\tval_loss=0.2350\tcorr=0.7652\n",
      "Epoch 260/300 \t lr=1.5e-04\t t=1s \tloss=0.0982\tval_loss=0.2356\tcorr=0.7651\n",
      "Epoch 270/300 \t lr=1.1e-04\t t=1s \tloss=0.0945\tval_loss=0.2347\tcorr=0.7663\n",
      "Epoch 280/300 \t lr=7.4e-05\t t=1s \tloss=0.0917\tval_loss=0.2346\tcorr=0.7657\n",
      "Epoch 290/300 \t lr=3.7e-05\t t=1s \tloss=0.0897\tval_loss=0.2349\tcorr=0.7649\n",
      "Epoch 300/300 \t lr=0.0e+00\t t=1s \tloss=0.0888\tval_loss=0.2352\tcorr=0.7649\n",
      "[0.2921212121212121, 0.8557575757575759, 0.9010101010101011, 0.9624242424242426, 0.9151515151515153, 0.7462626262626264, 0.9179797979797981, 0.7911111111111112] \n",
      "\n",
      "\n",
      "FOLD 3\n",
      "train size: 400, val size: 100\n",
      "Model parameters count: 109145608\n",
      "train batch num: 1\n",
      "val batch num: 1\n",
      "optim: Adam, lr: 0.001, warmup_steps: 30\n",
      "Epoch 10/300 \t lr=3.3e-04\t t=1s \tloss=0.9923\tval_loss=0.9912\tcorr=0.4209\n",
      "Epoch 20/300 \t lr=6.7e-04\t t=4s \tloss=0.8098\tval_loss=0.7288\tcorr=0.4459\n",
      "Epoch 30/300 \t lr=1.0e-03\t t=4s \tloss=0.4446\tval_loss=0.4790\tcorr=0.5355\n",
      "Epoch 40/300 \t lr=9.6e-04\t t=2s \tloss=0.3602\tval_loss=0.4089\tcorr=0.5928\n",
      "Epoch 50/300 \t lr=9.3e-04\t t=2s \tloss=0.3105\tval_loss=0.3641\tcorr=0.6359\n",
      "Epoch 60/300 \t lr=8.9e-04\t t=2s \tloss=0.2811\tval_loss=0.3409\tcorr=0.6598\n",
      "Epoch 70/300 \t lr=8.5e-04\t t=2s \tloss=0.2525\tval_loss=0.3162\tcorr=0.6851\n",
      "Epoch 80/300 \t lr=8.1e-04\t t=1s \tloss=0.2359\tval_loss=0.3002\tcorr=0.7011\n",
      "Epoch 90/300 \t lr=7.8e-04\t t=1s \tloss=0.2234\tval_loss=0.2866\tcorr=0.7151\n",
      "Epoch 100/300 \t lr=7.4e-04\t t=1s \tloss=0.2084\tval_loss=0.2738\tcorr=0.7284\n",
      "Epoch 110/300 \t lr=7.0e-04\t t=2s \tloss=0.1964\tval_loss=0.2621\tcorr=0.7391\n",
      "Epoch 120/300 \t lr=6.7e-04\t t=1s \tloss=0.1896\tval_loss=0.2574\tcorr=0.7438\n",
      "Epoch 130/300 \t lr=6.3e-04\t t=1s \tloss=0.1828\tval_loss=0.2501\tcorr=0.7512\n",
      "Epoch 140/300 \t lr=5.9e-04\t t=3s \tloss=0.1764\tval_loss=0.2414\tcorr=0.7608\n",
      "Epoch 150/300 \t lr=5.6e-04\t t=1s \tloss=0.1727\tval_loss=0.2415\tcorr=0.7602\n",
      "Epoch 160/300 \t lr=5.2e-04\t t=1s \tloss=0.1708\tval_loss=0.2403\tcorr=0.7608\n",
      "Epoch 170/300 \t lr=4.8e-04\t t=1s \tloss=0.1674\tval_loss=0.2411\tcorr=0.7586\n",
      "Epoch 180/300 \t lr=4.4e-04\t t=1s \tloss=0.1644\tval_loss=0.2400\tcorr=0.7601\n",
      "Epoch 190/300 \t lr=4.1e-04\t t=1s \tloss=0.1594\tval_loss=0.2408\tcorr=0.7592\n",
      "Epoch 200/300 \t lr=3.7e-04\t t=1s \tloss=0.1524\tval_loss=0.2430\tcorr=0.7580\n",
      "Epoch 210/300 \t lr=3.3e-04\t t=1s \tloss=0.1454\tval_loss=0.2463\tcorr=0.7551\n",
      "Epoch 220/300 \t lr=3.0e-04\t t=1s \tloss=0.1377\tval_loss=0.2508\tcorr=0.7495\n",
      "Epoch 230/300 \t lr=2.6e-04\t t=1s \tloss=0.1314\tval_loss=0.2508\tcorr=0.7499\n",
      "Epoch 240/300 \t lr=2.2e-04\t t=1s \tloss=0.1256\tval_loss=0.2518\tcorr=0.7486\n",
      "Epoch 250/300 \t lr=1.9e-04\t t=1s \tloss=0.1211\tval_loss=0.2525\tcorr=0.7473\n",
      "Epoch 260/300 \t lr=1.5e-04\t t=1s \tloss=0.1154\tval_loss=0.2536\tcorr=0.7470\n",
      "Epoch 270/300 \t lr=1.1e-04\t t=1s \tloss=0.1112\tval_loss=0.2540\tcorr=0.7466\n",
      "Epoch 280/300 \t lr=7.4e-05\t t=1s \tloss=0.1082\tval_loss=0.2545\tcorr=0.7458\n",
      "Epoch 290/300 \t lr=3.7e-05\t t=1s \tloss=0.1061\tval_loss=0.2547\tcorr=0.7461\n",
      "Epoch 300/300 \t lr=0.0e+00\t t=1s \tloss=0.1052\tval_loss=0.2547\tcorr=0.7459\n",
      "[0.25050505050505056, 0.8727272727272728, 0.886868686868687, 0.9664646464646466, 0.890909090909091, 0.5955555555555556, 0.9070707070707072, 0.7878787878787881] \n",
      "\n",
      "\n",
      "FOLD 4\n",
      "train size: 400, val size: 100\n",
      "Model parameters count: 109145608\n",
      "train batch num: 1\n",
      "val batch num: 1\n",
      "optim: Adam, lr: 0.001, warmup_steps: 30\n",
      "Epoch 10/300 \t lr=3.3e-04\t t=1s \tloss=0.9919\tval_loss=0.9895\tcorr=0.4640\n",
      "Epoch 20/300 \t lr=6.7e-04\t t=1s \tloss=0.7342\tval_loss=0.6694\tcorr=0.4532\n",
      "Epoch 30/300 \t lr=1.0e-03\t t=3s \tloss=0.4436\tval_loss=0.4386\tcorr=0.5718\n",
      "Epoch 40/300 \t lr=9.6e-04\t t=1s \tloss=0.3591\tval_loss=0.3585\tcorr=0.6429\n",
      "Epoch 50/300 \t lr=9.3e-04\t t=3s \tloss=0.3138\tval_loss=0.3040\tcorr=0.6967\n",
      "Epoch 60/300 \t lr=8.9e-04\t t=2s \tloss=0.2765\tval_loss=0.2674\tcorr=0.7345\n",
      "Epoch 70/300 \t lr=8.5e-04\t t=2s \tloss=0.2511\tval_loss=0.2529\tcorr=0.7490\n",
      "Epoch 80/300 \t lr=8.1e-04\t t=2s \tloss=0.2302\tval_loss=0.2396\tcorr=0.7639\n",
      "Epoch 90/300 \t lr=7.8e-04\t t=2s \tloss=0.2084\tval_loss=0.2330\tcorr=0.7692\n",
      "Epoch 100/300 \t lr=7.4e-04\t t=1s \tloss=0.2003\tval_loss=0.2275\tcorr=0.7734\n",
      "Epoch 110/300 \t lr=7.0e-04\t t=2s \tloss=0.1949\tval_loss=0.2240\tcorr=0.7774\n",
      "Epoch 120/300 \t lr=6.7e-04\t t=1s \tloss=0.1869\tval_loss=0.2182\tcorr=0.7829\n",
      "Epoch 130/300 \t lr=6.3e-04\t t=1s \tloss=0.1828\tval_loss=0.2165\tcorr=0.7859\n",
      "Epoch 140/300 \t lr=5.9e-04\t t=1s \tloss=0.1803\tval_loss=0.2154\tcorr=0.7853\n",
      "Epoch 150/300 \t lr=5.6e-04\t t=1s \tloss=0.1784\tval_loss=0.2144\tcorr=0.7860\n",
      "Epoch 160/300 \t lr=5.2e-04\t t=1s \tloss=0.1765\tval_loss=0.2134\tcorr=0.7882\n",
      "Epoch 170/300 \t lr=4.8e-04\t t=1s \tloss=0.1753\tval_loss=0.2141\tcorr=0.7864\n",
      "Epoch 180/300 \t lr=4.4e-04\t t=1s \tloss=0.1721\tval_loss=0.2146\tcorr=0.7853\n",
      "Epoch 190/300 \t lr=4.1e-04\t t=1s \tloss=0.1698\tval_loss=0.2154\tcorr=0.7850\n",
      "Epoch 200/300 \t lr=3.7e-04\t t=1s \tloss=0.1668\tval_loss=0.2147\tcorr=0.7860\n",
      "Epoch 210/300 \t lr=3.3e-04\t t=1s \tloss=0.1648\tval_loss=0.2128\tcorr=0.7881\n",
      "Epoch 220/300 \t lr=3.0e-04\t t=1s \tloss=0.1600\tval_loss=0.2136\tcorr=0.7870\n",
      "Epoch 230/300 \t lr=2.6e-04\t t=1s \tloss=0.1591\tval_loss=0.2133\tcorr=0.7876\n",
      "Epoch 240/300 \t lr=2.2e-04\t t=1s \tloss=0.1534\tval_loss=0.2141\tcorr=0.7863\n",
      "Epoch 250/300 \t lr=1.9e-04\t t=1s \tloss=0.1487\tval_loss=0.2170\tcorr=0.7837\n",
      "Epoch 260/300 \t lr=1.5e-04\t t=1s \tloss=0.1443\tval_loss=0.2194\tcorr=0.7806\n",
      "Epoch 270/300 \t lr=1.1e-04\t t=1s \tloss=0.1397\tval_loss=0.2207\tcorr=0.7796\n",
      "Epoch 280/300 \t lr=7.4e-05\t t=1s \tloss=0.1329\tval_loss=0.2232\tcorr=0.7770\n",
      "Epoch 290/300 \t lr=3.7e-05\t t=1s \tloss=0.1267\tval_loss=0.2244\tcorr=0.7764\n",
      "Epoch 300/300 \t lr=0.0e+00\t t=1s \tloss=0.1236\tval_loss=0.2248\tcorr=0.7757\n",
      "[0.30020202020202025, 0.85979797979798, 0.9127272727272728, 0.9672727272727274, 0.9131313131313133, 0.7094949494949496, 0.9353535353535355, 0.8044444444444446] \n",
      "\n",
      "\n",
      "0.78862 [0.27758, 0.87273, 0.90279, 0.96404, 0.89972, 0.67911, 0.9179, 0.79507]\n"
     ]
    }
   ],
   "source": [
    "loss_fct = CVPRLoss_tanh1()\n",
    "k=5\n",
    "scoref = []\n",
    "skf = KFold(n_splits=k, shuffle=False)\n",
    "for index, (train_index, test_index) in enumerate(skf.split(train_df)):   \n",
    "    print(f'FOLD {index}')\n",
    "    train0 = train_df.iloc[train_index]\n",
    "    val0 = train_df.iloc[test_index]   \n",
    "    train_dataset = MyDataset(train0, use_cols, target_cols)\n",
    "    val_dataset = MyDataset(val0, use_cols, target_cols)\n",
    "    print(f'train size: {len(train0)}, val size: {len(val0)}')\n",
    "\n",
    "    modelname = f'ohe_lstm2y_catall_tanh1_sig'\n",
    "    seed_everything(seed)\n",
    "    model = CVPRModel(input_dim=93,\n",
    "                    num_classes=8,\n",
    "                    bi=True,\n",
    "                    time_step=37\n",
    "                   ).to(device)\n",
    "\n",
    "    _ = train_sig(model, \n",
    "                train_dataset, \n",
    "                val_dataset, \n",
    "                verbose=10, \n",
    "                fold_=index,\n",
    "                modelname=modelname,\n",
    "                modelpath=modelpath,\n",
    "                input='input',\n",
    "                y='y',\n",
    "                debug=False\n",
    "                 )\n",
    "    scoref.append(_)\n",
    "scoreff = scoref\n",
    "print(np.round(np.array(scoreff).mean(1).mean(), 5), [round(x, 5) for x in np.array(scoreff).mean(0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#加载test\n",
    "with open('./data/CVPR_2022_NAS_Track2_test.json', 'r') as f:\n",
    "    test_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = get_df(test_data)\n",
    "get_step(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe_trans(test_df, emb_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_cuda(test_df, model):\n",
    "    #获得预测\n",
    "    test_dataset = MyDataset(test_df, use_cols, target_cols, 0)\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=1024*16,\n",
    "        shuffle=False,\n",
    "        drop_last=False,\n",
    "        pin_memory=True\n",
    "    )\n",
    "\n",
    "    preds = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for data in tqdm(test_loader):\n",
    "            pred = model(data['input'].to(device))\n",
    "            preds.append(pred.detach().cpu().numpy())\n",
    "    preds = np.concatenate(preds, 0)\n",
    "    print(preds.shape)\n",
    "\n",
    "    del test_dataset, test_loader, model;\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    return preds\n",
    "        \n",
    "def predict_sig(test_df, k=5, modelname=''):\n",
    "    for target in range(8):        \n",
    "        cols = []\n",
    "        for fold_ in range(k):\n",
    "            modelname1 = f'{modelname}_target{target}_{fold_}.pt'\n",
    "            print(f'Model {modelname1}')\n",
    "            model = CVPRModel(input_dim=93,\n",
    "                        num_classes=8,\n",
    "                        bi=True,\n",
    "                        time_step=37\n",
    "                       ).to(device)\n",
    "            model.load_state_dict(torch.load(modelpath+modelname1))\n",
    "\n",
    "            pred_ = pred_cuda(test_df, model)[:, target]\n",
    "            tmp_c = f'{target_cols[target]}_{fold_}'\n",
    "            test_df[tmp_c] = pred_\n",
    "            cols.append(tmp_c)\n",
    "            print(f'Done {tmp_c}')\n",
    "            \n",
    "        print(cols)\n",
    "        test_df[cols] = test_df[cols].rank()\n",
    "        test_df[target_cols[target]] = test_df[cols].mean(axis=1).rank()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model ohe_lstm2y_catall_tanh1_sig_target0_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:12<00:00,  1.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(99500, 8)\n",
      "Done cplfw_rank_0\n",
      "Model ohe_lstm2y_catall_tanh1_sig_target0_1.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:11<00:00,  1.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(99500, 8)\n",
      "Done cplfw_rank_1\n",
      "Model ohe_lstm2y_catall_tanh1_sig_target0_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:10<00:00,  1.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(99500, 8)\n",
      "Done cplfw_rank_2\n",
      "Model ohe_lstm2y_catall_tanh1_sig_target0_3.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:10<00:00,  1.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(99500, 8)\n",
      "Done cplfw_rank_3\n",
      "Model ohe_lstm2y_catall_tanh1_sig_target0_4.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:10<00:00,  1.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(99500, 8)\n",
      "Done cplfw_rank_4\n",
      "['cplfw_rank_0', 'cplfw_rank_1', 'cplfw_rank_2', 'cplfw_rank_3', 'cplfw_rank_4']\n",
      "Model ohe_lstm2y_catall_tanh1_sig_target1_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:10<00:00,  1.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(99500, 8)\n",
      "Done market1501_rank_0\n",
      "Model ohe_lstm2y_catall_tanh1_sig_target1_1.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:10<00:00,  1.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(99500, 8)\n",
      "Done market1501_rank_1\n",
      "Model ohe_lstm2y_catall_tanh1_sig_target1_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:10<00:00,  1.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(99500, 8)\n",
      "Done market1501_rank_2\n",
      "Model ohe_lstm2y_catall_tanh1_sig_target1_3.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:10<00:00,  1.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(99500, 8)\n",
      "Done market1501_rank_3\n",
      "Model ohe_lstm2y_catall_tanh1_sig_target1_4.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:10<00:00,  1.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(99500, 8)\n",
      "Done market1501_rank_4\n",
      "['market1501_rank_0', 'market1501_rank_1', 'market1501_rank_2', 'market1501_rank_3', 'market1501_rank_4']\n",
      "Model ohe_lstm2y_catall_tanh1_sig_target2_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:10<00:00,  1.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(99500, 8)\n",
      "Done dukemtmc_rank_0\n",
      "Model ohe_lstm2y_catall_tanh1_sig_target2_1.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:10<00:00,  1.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(99500, 8)\n",
      "Done dukemtmc_rank_1\n",
      "Model ohe_lstm2y_catall_tanh1_sig_target2_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:10<00:00,  1.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(99500, 8)\n",
      "Done dukemtmc_rank_2\n",
      "Model ohe_lstm2y_catall_tanh1_sig_target2_3.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:10<00:00,  1.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(99500, 8)\n",
      "Done dukemtmc_rank_3\n",
      "Model ohe_lstm2y_catall_tanh1_sig_target2_4.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:10<00:00,  1.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(99500, 8)\n",
      "Done dukemtmc_rank_4\n",
      "['dukemtmc_rank_0', 'dukemtmc_rank_1', 'dukemtmc_rank_2', 'dukemtmc_rank_3', 'dukemtmc_rank_4']\n",
      "Model ohe_lstm2y_catall_tanh1_sig_target3_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:10<00:00,  1.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(99500, 8)\n",
      "Done msmt17_rank_0\n",
      "Model ohe_lstm2y_catall_tanh1_sig_target3_1.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:10<00:00,  1.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(99500, 8)\n",
      "Done msmt17_rank_1\n",
      "Model ohe_lstm2y_catall_tanh1_sig_target3_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:10<00:00,  1.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(99500, 8)\n",
      "Done msmt17_rank_2\n",
      "Model ohe_lstm2y_catall_tanh1_sig_target3_3.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:10<00:00,  1.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(99500, 8)\n",
      "Done msmt17_rank_3\n",
      "Model ohe_lstm2y_catall_tanh1_sig_target3_4.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:10<00:00,  1.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(99500, 8)\n",
      "Done msmt17_rank_4\n",
      "['msmt17_rank_0', 'msmt17_rank_1', 'msmt17_rank_2', 'msmt17_rank_3', 'msmt17_rank_4']\n",
      "Model ohe_lstm2y_catall_tanh1_sig_target4_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:10<00:00,  1.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(99500, 8)\n",
      "Done veri_rank_0\n",
      "Model ohe_lstm2y_catall_tanh1_sig_target4_1.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:10<00:00,  1.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(99500, 8)\n",
      "Done veri_rank_1\n",
      "Model ohe_lstm2y_catall_tanh1_sig_target4_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:10<00:00,  1.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(99500, 8)\n",
      "Done veri_rank_2\n",
      "Model ohe_lstm2y_catall_tanh1_sig_target4_3.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:10<00:00,  1.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(99500, 8)\n",
      "Done veri_rank_3\n",
      "Model ohe_lstm2y_catall_tanh1_sig_target4_4.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:10<00:00,  1.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(99500, 8)\n",
      "Done veri_rank_4\n",
      "['veri_rank_0', 'veri_rank_1', 'veri_rank_2', 'veri_rank_3', 'veri_rank_4']\n",
      "Model ohe_lstm2y_catall_tanh1_sig_target5_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:10<00:00,  1.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(99500, 8)\n",
      "Done vehicleid_rank_0\n",
      "Model ohe_lstm2y_catall_tanh1_sig_target5_1.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:10<00:00,  1.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(99500, 8)\n",
      "Done vehicleid_rank_1\n",
      "Model ohe_lstm2y_catall_tanh1_sig_target5_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:10<00:00,  1.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(99500, 8)\n",
      "Done vehicleid_rank_2\n",
      "Model ohe_lstm2y_catall_tanh1_sig_target5_3.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:10<00:00,  1.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(99500, 8)\n",
      "Done vehicleid_rank_3\n",
      "Model ohe_lstm2y_catall_tanh1_sig_target5_4.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:10<00:00,  1.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(99500, 8)\n",
      "Done vehicleid_rank_4\n",
      "['vehicleid_rank_0', 'vehicleid_rank_1', 'vehicleid_rank_2', 'vehicleid_rank_3', 'vehicleid_rank_4']\n",
      "Model ohe_lstm2y_catall_tanh1_sig_target6_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:10<00:00,  1.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(99500, 8)\n",
      "Done veriwild_rank_0\n",
      "Model ohe_lstm2y_catall_tanh1_sig_target6_1.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:10<00:00,  1.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(99500, 8)\n",
      "Done veriwild_rank_1\n",
      "Model ohe_lstm2y_catall_tanh1_sig_target6_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:10<00:00,  1.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(99500, 8)\n",
      "Done veriwild_rank_2\n",
      "Model ohe_lstm2y_catall_tanh1_sig_target6_3.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:10<00:00,  1.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(99500, 8)\n",
      "Done veriwild_rank_3\n",
      "Model ohe_lstm2y_catall_tanh1_sig_target6_4.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:10<00:00,  1.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(99500, 8)\n",
      "Done veriwild_rank_4\n",
      "['veriwild_rank_0', 'veriwild_rank_1', 'veriwild_rank_2', 'veriwild_rank_3', 'veriwild_rank_4']\n",
      "Model ohe_lstm2y_catall_tanh1_sig_target7_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:10<00:00,  1.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(99500, 8)\n",
      "Done sop_rank_0\n",
      "Model ohe_lstm2y_catall_tanh1_sig_target7_1.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:10<00:00,  1.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(99500, 8)\n",
      "Done sop_rank_1\n",
      "Model ohe_lstm2y_catall_tanh1_sig_target7_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:10<00:00,  1.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(99500, 8)\n",
      "Done sop_rank_2\n",
      "Model ohe_lstm2y_catall_tanh1_sig_target7_3.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:10<00:00,  1.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(99500, 8)\n",
      "Done sop_rank_3\n",
      "Model ohe_lstm2y_catall_tanh1_sig_target7_4.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:10<00:00,  1.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(99500, 8)\n",
      "Done sop_rank_4\n",
      "['sop_rank_0', 'sop_rank_1', 'sop_rank_2', 'sop_rank_3', 'sop_rank_4']\n"
     ]
    }
   ],
   "source": [
    "predict_sig(test_df, k=5, modelname='ohe_lstm2y_catall_tanh1_sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df[target_cols] = test_df[target_cols].astype(int)-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cplfw_rank         92079\n",
       "market1501_rank    90972\n",
       "dukemtmc_rank      90933\n",
       "msmt17_rank        90683\n",
       "veri_rank          90622\n",
       "vehicleid_rank     90648\n",
       "veriwild_rank      90738\n",
       "sop_rank           90501\n",
       "dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df[target_cols].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to_sub\n",
    "def to_sub(test_df, test_data, name='CVPR_2022_lgb_score'):\n",
    "    for i in tqdm(test_df[['id']+target_cols].values):\n",
    "        id_ = i[0]\n",
    "        for k,v in enumerate(target_cols):\n",
    "            k += 1\n",
    "            test_data[id_][v] = i[k]\n",
    "            \n",
    "    with open(f'./sub/{name}.json', 'w') as f:\n",
    "        json.dump(test_data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 99500/99500 [00:00<00:00, 680886.84it/s]\n"
     ]
    }
   ],
   "source": [
    "to_sub(test_df, test_data, name='CVPR_2022_ohe_lstm2y_catall_tanh1_sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
