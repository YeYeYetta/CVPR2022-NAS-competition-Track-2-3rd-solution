{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "CVPRLoss:  使用1-pearson相关性作为loss;\n",
    "CVPRLoss1: 使用1-spearman rank相关性作为loss;\n",
    "CVPRLoss_tanh: 使用tanh改写的1-kendall rank相关性作为loss;\n",
    "CVPRLoss_softsign: 使用softsign改写的1-kendall rank相关性作为loss;\n",
    "CVPRLoss_erf: 使用erf改写的1-kendall rank相关性作为loss;\n",
    "CVPRLoss_sigmoid: 使用sigmoid改写的1-kendall rank相关性作为loss;\n",
    "CVPRLoss_tanh1: 使用tanh改写的1-kendall rank相关性作为loss，矩阵写法;\n",
    "CVPRLoss_pair： 使用huawei-noah定义的一种rank loss作为loss；\n",
    "'''\n",
    "class CVPRLoss(nn.Module):\n",
    "    # use pearson as loss\n",
    "    def __call__(self, pred, y):\n",
    "        pred_mean, y_mean = pred.mean(0), y.mean(0)\n",
    "        pred_std, y_std = pred.std(0), y.std(0)\n",
    "        corr = ((pred - pred_mean) * (y - y_mean)).sum(0) / ((((pred - pred_mean)**2).sum(0).sqrt()) * (((y - y_mean)**2).sum(0).sqrt())) \n",
    "        return 1-corr\n",
    "\n",
    "from fast_soft_sort.pytorch_ops import soft_rank\n",
    "class CVPRLoss1(nn.Module):\n",
    "    # use spearman as loss refer:https://forum.numer.ai/t/custom-loss-functions-for-xgboost-using-pytorch/960\n",
    "    def __call__(self, pred, y):\n",
    "        pred = pred.cpu()\n",
    "        y = y.cpu()\n",
    "        return 1-torch.cat(\n",
    "            [self.spearman(y[:,i].reshape(1,-1), \n",
    "                           pred[:,i].reshape(1,-1)).reshape(1,1) for i in range(y.shape[1])]\n",
    "        ).reshape(1, -1)\n",
    "        \n",
    "    def corrcoef(self, target, pred):\n",
    "        pred_n = pred - pred.mean()\n",
    "        target_n = target - target.mean()\n",
    "        pred_n = pred_n / pred_n.norm()\n",
    "        target_n = target_n / target_n.norm()\n",
    "        return (pred_n * target_n).sum()\n",
    "\n",
    "\n",
    "    def spearman(self,\n",
    "        target,\n",
    "        pred,\n",
    "        regularization=\"l2\",\n",
    "        regularization_strength=0.01,\n",
    "    ):\n",
    "        pred = soft_rank(\n",
    "            pred,\n",
    "            regularization=regularization,\n",
    "            regularization_strength=regularization_strength,\n",
    "        )\n",
    "        return self.corrcoef(target, pred / pred.shape[-1])\n",
    "    \n",
    "class CVPRLoss_tanh(nn.Module):\n",
    "    # use soft kendall as loss, loop\n",
    "    def __call__(self, pred, y):\n",
    "        return 1-torch.cat(\n",
    "            [self.get_score(y[:,i].reshape(1,-1), \n",
    "                           pred[:,i].reshape(1,-1)).reshape(1,-1) for i in range(y.shape[1])]\n",
    "        ).reshape(1, -1)\n",
    "    \n",
    "    def get_score(self, actuals, preds):\n",
    "        sa = actuals.argsort()[0]\n",
    "        tmp = preds.index_select(1, sa.int())[0]\n",
    "        score = torch.cat([((tmp[i:]-tmp[i-1])).tanh() for i in range(1, tmp.shape[0])]).sum()\n",
    "        score1 = score/sum(list(range(1,len(tmp))))\n",
    "        return score1\n",
    "    \n",
    "class CVPRLoss_tanh1(nn.Module):\n",
    "    # use soft kendall as loss, mat\n",
    "    def __call__(self, pred, y):\n",
    "        return 1-torch.cat(\n",
    "            [self.get_score(pred[:,i], y[:,i]).reshape(1) for i in range(y.shape[1])]\n",
    "        ).reshape(1,-1)\n",
    "    \n",
    "    def get_score(self, outputs, labels):\n",
    "        output1 = outputs.unsqueeze(1).repeat(1,outputs.shape[0])\n",
    "        label1 = labels.unsqueeze(1).repeat(1,labels.shape[0])\n",
    "\n",
    "        tmp = ((output1-output1.t())*torch.sign(label1-label1.t())).tanh()\n",
    "        eye_tmp = tmp*torch.eye(tmp.shape[0]).cuda()\n",
    "        new_tmp = tmp - eye_tmp\n",
    "        \n",
    "        loss = torch.sum(new_tmp)/(outputs.shape[0]*(outputs.shape[0]-1))\n",
    "\n",
    "        return loss\n",
    "    \n",
    "    \n",
    "class CVPRLoss_pair(nn.Module):\n",
    "    # use rank pair loss refer: https://github.com/huawei-noah/Efficient-Computing/blob/master/Efficient-NAS/ReNAS/renas.py\n",
    "    def __call__(self, pred, y):\n",
    "        return torch.cat(\n",
    "            [self.pair_loss(pred[:,i], y[:,i]).reshape(1) for i in range(y.shape[1])]\n",
    "        ).reshape(1,-1)\n",
    "    \n",
    "    def pair_loss(self, outputs, labels):\n",
    "        output = outputs.unsqueeze(1)\n",
    "        output1 = output.repeat(1,outputs.shape[0])\n",
    "        label = labels.unsqueeze(1)\n",
    "        label1 = label.repeat(1,labels.shape[0])\n",
    "\n",
    "        tmp = (output1-output1.t())*torch.sign(label1-label1.t())\n",
    "        tmp = torch.log(1+torch.exp(-tmp))\n",
    "        eye_tmp = tmp*torch.eye(len(tmp)).cuda()\n",
    "        new_tmp = tmp - eye_tmp\n",
    "        loss = torch.sum(new_tmp)/(outputs.shape[0]*(outputs.shape[0]-1))\n",
    "\n",
    "        return loss\n",
    "    \n",
    "class CVPRLoss_softsign(nn.Module):\n",
    "    #kendall softsign\n",
    "    def __call__(self, pred, y):\n",
    "        return 1-torch.cat(\n",
    "            [self.get_score(y[:,i].reshape(1,-1), \n",
    "                           pred[:,i].reshape(1,-1)).reshape(1,-1) for i in range(y.shape[1])]\n",
    "        ).reshape(1, -1)\n",
    "\n",
    "    \n",
    "    def get_score(self, actuals, preds):\n",
    "        sa = actuals.argsort()[0]\n",
    "        tmp = preds.index_select(1, sa.int())[0]\n",
    "        score = torch.cat([(tmp[i:]-tmp[i-1])/(0.01+torch.abs(tmp[i:]-tmp[i-1])) for i in range(1, tmp.shape[0])]).sum()\n",
    "        score1 = score/sum(list(range(1,len(tmp))))\n",
    "        return score1\n",
    "    \n",
    "class CVPRLoss_erf(nn.Module):\n",
    "    # kendall erf\n",
    "    def __call__(self, pred, y):\n",
    "        return 1-torch.cat(\n",
    "            [self.get_score(y[:,i].reshape(1,-1), \n",
    "                           pred[:,i].reshape(1,-1)).reshape(1,-1) for i in range(y.shape[1])]\n",
    "        ).reshape(1, -1)\n",
    "    \n",
    "    def get_score(self, actuals, preds):\n",
    "        sa = actuals.argsort()[0]\n",
    "        tmp = preds.index_select(1, sa.int())[0]\n",
    "        score = torch.cat([((tmp[i:]-tmp[i-1])).erf() for i in range(1, tmp.shape[0])]).sum()\n",
    "        score1 = score/sum(list(range(1,len(tmp))))\n",
    "        return score1\n",
    "    \n",
    "class CVPRLoss_sigmoid(nn.Module):\n",
    "    # kendall sigmoid\n",
    "    def __call__(self, pred, y):\n",
    "        return 1-torch.cat(\n",
    "            [self.get_score(y[:,i].reshape(1,-1), \n",
    "                           pred[:,i].reshape(1,-1)).reshape(1,-1) for i in range(y.shape[1])]\n",
    "        ).reshape(1, -1)\n",
    "    \n",
    "    def get_score(self, actuals, preds):\n",
    "        sa = actuals.argsort()[0]\n",
    "        tmp = preds.index_select(1, sa.int())[0]\n",
    "        score = torch.cat([2*(((tmp[i:]-tmp[i-1])).sigmoid() - 0.5) for i in range(1, tmp.shape[0])]).sum()\n",
    "        score1 = score/sum(list(range(1,len(tmp))))\n",
    "        return score1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
