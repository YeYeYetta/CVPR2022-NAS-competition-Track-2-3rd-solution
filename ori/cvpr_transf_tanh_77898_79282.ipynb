{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cplfw_rank': 9, 'market1501_rank': 361, 'dukemtmc_rank': 426, 'msmt17_rank': 433, 'veri_rank': 327, 'vehicleid_rank': 480, 'veriwild_rank': 425, 'sop_rank': 367, 'arch': 'l231131331121121331111211121331321321'}\n",
      "train_num: 500\n"
     ]
    }
   ],
   "source": [
    "# 读取训练数据, 训练集包含500个模型结构，以及这些结构在cplfw，market1501，dukemtmc等8个任务上的性能排序\n",
    "import json\n",
    "with open('./data/CVPR_2022_NAS_Track2_train.json', 'r') as f:\n",
    "    train_data = json.load(f)\n",
    "print(train_data['arch1'])\n",
    "print('train_num:',len(train_data.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_cols = ['cplfw_rank', 'market1501_rank', 'dukemtmc_rank', 'msmt17_rank', 'veri_rank', 'vehicleid_rank', 'veriwild_rank', 'sop_rank']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df(train_data):\n",
    "    ret = []\n",
    "    for k, v in train_data.items():\n",
    "        tmp = list(v['arch'])\n",
    "        tmp1 = []\n",
    "        for c in target_cols:\n",
    "            tmp1.append(v[c])\n",
    "        ret.append(tmp+tmp1+[k,v['arch']])\n",
    "    retf = pd.DataFrame(ret,columns=[f'col{_}' for _ in range(len(tmp))]+target_cols+['id','arch'])\n",
    "    retf['col0'] = retf['col0'].map({'l':1, 'j':2, 'k':3})\n",
    "    int_cols = [x for x in retf.columns if x not in ['id','arch']]\n",
    "    retf[int_cols] = retf[int_cols].astype(float)\n",
    "    return retf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = get_df(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in target_cols:\n",
    "    train_df[c+'_log1p'] = train_df[c].map(lambda x: np.log1p(x))\n",
    "    \n",
    "    bins = train_df[c].quantile(np.arange(0.0,1.05,0.05)).values\n",
    "    def quantile(x,bins=bins):\n",
    "        for i in bins[1:]:\n",
    "            if x<=i:\n",
    "                return i\n",
    "    train_df[c+'_quantile'] = train_df[c].map(quantile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['col0', 'col1', 'col2', 'col3', 'col4', 'col5', 'col6', 'col7', 'col8',\n",
       "       'col9', 'col10', 'col11', 'col12', 'col13', 'col14', 'col15', 'col16',\n",
       "       'col17', 'col18', 'col19', 'col20', 'col21', 'col22', 'col23', 'col24',\n",
       "       'col25', 'col26', 'col27', 'col28', 'col29', 'col30', 'col31', 'col32',\n",
       "       'col33', 'col34', 'col35', 'col36', 'cplfw_rank', 'market1501_rank',\n",
       "       'dukemtmc_rank', 'msmt17_rank', 'veri_rank', 'vehicleid_rank',\n",
       "       'veriwild_rank', 'sop_rank', 'id', 'arch', 'cplfw_rank_log1p',\n",
       "       'cplfw_rank_quantile', 'market1501_rank_log1p',\n",
       "       'market1501_rank_quantile', 'dukemtmc_rank_log1p',\n",
       "       'dukemtmc_rank_quantile', 'msmt17_rank_log1p', 'msmt17_rank_quantile',\n",
       "       'veri_rank_log1p', 'veri_rank_quantile', 'vehicleid_rank_log1p',\n",
       "       'vehicleid_rank_quantile', 'veriwild_rank_log1p',\n",
       "       'veriwild_rank_quantile', 'sop_rank_log1p', 'sop_rank_quantile'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_step(train_df):\n",
    "    res0 = []\n",
    "    res1 = []\n",
    "    res2 = []\n",
    "    res3 = []\n",
    "    res4 = []\n",
    "    map_={'l':1, 'j':2, 'k':3}\n",
    "    time_step=12\n",
    "    for item in train_df.arch:\n",
    "        ret = np.array(list(item[1:]),dtype=np.float32).reshape(-1,3)\n",
    "        res0.append(ret[:,0][:time_step])\n",
    "        res1.append(ret[:,1][:time_step])\n",
    "        res2.append(ret[:,2][:time_step])\n",
    "        res3.append(np.array([map_[item[0]]]*time_step))\n",
    "        res4.append([map_[item[0]]]+list(np.array(list(item[1:]),dtype=np.float32)))\n",
    "        \n",
    "    train_df['head'] = res0\n",
    "    train_df['mlp'] = res1\n",
    "    train_df['emb'] = res2\n",
    "    train_df['depth'] = res3\n",
    "    train_df['all_emb'] = res4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     retf['col0'] = retf['col0'].map({'j':10, 'k':11, 'l':12})\n",
    "#     retf[num_heads] = retf[num_heads].replace({1:12, 2:11, 3:10})\n",
    "#     retf[mlp_ratio] = retf[mlp_ratio].replace({1:4, 2:3.5, 3:3})\n",
    "#     retf[emb_dim] = retf[emb_dim].replace({1:768})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_step(train_df):\n",
    "    res0 = []\n",
    "    res1 = []\n",
    "    res2 = []\n",
    "    res3 = []\n",
    "    res4 = []\n",
    "    map_={'l':1, 'j':2, 'k':3}\n",
    "    time_step=12\n",
    "    head_ = set([1+_*3 for _ in range(12)])\n",
    "    mlp_ = set([2+_*3 for _ in range(12)])\n",
    "    emb_ = set([3+_*3 for _ in range(12)])\n",
    "    depth_ = set([0])\n",
    "    for item in train_df.arch:\n",
    "        ret = np.array(list(item[1:]),dtype=np.float32).reshape(-1,3)\n",
    "        res0.append([1 if x in head_ else 0 for x in range(37)])\n",
    "        res1.append([1 if x in mlp_ else 0 for x in range(37)])\n",
    "        res2.append([1 if x in emb_ else 0 for x in range(37)])\n",
    "        res3.append([1 if x in depth_ else 0 for x in range(37)])\n",
    "        res4.append([map_[item[0]]]+list(np.array(list(item[1:]),dtype=np.float32)))\n",
    "        \n",
    "    train_df['head'] = res0\n",
    "    train_df['mlp'] = res1\n",
    "    train_df['emb'] = res2\n",
    "    train_df['depth'] = res3\n",
    "    train_df['all_emb'] = res4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_step(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_step_0503(train_df):\n",
    "    res0 = []\n",
    "    res1 = []\n",
    "    res2 = []\n",
    "    res3 = []\n",
    "    res4 = []\n",
    "    map_={'l':.1, 'j':.2, 'k':.3}\n",
    "    time_step=12\n",
    "    head_ = set([1+_*3 for _ in range(12)])\n",
    "    mlp_ = set([2+_*3 for _ in range(12)])\n",
    "    emb_ = set([3+_*3 for _ in range(12)])\n",
    "    depth_ = set([0])\n",
    "    for item in train_df.arch:\n",
    "        ret = np.array(list(item[1:]),dtype=np.float32).reshape(-1,3)\n",
    "        res0.append([int(item[x])/10 if x in head_ else 0 for x in range(37)])\n",
    "        res1.append([int(item[x])/10 if x in mlp_ else 0 for x in range(37)])\n",
    "        res2.append([int(item[x])/10 if x in emb_ else 0 for x in range(37)])\n",
    "        res3.append([map_[item[0]]]+[0]*36)\n",
    "        res4.append([map_[item[0]]]+list(np.array(list(item[1:]),dtype=np.float32)/10))\n",
    "#         tr=[]\n",
    "#         for k,v in enumerate(item):\n",
    "#             if k>0 and k not in emb_:\n",
    "#                 tr.append(np.float32(v))\n",
    "                \n",
    "#         res4.append([map_[item[0]]]+tr)\n",
    "        \n",
    "    train_df['head'] = res0\n",
    "    train_df['mlp'] = res1\n",
    "    train_df['emb'] = res2\n",
    "    train_df['depth'] = res3\n",
    "    train_df['all_emb'] = res4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_step_0503(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_df.all_emb.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for c in ['head','mlp']:\n",
    "#     train_df[c+'_diff1'] = train_df[c].map(lambda x: x - np.concatenate([np.array([0]),x[:-1]]))\n",
    "#     train_df[c+'_diff2'] = train_df[c].map(lambda x: x - np.concatenate([np.array([0,0]),x[:-2]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义数据\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self,df,use_cols,target_cols,show=0):\n",
    "        self.df = df\n",
    "        self.show = show\n",
    "        self.use_cols = use_cols\n",
    "        self.target_cols = target_cols\n",
    "\n",
    "        self.prepare_data()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "    \n",
    "    def prepare_data(self):\n",
    "        self.y = self.df[self.target_cols].values\n",
    "        self.y_quantile = self.df[[_+'_quantile' for _ in self.target_cols]].values\n",
    "        self.y0 = self.df[[self.target_cols[0]]].values\n",
    "        self.y1 = self.df[[self.target_cols[1]]].values\n",
    "        self.y2 = self.df[[self.target_cols[2]]].values\n",
    "        self.y3 = self.df[[self.target_cols[3]]].values\n",
    "        self.y4 = self.df[[self.target_cols[4]]].values\n",
    "        self.y5 = self.df[[self.target_cols[5]]].values\n",
    "        self.y6 = self.df[[self.target_cols[6]]].values\n",
    "        self.y7 = self.df[[self.target_cols[7]]].values\n",
    "        \n",
    "#         self.inputs = self.df[use_cols].values\n",
    "        uc = ['all_emb']\n",
    "#         uc = ['head','mlp','emb']\n",
    "        tmp_dt = {}\n",
    "        for c in uc:\n",
    "            tmp_dt[c] = np.array(self.df[c].tolist())\n",
    "        self.inputs = np.concatenate([tmp_dt[c][:, None] for c in uc], 1).transpose(0, 2, 1)\n",
    "        \n",
    "#         uc= ['all_emb','depth','head','mlp','emb']\n",
    "#         tmp_dt = {}\n",
    "#         for c in uc:\n",
    "#             tmp_dt[c] = np.array(self.df[c].tolist())\n",
    "#         self.inputs1= np.concatenate([tmp_dt[c][:, None] for c in uc], 1).transpose(0, 2, 1)\n",
    "        \n",
    "        \n",
    "        if self.show==1:\n",
    "            print('inputs_shape',self.inputs.shape)\n",
    "#             print('inputs1_shape',self.inputs1.shape)\n",
    "            print('y_shape',self.y.shape)\n",
    "            print('y_quantile',self.y_quantile.shape)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        data = {\n",
    "            \"input\": torch.tensor(self.inputs[idx], dtype=torch.float),\n",
    "#             \"input1\": torch.tensor(self.inputs1[idx], dtype=torch.float),\n",
    "            \"y\": torch.tensor(self.y[idx], dtype=torch.float),\n",
    "            \"y_quantile\": torch.tensor(self.y_quantile[idx], dtype=torch.float),\n",
    "            \"y0\": torch.tensor(self.y0[idx], dtype=torch.float),\n",
    "            \"y1\": torch.tensor(self.y1[idx], dtype=torch.float),\n",
    "            \"y2\": torch.tensor(self.y2[idx], dtype=torch.float),\n",
    "            \"y3\": torch.tensor(self.y3[idx], dtype=torch.float),\n",
    "            \"y4\": torch.tensor(self.y4[idx], dtype=torch.float),\n",
    "            \"y5\": torch.tensor(self.y5[idx], dtype=torch.float),\n",
    "            \"y6\": torch.tensor(self.y6[idx], dtype=torch.float),\n",
    "            \"y7\": torch.tensor(self.y7[idx], dtype=torch.float),\n",
    "        }\n",
    "        \n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['col0', 'col1', 'col2', 'col3', 'col4', 'col5', 'col6', 'col7', 'col8',\n",
       "       'col9', 'col10', 'col11', 'col12', 'col13', 'col14', 'col15', 'col16',\n",
       "       'col17', 'col18', 'col19', 'col20', 'col21', 'col22', 'col23', 'col24',\n",
       "       'col25', 'col26', 'col27', 'col28', 'col29', 'col30', 'col31', 'col32',\n",
       "       'col33', 'col34', 'col35', 'col36', 'cplfw_rank', 'market1501_rank',\n",
       "       'dukemtmc_rank', 'msmt17_rank', 'veri_rank', 'vehicleid_rank',\n",
       "       'veriwild_rank', 'sop_rank', 'id', 'arch', 'cplfw_rank_log1p',\n",
       "       'cplfw_rank_quantile', 'market1501_rank_log1p',\n",
       "       'market1501_rank_quantile', 'dukemtmc_rank_log1p',\n",
       "       'dukemtmc_rank_quantile', 'msmt17_rank_log1p', 'msmt17_rank_quantile',\n",
       "       'veri_rank_log1p', 'veri_rank_quantile', 'vehicleid_rank_log1p',\n",
       "       'vehicleid_rank_quantile', 'veriwild_rank_log1p',\n",
       "       'veriwild_rank_quantile', 'sop_rank_log1p', 'sop_rank_quantile', 'head',\n",
       "       'mlp', 'emb', 'depth', 'all_emb'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train0 = train_df.sample(400, random_state=666).reset_index(drop=True)\n",
    "val0 = train_df[~train_df.id.isin(train0.id)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cols = [x for x in train_df.columns if 'col' in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(use_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs_shape (400, 37, 1)\n",
      "y_shape (400, 8)\n",
      "y_quantile (400, 8)\n",
      "inputs_shape (100, 37, 1)\n",
      "y_shape (100, 8)\n",
      "y_quantile (100, 8)\n"
     ]
    }
   ],
   "source": [
    "train_dataset = MyDataset(train0, use_cols, target_cols, 1)\n",
    "val_dataset = MyDataset(val0, use_cols, target_cols, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    \n",
    "    \n",
    "def count_parameters(model, all=False):\n",
    "    if all:\n",
    "        return sum(p.numel() for p in model.parameters())\n",
    "    else:\n",
    "        return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "\n",
    "def save_model_weights(model, modelpath, filename):\n",
    "    torch.save(model.state_dict(), modelpath+filename)\n",
    "    return f\"\\n -> Save weights to {modelpath+filename}\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metric(pred, y):\n",
    "    corr = []\n",
    "    if pred.shape[1]>2:\n",
    "        for i in range(8):\n",
    "            corr.append(scipy.stats.stats.kendalltau(pred[:, i], y[:, i])[0])\n",
    "    else:\n",
    "        corr.append(scipy.stats.stats.kendalltau(pred, y)[0])\n",
    "    return np.array(corr)\n",
    "\n",
    "class CVPRLoss(nn.Module):\n",
    "    def __call__(self, pred, y):\n",
    "        pred_mean, y_mean = pred.mean(0), y.mean(0)\n",
    "        pred_std, y_std = pred.std(0), y.std(0)\n",
    "        corr = ((pred - pred_mean) * (y - y_mean)).sum(0) / ((((pred - pred_mean)**2).sum(0).sqrt()) * (((y - y_mean)**2).sum(0).sqrt())) \n",
    "    \n",
    "#         cos = nn.CosineSimilarity(dim=0, eps=1e-08)\n",
    "#         corr1 = cos(pred, y)\n",
    "#         corr2 = (corr+corr1)/2\n",
    "        return 1-corr\n",
    "\n",
    "from fast_soft_sort.pytorch_ops import soft_rank\n",
    "class CVPRLoss1(nn.Module):\n",
    "    #spearman\n",
    "    def __call__(self, pred, y):\n",
    "        pred = pred.cpu()\n",
    "        y = y.cpu()\n",
    "        return 1-torch.cat(\n",
    "            [self.spearman(y[:,i].reshape(1,-1), \n",
    "                           pred[:,i].reshape(1,-1)).reshape(1,1) for i in range(y.shape[1])]\n",
    "        ).reshape(1, -1)\n",
    "        \n",
    "    def corrcoef(self, target, pred):\n",
    "        # np.corrcoef in torch from @mdo\n",
    "        # https://forum.numer.ai/t/custom-loss-functions-for-xgboost-using-pytorch/960\n",
    "        pred_n = pred - pred.mean()\n",
    "        target_n = target - target.mean()\n",
    "        pred_n = pred_n / pred_n.norm()\n",
    "        target_n = target_n / target_n.norm()\n",
    "        return (pred_n * target_n).sum()\n",
    "\n",
    "\n",
    "    def spearman(self,\n",
    "        target,\n",
    "        pred,\n",
    "        regularization=\"l2\",\n",
    "        regularization_strength=0.01,\n",
    "    ):\n",
    "        # fast_soft_sort uses 1-based indexing, divide by len to compute percentage of rank\n",
    "        pred = soft_rank(\n",
    "            pred,\n",
    "            regularization=regularization,\n",
    "            regularization_strength=regularization_strength,\n",
    "        )\n",
    "    #     print(pred)\n",
    "        return self.corrcoef(target, pred / pred.shape[-1])\n",
    "     \n",
    "class CVPRLoss2(nn.Module):\n",
    "    #kendall soft rank+tanh\n",
    "    def __call__(self, pred, y):\n",
    "        pred = pred.cpu()\n",
    "        y = y.cpu()\n",
    "        return 1-torch.cat(\n",
    "            [self.get_score(y[:,i].reshape(1,-1), \n",
    "                           pred[:,i].reshape(1,-1)).reshape(1,-1) for i in range(y.shape[1])]\n",
    "        ).reshape(1, -1)\n",
    "        \n",
    "    def get_score(self, actuals, preds):\n",
    "        sa = actuals.argsort()[0]\n",
    "\n",
    "        tmp = soft_rank(\n",
    "            preds.index_select(1, sa),\n",
    "            regularization='l2',\n",
    "            regularization_strength=0.01,\n",
    "        )[0]-1\n",
    "        \n",
    "        tmp = tmp.cuda()\n",
    "\n",
    "        score = torch.cat([((tmp[i:]-tmp[i-1]) * 10).tanh() for i in range(1, tmp.shape[0])]).sum()\n",
    "        score1 = score/sum(list(range(1,len(tmp))))\n",
    "        return score1\n",
    "    \n",
    "class CVPRLoss_softrank(nn.Module):\n",
    "    #kendall soft rank+tanh\n",
    "    def __call__(self, pred, y):\n",
    "        pred = pred.cpu()\n",
    "        y = y.cpu()\n",
    "        return 1-torch.cat(\n",
    "            [self.get_score(y[:,i].reshape(1,-1), \n",
    "                           pred[:,i].reshape(1,-1)).reshape(1,-1) for i in range(y.shape[1])]\n",
    "        ).reshape(1, -1)\n",
    "        \n",
    "    def get_score(self, actuals, preds):\n",
    "        sa = actuals.argsort()[0]\n",
    "\n",
    "        tmp = soft_rank(\n",
    "            preds.index_select(1, sa),\n",
    "            regularization='l2',\n",
    "            regularization_strength=0.01,\n",
    "        )[0]-1\n",
    "        \n",
    "        tmp = tmp.cuda()\n",
    "\n",
    "        score = torch.cat([((tmp[i:]-tmp[i-1]) * 10).tanh() for i in range(1, tmp.shape[0])]).sum()\n",
    "        score1 = score/sum(list(range(1,len(tmp))))\n",
    "        return score1\n",
    "    \n",
    "class CVPRLoss_softsign(nn.Module):\n",
    "    #kendall softsign\n",
    "    def __call__(self, pred, y):\n",
    "        return 1-torch.cat(\n",
    "            [self.get_score(y[:,i].reshape(1,-1), \n",
    "                           pred[:,i].reshape(1,-1)).reshape(1,-1) for i in range(y.shape[1])]\n",
    "        ).reshape(1, -1)\n",
    "\n",
    "    \n",
    "    def get_score(self, actuals, preds):\n",
    "        sa = actuals.argsort()[0]\n",
    "        tmp = preds.index_select(1, sa.int())[0]\n",
    "        score = torch.cat([((tmp[i:]-tmp[i-1]))/(0.00001+torch.abs(tmp[i:]-tmp[i-1])) for i in range(1, tmp.shape[0])]).sum()\n",
    "        score1 = score/sum(list(range(1,len(tmp))))\n",
    "        return score1\n",
    "    \n",
    "class CVPRLoss_tanh(nn.Module):\n",
    "    # kendall tanh\n",
    "    def __call__(self, pred, y):\n",
    "        pred = pred\n",
    "        y = y\n",
    "        return 1-torch.cat(\n",
    "            [self.get_score(y[:,i].reshape(1,-1), \n",
    "                           pred[:,i].reshape(1,-1)).reshape(1,-1) for i in range(y.shape[1])]\n",
    "        ).reshape(1, -1)\n",
    "    \n",
    "    def get_score(self, actuals, preds):\n",
    "        sa = actuals.argsort()[0]\n",
    "        tmp = preds.index_select(1, sa.int())[0]\n",
    "        score = torch.cat([((tmp[i:]-tmp[i-1])*1).tanh() for i in range(1, tmp.shape[0])]).sum()\n",
    "        score1 = score/sum(list(range(1,len(tmp))))\n",
    "        return score1\n",
    "    \n",
    "class CVPRLoss_softrankf(nn.Module):\n",
    "    #kendall soft rank+tanh\n",
    "    def __call__(self, pred, y):\n",
    "#         l0 = torch.abs(y-pred)\n",
    "\n",
    "        pred = pred.cpu()\n",
    "        y = y.cpu()\n",
    "        l1 = 1-torch.cat(\n",
    "            [self.get_score(y[:,i].reshape(1,-1), \n",
    "                           pred[:,i].reshape(1,-1)).reshape(1,-1) for i in range(y.shape[1])]).reshape(1, -1)\n",
    "        global mytest\n",
    "        mytest.append([(1-l1).cpu().detach().numpy(),compute_metric(pred.detach().numpy(), y.detach().numpy())])\n",
    "        return l1\n",
    "        \n",
    "        \n",
    "    def get_score(self, actuals, preds):\n",
    "        sa = actuals.argsort()[0]\n",
    "\n",
    "        tmp = soft_rank(\n",
    "            preds.index_select(1, sa),\n",
    "            regularization='l2',\n",
    "            regularization_strength=0.01,\n",
    "        )[0]-1\n",
    "        \n",
    "        tmp = tmp.cuda()\n",
    "        score = torch.cat([((tmp[i:]-tmp[i-1]) * 1).tanh() for i in range(1, tmp.shape[0])]).sum()\n",
    "        score1 = score/sum(list(range(1,len(tmp))))\n",
    "        global mytest1\n",
    "        mytest1.append(tmp.cpu().detach().numpy())\n",
    "        return score1\n",
    "    \n",
    "class CVPRLoss_softrankf1(nn.Module):\n",
    "    #kendall soft rank+tanh\n",
    "    def __call__(self, pred, y):\n",
    "#         l0 = torch.abs(y-pred)\n",
    "\n",
    "        pred = pred.cpu()\n",
    "        y = y.cpu()\n",
    "        l1 = 1-torch.cat(\n",
    "            [self.get_score(y[:,i].reshape(1,-1), \n",
    "                           pred[:,i].reshape(1,-1)).reshape(1,-1) for i in range(y.shape[1])]).reshape(1, -1)\n",
    "#         global mytest\n",
    "#         mytest.append([(1-l1).cpu().detach().numpy(),compute_metric(pred.detach().numpy(), y.detach().numpy())])\n",
    "        return l1\n",
    "        \n",
    "        \n",
    "    def get_score(self, actuals, preds):\n",
    "        sa = actuals.argsort()[0]\n",
    "\n",
    "        tmp = soft_rank(\n",
    "            preds.index_select(1, sa),\n",
    "            regularization='l2',\n",
    "            regularization_strength=0.01,\n",
    "        )[0]-1\n",
    "        \n",
    "        tmp = tmp.cuda()\n",
    "        score = torch.cat([((tmp[i:]-tmp[i-1]) * 1).tanh() for i in range(1, tmp.shape[0])]).sum()\n",
    "        score1 = score/sum(list(range(1,len(tmp))))\n",
    "#         global mytest1\n",
    "#         mytest1.append(tmp.cpu().detach().numpy())\n",
    "        return score1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, \n",
    "        train_dataset, \n",
    "        val_dataset, \n",
    "        verbose=20, \n",
    "        fold_=0,\n",
    "        modelname='MLP_base',\n",
    "        modelpath=r'./model'+'//',\n",
    "        input='input',\n",
    "        y='y',\n",
    "        early_stop_round=60,\n",
    "        debug=False):\n",
    "    \n",
    "    print(f'Model parameters count: {count_parameters(model)}')\n",
    "    #数据加载\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=False,\n",
    "        drop_last=True,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=BATCH_SIZE_TEST,\n",
    "        shuffle=False,\n",
    "        drop_last=False,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    print(f'train batch num: {len(train_loader)}')\n",
    "    print(f'val batch num: {len(val_loader)}')\n",
    "            \n",
    "    # Optimizer\n",
    "    optimizer = getattr(torch.optim, optim)(model.parameters(), lr=LR)\n",
    "    # Scheduler\n",
    "    num_warmup_steps = int(0.1 * EPOCHS * len(train_loader))\n",
    "    num_training_steps = int(EPOCHS * len(train_loader))\n",
    "    scheduler = get_linear_schedule_with_warmup(\n",
    "        optimizer, num_warmup_steps, num_training_steps\n",
    "    )\n",
    "    print(f'optim: {optim}, lr: {LR}, warmup_steps: {num_warmup_steps}')\n",
    "    \n",
    "    print(f'early stopping round: {early_stop_round}\\n')\n",
    "    #train\n",
    "    score_best=0\n",
    "    bst_epoch=0\n",
    "    first_epoch_eval=0\n",
    "    for epoch in range(EPOCHS):\n",
    "        if epoch > early_stop_round and (epoch - bst_epoch > early_stop_round):\n",
    "            print(f'early stopping.')\n",
    "            break\n",
    "        \n",
    "        model.train()\n",
    "        model.zero_grad()\n",
    "        start_time = time.time()\n",
    "\n",
    "        avg_loss = 0\n",
    "        for data in train_loader:\n",
    "            pred = model(data[input].to(device))\n",
    "#             print(pred.shape,data['y'].shape)\n",
    "\n",
    "            loss = loss_fct(\n",
    "                pred,\n",
    "#                 data[y+'_quantile'].to(device),\n",
    "                data[y].to(device),\n",
    "            ).mean()\n",
    "\n",
    "            loss.backward()\n",
    "            avg_loss += loss.item() / len(train_loader)\n",
    "\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "        #VAL\n",
    "        model.eval()\n",
    "        mae, avg_val_loss = 0, 0\n",
    "        preds = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for data in val_loader:\n",
    "                pred = model(data[input].to(device))\n",
    "\n",
    "                loss = loss_fct(\n",
    "                    pred,\n",
    "                    data[y].to(device)\n",
    "                ).mean()\n",
    "\n",
    "                avg_val_loss += loss.item() / len(val_loader)\n",
    "\n",
    "                preds.append(pred.detach().cpu().numpy())\n",
    "\n",
    "        preds = np.concatenate(preds, 0)\n",
    "        if y=='y':\n",
    "            mae = compute_metric(preds,val_dataset.df[target_cols].values).mean()\n",
    "        else:\n",
    "            mae = compute_metric(preds,val_dataset.df[[target_cols[int(y.replace('y',''))]]].values).mean()\n",
    "        \n",
    "        elapsed_time = time.time() - start_time\n",
    "        if (epoch + 1) % verbose == 0:\n",
    "            elapsed_time = elapsed_time * verbose\n",
    "            lr = scheduler.get_last_lr()[0]\n",
    "    #         lr=LR\n",
    "            print(\n",
    "                f\"Epoch {epoch + 1:02d}/{ EPOCHS:02d} \\t lr={lr:.1e}\\t t={elapsed_time:.0f}s \\t\"\n",
    "                f\"loss={avg_loss:.4f}\",\n",
    "                end=\"\\t\",\n",
    "            )\n",
    "\n",
    "            if (epoch + 1 >= first_epoch_eval) or (epoch + 1 == EPOCHS):\n",
    "                print(f\"val_loss={avg_val_loss:.4f}\\tcorr={mae:.4f}\")\n",
    "            else:\n",
    "                print(\"\")\n",
    "                \n",
    "        #保存最优模型\n",
    "        if mae>score_best:\n",
    "            bst = save_model_weights(model, modelpath, f'{modelname}_{fold_}.pt')\n",
    "            score_best = mae\n",
    "            bst_epoch = epoch\n",
    "            if y=='y':\n",
    "                bst_list = compute_metric(preds,val_dataset.df[target_cols].values)\n",
    "            else:\n",
    "                bst_list = compute_metric(preds,val_dataset.df[[target_cols[int(y.replace('y',''))]]].values).mean()\n",
    "            bst_preds = preds\n",
    "    print(f'best score {score_best}, best epoch: {bst_epoch}, {bst} ' )\n",
    "    print(bst_list,'\\n\\n')\n",
    "    del (val_loader, train_loader, loss, data, pred)\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    return bst_preds, bst_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CVPRModel(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim=3,\n",
    "        num_classes=8,\n",
    "        time_step=12,\n",
    "        bi=True\n",
    "    ):\n",
    "        super(CVPRModel,self).__init__()\n",
    "        \n",
    "        self.bi_num = 2 if bi else 1\n",
    "        \n",
    "        self.MLP = nn.Sequential(\n",
    "            nn.Linear(input_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 256),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        \n",
    "        self.LSTM = nn.Sequential(\n",
    "            nn.LSTM(256, 256, \n",
    "                    batch_first=True, \n",
    "                    bidirectional=bi, \n",
    "                    num_layers=1,\n",
    "                    dropout=0)\n",
    "                                 )\n",
    "        \n",
    "        self.LSTM1 = nn.LSTM(512, 256, \n",
    "                    batch_first=True, \n",
    "                    bidirectional=bi, \n",
    "                    num_layers=1,\n",
    "                    dropout=0\n",
    "                            )         \n",
    "        \n",
    "        \n",
    "#         self.transformer = nn.TransformerEncoderLayer(\n",
    "#             d_model=768, \n",
    "#             nhead=16, \n",
    "#             dropout=0.1,\n",
    "#             dim_feedforward=768*4\n",
    "#         )\n",
    "        \n",
    "        self.Logits = nn.Sequential(\n",
    "            nn.Flatten(start_dim=1),\n",
    "            nn.Linear(512*time_step, 2048),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(2048, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x1 = self.MLP(x)\n",
    "        x2,(h0, c0) = self.LSTM(x1)\n",
    "        x3,(h1, c1) = self.LSTM1(x2, (h0, c0))\n",
    "        \n",
    "        pred = self.Logits(x3)\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CVPRModel(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim=3,\n",
    "        num_classes=8,\n",
    "        time_step=12,\n",
    "        bi=True\n",
    "    ):\n",
    "        super(CVPRModel,self).__init__()\n",
    "        \n",
    "        self.bi_num = 2 if bi else 1\n",
    "        \n",
    "        self.MLP = nn.Sequential(\n",
    "            nn.Linear(input_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 256),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.LSTM = nn.Sequential(\n",
    "            nn.LSTM(256, 256, \n",
    "                    batch_first=True, \n",
    "                    bidirectional=bi, \n",
    "                    num_layers=1,\n",
    "                    dropout=0)\n",
    "                                 )\n",
    "        \n",
    "        self.LSTM1 = nn.LSTM(512, 256, \n",
    "                    batch_first=True, \n",
    "                    bidirectional=bi, \n",
    "                    num_layers=1,\n",
    "                    dropout=0\n",
    "                            ) \n",
    "        \n",
    "        self.encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=256, \n",
    "            nhead=2, \n",
    "            dropout=0,\n",
    "            dim_feedforward=256*4\n",
    "        )\n",
    "        self.encoder = nn.TransformerEncoder(\n",
    "            encoder_layer=self.encoder_layer, \n",
    "            num_layers=1\n",
    "        )\n",
    "        \n",
    "        \n",
    "        self.decoder_layer = nn.TransformerDecoderLayer(\n",
    "            d_model=256, \n",
    "            nhead=2,\n",
    "            dropout=0,\n",
    "            dim_feedforward=256*4\n",
    "        )      \n",
    "        self.decoder = nn.TransformerDecoder(\n",
    "            decoder_layer=self.decoder_layer, \n",
    "            num_layers=1\n",
    "        )\n",
    "        \n",
    "        \n",
    "        self.Logits = nn.Sequential(\n",
    "            nn.Flatten(start_dim=1),\n",
    "            nn.Linear(768*time_step, 2048),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(2048, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x1 = self.MLP(x)\n",
    "        \n",
    "        x2,(h0, c0) = self.LSTM(x1)\n",
    "        x3,(h1, c1) = self.LSTM1(x2, (h0, c0))\n",
    "        \n",
    "        enc = self.encoder(x1)\n",
    "        dec = self.decoder(x1, enc)\n",
    "        \n",
    "        c = torch.cat([x3, dec],-1)\n",
    "        \n",
    "        pred = self.Logits(c)\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CVPRModel(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim=3,\n",
    "        num_classes=8,\n",
    "        time_step=12,\n",
    "        bi=True\n",
    "    ):\n",
    "        super(CVPRModel,self).__init__()\n",
    "        \n",
    "        self.bi_num = 2 if bi else 1\n",
    "        \n",
    "        self.MLP = nn.Sequential(\n",
    "            nn.Linear(input_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 256),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=256, \n",
    "            nhead=2, \n",
    "            dropout=0,\n",
    "            dim_feedforward=256*4\n",
    "        )\n",
    "        self.encoder = nn.TransformerEncoder(\n",
    "            encoder_layer=self.encoder_layer, \n",
    "            num_layers=1\n",
    "        )\n",
    "        \n",
    "        \n",
    "        self.decoder_layer = nn.TransformerDecoderLayer(\n",
    "            d_model=256, \n",
    "            nhead=2,\n",
    "            dropout=0,\n",
    "            dim_feedforward=256*4\n",
    "        )      \n",
    "        self.decoder = nn.TransformerDecoder(\n",
    "            decoder_layer=self.decoder_layer, \n",
    "            num_layers=1\n",
    "        )\n",
    "        \n",
    "        \n",
    "        self.Logits = nn.Sequential(\n",
    "            nn.Flatten(start_dim=1),\n",
    "            nn.Linear(256*time_step, 2048),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(2048, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x1 = self.MLP(x)\n",
    "        enc = self.encoder(x1)\n",
    "        dec = self.decoder(x1, enc)\n",
    "        \n",
    "        pred = self.Logits(dec)\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#参数设置\n",
    "seed = 666\n",
    "BATCH_SIZE = 384\n",
    "BATCH_SIZE_TEST = 128\n",
    "EPOCHS = 300\n",
    "LR = 0.0001\n",
    "optim = \"Adam\"\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "modelpath = r'./model'+'//'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 8])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.rand(128,37,1).to(device)\n",
    "net = CVPRModel(input_dim=1,\n",
    "                num_classes=len(target_cols),\n",
    "                bi=True,\n",
    "                time_step=37\n",
    "               ).to(device)\n",
    "b = net(a)\n",
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 8])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.flatten(1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "del a,b,net;\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "mytest = []\n",
    "mytest1 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model parameters count: 25548808\n",
      "train batch num: 1\n",
      "val batch num: 1\n",
      "optim: Adam, lr: 0.0001, warmup_steps: 30\n",
      "early stopping round: 60\n",
      "\n",
      "Epoch 20/300 \t lr=6.7e-05\t t=9s \tloss=0.8340\tval_loss=0.8276\tcorr=0.3698\n",
      "Epoch 40/300 \t lr=9.6e-05\t t=10s \tloss=0.2789\tval_loss=0.3084\tcorr=0.7066\n",
      "Epoch 60/300 \t lr=8.9e-05\t t=10s \tloss=0.1878\tval_loss=0.2339\tcorr=0.7753\n",
      "Epoch 80/300 \t lr=8.1e-05\t t=9s \tloss=0.1370\tval_loss=0.2355\tcorr=0.7735\n",
      "Epoch 100/300 \t lr=7.4e-05\t t=9s \tloss=0.0905\tval_loss=0.2319\tcorr=0.7734\n",
      "Epoch 120/300 \t lr=6.7e-05\t t=9s \tloss=0.0630\tval_loss=0.2309\tcorr=0.7754\n",
      "early stopping.\n",
      "best score 0.7839898989898991, best epoch: 68, \n",
      " -> Save weights to ./model//LSTM1_step37_base1_test__t.pt\n",
      " \n",
      "[0.30868687 0.86868687 0.88848485 0.95111111 0.87393939 0.68080808\n",
      " 0.89737374 0.80282828] \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loss_fct = CVPRLoss_softrankf1()\n",
    "loss_fct = CVPRLoss_tanh()\n",
    "index = '_t'\n",
    "seed_everything(seed)\n",
    "modelname = 'LSTM1_step37_base1_test'\n",
    "\n",
    "model = CVPRModel(input_dim=1,\n",
    "                num_classes=8,\n",
    "                bi=True,\n",
    "                time_step=37\n",
    "               ).to(device)\n",
    "\n",
    "preds,_ = train(model, \n",
    "            train_dataset, \n",
    "            val_dataset, \n",
    "            verbose=20, \n",
    "            fold_=index,\n",
    "            modelname=modelname,\n",
    "            modelpath=modelpath,\n",
    "            input='input',\n",
    "            y='y',\n",
    "            debug=False\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "404"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "retf = []\n",
    "for i in mytest:\n",
    "    tmp0,tmp1 = i\n",
    "    tr=list(tmp0[0])+list(tmp1)\n",
    "    retf.append(tr)\n",
    "retf = pd.DataFrame(retf,columns=target_cols+[x+'_loss' for x in target_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cplfw_rank 1.147863385396876\n",
      "market1501_rank 1.6789394379490759\n",
      "dukemtmc_rank 1.963100413137639\n",
      "msmt17_rank 2.1124751344489137\n",
      "veri_rank 1.5402529562518859\n",
      "vehicleid_rank 1.424956932201814\n",
      "veriwild_rank 2.2069543952296256\n",
      "sop_rank 1.6854778987706704\n"
     ]
    }
   ],
   "source": [
    "for c in target_cols:\n",
    "    print(c, np.abs(retf[c]-retf[c+'_loss']).mean()*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cplfw_rank 1.147863385396876\n",
      "market1501_rank 1.6789394379490759\n",
      "dukemtmc_rank 1.963100413137639\n",
      "msmt17_rank 2.1124751344489137\n",
      "veri_rank 1.5402529562518859\n",
      "vehicleid_rank 1.424956932201814\n",
      "veriwild_rank 2.2069543952296256\n",
      "sop_rank 1.6854778987706704\n"
     ]
    }
   ],
   "source": [
    "for c in target_cols:\n",
    "    print(c, np.abs(retf[c]-retf[c+'_loss']).mean()*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  0.7891414141414143,\n",
    "#  array([0.33454545, 0.87070707, 0.88929293, 0.95232323, 0.88565657,\n",
    "#         0.67111111, 0.90868687, 0.80080808]))\n",
    "# 0.788939 [0.33737374 0.86828283 0.88969697 0.95838384 0.87838384 0.66787879 0.91555556 0.7959596 ] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 512 多头4，4 0.7927 [0.35515152 0.87232323 0.89050505 0.96484848 0.87676768 0.66343434  0.9159596  0.80282828] \n",
    "# 多头1，1 [0.34222222 0.87555556 0.89575758 0.96242424 0.8759596  0.66383838 0.91111111 0.80646465] \n",
    "# 多头2,2 0.7964646464646465,[0.37737374 0.87434343 0.89333333 0.9640404  0.87434343 0.66545455 0.91717172 0.80565657]\n",
    "# 多头4,4 [0.34424242 0.87717172 0.89333333 0.96606061 0.88363636 0.65656566 0.90989899 0.80363636] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [0.36686869 0.87717172 0.89212121 0.95636364 0.8840404  0.66141414\n",
    "#  0.91151515 0.80525253] \n",
    "# [0.34505051 0.87515152 0.89616162 0.96282828 0.88686869 0.66424242\n",
    "#  0.91474747 0.79191919] \n",
    "# [0.35393939 0.87151515 0.89171717 0.96121212 0.8840404  0.66343434\n",
    "#  0.91191919 0.8040404 ] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2层自带lstm 0.7911616161616162 \n",
    "# 1层的输出作为2层的h和c 0.7920707070707071\n",
    "# 2层手写，不初始化 0.7911616161616162 \n",
    "# 3层手写，输出作为输入 0.7911111111111113 \n",
    "# 2自带*2自带，输出作为输入 0.7875757575757577 \n",
    "# 1层输出作为2层输入，最后2层输出cat 0.7894444444444446\n",
    "# 1层输出作为2层输入，最后2层输出相乘 0.7885858585858587\n",
    "# 1层的输出作为2层的h和c,加一层gru cat 0.7894949494949497 \n",
    "# 1层的输出作为2层的h和c,加一层gru*1层输出 cat 0.7886868686868689\n",
    "# 1层的输出作为2层的h和c,加2层gru cat 0.7913131313131314 \n",
    "# 1层的输出作为2层的h和c,加2层gru*1层输出 cat2层输出 0.7915151515151516 \n",
    "# 1层的输出作为2层的h和c，2层的输出transformer然后乘以2层的输出，0.7899494949494951\n",
    "# 1层的输出作为2层的h和c,Tanh 0.7893939393939395 \n",
    "# 1层的输出作为2层的h和c,relu 0.7862121212121214 \n",
    "# 1层的输出作为2层的h和c,fc出去，0.7872222222222224 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# index = '_t'\n",
    "# modelname = 'LSTM1_step37_base1_test'\n",
    "# scoref = []\n",
    "# for i in range(8):\n",
    "#     seed_everything(seed)\n",
    "#     model = CVPRModel(input_dim=1,\n",
    "#                     num_classes=1,\n",
    "#                     bi=True,\n",
    "#                     time_step=37\n",
    "#                    ).to(device)\n",
    "#     preds,_ = train(model, \n",
    "#                 train_dataset, \n",
    "#                 val_dataset, \n",
    "#                 verbose=20, \n",
    "#                 fold_=index,\n",
    "#                 modelname=modelname,\n",
    "#                 modelpath=modelpath,\n",
    "#                 input='input',\n",
    "#                 y=f'y{i}',\n",
    "#                 debug=False\n",
    "#                  )\n",
    "#     scoref.append(_)\n",
    "# np.mean(scoref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [0.33171717 0.86222222 0.88888889 0.94222222 0.8630303  0.66909091 0.9030303  0.79757576]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "train size: 400, val size: 100\n",
      "Model parameters count: 25548808\n",
      "train batch num: 1\n",
      "val batch num: 1\n",
      "optim: Adam, lr: 0.0001, warmup_steps: 30\n",
      "early stopping round: 60\n",
      "\n",
      "Epoch 100/300 \t lr=7.4e-05\t t=47s \tloss=0.0923\tval_loss=0.2270\tcorr=0.7798\n",
      "early stopping.\n",
      "best score 0.785858585858586, best epoch: 66, \n",
      " -> Save weights to ./model//transformer_encoder_decoder_hardtanh_0.pt\n",
      " \n",
      "[0.28       0.89737374 0.89292929 0.94909091 0.88040404 0.6820202\n",
      " 0.91959596 0.78545455] \n",
      "\n",
      "\n",
      "FOLD 1\n",
      "train size: 400, val size: 100\n",
      "Model parameters count: 25548808\n",
      "train batch num: 1\n",
      "val batch num: 1\n",
      "optim: Adam, lr: 0.0001, warmup_steps: 30\n",
      "early stopping round: 60\n",
      "\n",
      "Epoch 100/300 \t lr=7.4e-05\t t=53s \tloss=0.0923\tval_loss=0.2323\tcorr=0.7742\n",
      "early stopping.\n",
      "best score 0.7763131313131314, best epoch: 82, \n",
      " -> Save weights to ./model//transformer_encoder_decoder_hardtanh_1.pt\n",
      " \n",
      "[0.27717172 0.86868687 0.89979798 0.95393939 0.88646465 0.64080808\n",
      " 0.88808081 0.79555556] \n",
      "\n",
      "\n",
      "FOLD 2\n",
      "train size: 400, val size: 100\n",
      "Model parameters count: 25548808\n",
      "train batch num: 1\n",
      "val batch num: 1\n",
      "optim: Adam, lr: 0.0001, warmup_steps: 30\n",
      "early stopping round: 60\n",
      "\n",
      "Epoch 100/300 \t lr=7.4e-05\t t=46s \tloss=0.0962\tval_loss=0.2362\tcorr=0.7699\n",
      "early stopping.\n",
      "best score 0.7854040404040405, best epoch: 63, \n",
      " -> Save weights to ./model//transformer_encoder_decoder_hardtanh_2.pt\n",
      " \n",
      "[0.23515152 0.85333333 0.88848485 0.95676768 0.90747475 0.72121212\n",
      " 0.92161616 0.79919192] \n",
      "\n",
      "\n",
      "FOLD 3\n",
      "train size: 400, val size: 100\n",
      "Model parameters count: 25548808\n",
      "train batch num: 1\n",
      "val batch num: 1\n",
      "optim: Adam, lr: 0.0001, warmup_steps: 30\n",
      "early stopping round: 60\n",
      "\n",
      "Epoch 100/300 \t lr=7.4e-05\t t=49s \tloss=0.0883\tval_loss=0.2538\tcorr=0.7536\n",
      "early stopping.\n",
      "best score 0.7601515151515152, best epoch: 66, \n",
      " -> Save weights to ./model//transformer_encoder_decoder_hardtanh_3.pt\n",
      " \n",
      "[0.21979798 0.87111111 0.87757576 0.94828283 0.87838384 0.59555556\n",
      " 0.90343434 0.78707071] \n",
      "\n",
      "\n",
      "FOLD 4\n",
      "train size: 400, val size: 100\n",
      "Model parameters count: 25548808\n",
      "train batch num: 1\n",
      "val batch num: 1\n",
      "optim: Adam, lr: 0.0001, warmup_steps: 30\n",
      "early stopping round: 60\n",
      "\n",
      "Epoch 100/300 \t lr=7.4e-05\t t=50s \tloss=0.0887\tval_loss=0.2283\tcorr=0.7786\n",
      "early stopping.\n",
      "best score 0.7871717171717174, best epoch: 62, \n",
      " -> Save weights to ./model//transformer_encoder_decoder_hardtanh_4.pt\n",
      " \n",
      "[0.26383838 0.84323232 0.90909091 0.95191919 0.90909091 0.69656566\n",
      " 0.93050505 0.79313131] \n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.77898,\n",
       " [0.25519, 0.86675, 0.89358, 0.952, 0.89236, 0.66723, 0.91265, 0.79208])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# K折训练，同时\n",
    "# loss_fct = CVPRLoss_softrankf()\n",
    "loss_fct = CVPRLoss_tanh()\n",
    "k=5\n",
    "scoref = []\n",
    "skf = KFold(n_splits=k, shuffle=False)\n",
    "for index, (train_index, test_index) in enumerate(skf.split(train_df)):   \n",
    "    print(f'FOLD {index}')\n",
    "    train0 = train_df.iloc[train_index]\n",
    "    val0 = train_df.iloc[test_index]   \n",
    "    train_dataset = MyDataset(train0, use_cols, target_cols)\n",
    "    val_dataset = MyDataset(val0, use_cols, target_cols)\n",
    "    print(f'train size: {len(train0)}, val size: {len(val0)}')\n",
    "\n",
    "    modelname = f'transformer_encoder_decoder_hardtanh'\n",
    "    seed_everything(seed)\n",
    "    model = CVPRModel(input_dim=1,\n",
    "                    num_classes=8,\n",
    "                    bi=True,\n",
    "                    time_step=37\n",
    "                   ).to(device)\n",
    "    preds,_ = train(model, \n",
    "                train_dataset, \n",
    "                val_dataset, \n",
    "                verbose=100, \n",
    "                fold_=index,\n",
    "                modelname=modelname,\n",
    "                modelpath=modelpath,\n",
    "                input='input',\n",
    "                y='y',\n",
    "                debug=False\n",
    "                 )\n",
    "    scoref.append(_)\n",
    "scoreff = scoref\n",
    "np.round(np.array(scoreff).mean(1).mean(), 5), [round(x, 5) for x in np.array(scoreff).mean(0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.77939,\n",
       " [0.25301, 0.86158, 0.89915, 0.96024, 0.89277, 0.66764, 0.91451, 0.78626])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.77939,[0.25301, 0.86158, 0.89915, 0.96024, 0.89277, 0.66764, 0.91451, 0.78626]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.77898,\n",
       " [0.25519, 0.86675, 0.89358, 0.952, 0.89236, 0.66723, 0.91265, 0.79208])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(np.array(scoreff).mean(1).mean(), 5), [round(x, 5) for x in np.array(scoreff).mean(0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 多头384 (0.78, [0.2682, 0.86602, 0.89737, 0.95741, 0.88905, 0.66335, 0.91281, 0.78578])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# K折训练，目标分别\n",
    "# scoreff = []\n",
    "# for target in range(8):\n",
    "#     k=5\n",
    "#     scoref = []\n",
    "#     skf = KFold(n_splits=k, shuffle=False)\n",
    "#     for index, (train_index, test_index) in enumerate(skf.split(train_df)):   \n",
    "#         print(f'TARGET {target} FOLD {index}')\n",
    "#         train0 = train_df.iloc[train_index]\n",
    "#         val0 = train_df.iloc[test_index]   \n",
    "#         train_dataset = MyDataset(train0, use_cols, target_cols)\n",
    "#         val_dataset = MyDataset(val0, use_cols, target_cols)\n",
    "#         print(f'train size: {len(train0)}, val size: {len(val0)}')\n",
    "\n",
    "#         modelname = f'LSTM_2layer_step37_kendall_tanh_target{target}'\n",
    "#         seed_everything(seed)\n",
    "#         model = CVPRModel(input_dim=1,\n",
    "#                         num_classes=1,\n",
    "#                         bi=True,\n",
    "#                         time_step=37\n",
    "#                        ).to(device)\n",
    "#         preds,_ = train(model, \n",
    "#                     train_dataset, \n",
    "#                     val_dataset, \n",
    "#                     verbose=100, \n",
    "#                     fold_=index,\n",
    "#                     modelname=modelname,\n",
    "#                     modelpath=modelpath,\n",
    "#                     input='input',\n",
    "#                     y=f'y{target}',\n",
    "#                     debug=False\n",
    "#                      )\n",
    "#         scoref.append(_)\n",
    "#     scoreff.append(scoref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.77898, [0.78586, 0.77631, 0.7854, 0.76015, 0.78717])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(np.array(scoreff).mean(1).mean(),5),[round(x,5) for x in np.array(scoreff).mean(1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.78795,\n",
       " [0.26836, 0.87111, 0.90545, 0.96509, 0.89745, 0.67507, 0.91895, 0.8021])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(0.78795,\n",
    " [0.26836, 0.87111, 0.90545, 0.96509, 0.89745, 0.67507, 0.91895, 0.8021])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cplfw_rank': 0,\n",
       " 'market1501_rank': 0,\n",
       " 'dukemtmc_rank': 0,\n",
       " 'msmt17_rank': 0,\n",
       " 'veri_rank': 0,\n",
       " 'vehicleid_rank': 0,\n",
       " 'veriwild_rank': 0,\n",
       " 'sop_rank': 0,\n",
       " 'arch': 'j121221121221221311331321121221000000'}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#加载test\n",
    "with open('./data/CVPR_2022_NAS_Track2_test.json', 'r') as f:\n",
    "    test_data = json.load(f)\n",
    "test_data['arch99997']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = get_df(test_data)\n",
    "get_step(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df[[x+'_quantile' for x in target_cols]] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_cuda(test_df, model):\n",
    "    #获得预测\n",
    "    test_dataset = MyDataset(test_df, use_cols, target_cols, 0)\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=1024*2,\n",
    "        shuffle=False,\n",
    "        drop_last=False,\n",
    "        pin_memory=True\n",
    "    )\n",
    "\n",
    "    preds = []\n",
    "    with torch.no_grad():\n",
    "        for data in tqdm(test_loader):\n",
    "            pred = model(data['input'].to(device))\n",
    "            preds.append(pred.detach().cpu().numpy())\n",
    "    preds = np.concatenate(preds, 0)\n",
    "    print(preds.shape)\n",
    "    return preds\n",
    "        \n",
    "def predict_sig(test_df, k=5):\n",
    "    for target in range(8):\n",
    "        \n",
    "        modelname = f'LSTM_2layer_step37_kendall_tanh_target{target}'\n",
    "        print(f'Model {modelname}')\n",
    "        \n",
    "        cols = []\n",
    "        for fold_ in range(k):\n",
    "            model = CVPRModel(input_dim=1,\n",
    "                        num_classes=1,\n",
    "                        bi=True,\n",
    "                        time_step=37\n",
    "                       ).to(device)\n",
    "            model.load_state_dict(torch.load(modelpath+f'{modelname}_{fold_}.pt'))\n",
    "\n",
    "            pred_ = pred_cuda(test_df, model)\n",
    "            tmp_c = f'{target_cols[target]}_{fold_}'\n",
    "            test_df[tmp_c] = pred_\n",
    "            cols.append(tmp_c)\n",
    "            print(f'Done {tmp_c}')\n",
    "        print(cols)\n",
    "        test_df[cols] = test_df[cols].rank()\n",
    "        test_df[target_cols[target]] = test_df[cols].mean(axis=1).rank()\n",
    "        \n",
    "def predict_all(test_df, k=5):\n",
    "        \n",
    "    modelname = f'transformer_encoder_decoder_hardtanh'\n",
    "    print(f'Model {modelname}')\n",
    "    \n",
    "    k_list = [0,1,2,3,4]\n",
    "\n",
    "    cols = []\n",
    "    for fold_ in range(k):\n",
    "        if fold_ not in k_list:\n",
    "            continue\n",
    "        model = CVPRModel(input_dim=1,\n",
    "                    num_classes=8,\n",
    "                    bi=True,\n",
    "                    time_step=37\n",
    "                   ).to(device)\n",
    "        model.load_state_dict(torch.load(modelpath+f'{modelname}_{fold_}.pt'))\n",
    "\n",
    "        pred_ = pred_cuda(test_df, model)\n",
    "        tmp_c = [f'{target}_{fold_}' for target in target_cols]\n",
    "        test_df[tmp_c] = pred_\n",
    "        cols += tmp_c\n",
    "    #get rank\n",
    "    print(cols)\n",
    "    test_df[cols] = test_df[cols].rank()\n",
    "    for c in target_cols:\n",
    "        test_df[c] = test_df[[f'{c}_{fold_}' for fold_ in k_list]].mean(axis=1)\n",
    "        test_df[c] = test_df[c].rank()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 'transformer_encoder_decoder_hardtanh')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k, modelname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM_2layer_step37_kendall_8all_softrankloss\n",
    "# LSTM_2layer_step37_kendall_8all_softsign\n",
    "# LSTM_2layer_step37_kendall_8all_tanh\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model transformer_encoder_decoder_hardtanh\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\45928\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "908478e2b088482b89631d01e89718aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/49 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(99500, 8)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63328eb80a6b440d83a6b38869d14656",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/49 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(99500, 8)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36332b8589d845ddbcb1456c7c951295",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/49 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(99500, 8)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0f61ebf888b44849a3798f5ac34da0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/49 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(99500, 8)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f965d65bffc04b3db049c05c2a3740cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/49 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(99500, 8)\n",
      "['cplfw_rank_0', 'market1501_rank_0', 'dukemtmc_rank_0', 'msmt17_rank_0', 'veri_rank_0', 'vehicleid_rank_0', 'veriwild_rank_0', 'sop_rank_0', 'cplfw_rank_1', 'market1501_rank_1', 'dukemtmc_rank_1', 'msmt17_rank_1', 'veri_rank_1', 'vehicleid_rank_1', 'veriwild_rank_1', 'sop_rank_1', 'cplfw_rank_2', 'market1501_rank_2', 'dukemtmc_rank_2', 'msmt17_rank_2', 'veri_rank_2', 'vehicleid_rank_2', 'veriwild_rank_2', 'sop_rank_2', 'cplfw_rank_3', 'market1501_rank_3', 'dukemtmc_rank_3', 'msmt17_rank_3', 'veri_rank_3', 'vehicleid_rank_3', 'veriwild_rank_3', 'sop_rank_3', 'cplfw_rank_4', 'market1501_rank_4', 'dukemtmc_rank_4', 'msmt17_rank_4', 'veri_rank_4', 'vehicleid_rank_4', 'veriwild_rank_4', 'sop_rank_4']\n"
     ]
    }
   ],
   "source": [
    "model_dt = predict_all(test_df, k=k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cplfw_rank</th>\n",
       "      <th>market1501_rank</th>\n",
       "      <th>dukemtmc_rank</th>\n",
       "      <th>msmt17_rank</th>\n",
       "      <th>veri_rank</th>\n",
       "      <th>vehicleid_rank</th>\n",
       "      <th>veriwild_rank</th>\n",
       "      <th>sop_rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>99500.000000</td>\n",
       "      <td>99500.000000</td>\n",
       "      <td>99500.000000</td>\n",
       "      <td>99500.000000</td>\n",
       "      <td>99500.000000</td>\n",
       "      <td>99500.000000</td>\n",
       "      <td>99500.000000</td>\n",
       "      <td>99500.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>49750.500000</td>\n",
       "      <td>49750.500000</td>\n",
       "      <td>49750.500000</td>\n",
       "      <td>49750.500000</td>\n",
       "      <td>49750.500000</td>\n",
       "      <td>49750.500000</td>\n",
       "      <td>49750.500000</td>\n",
       "      <td>49750.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>28723.320228</td>\n",
       "      <td>28723.320228</td>\n",
       "      <td>28723.320228</td>\n",
       "      <td>28723.320228</td>\n",
       "      <td>28723.320228</td>\n",
       "      <td>28723.320228</td>\n",
       "      <td>28723.320228</td>\n",
       "      <td>28723.320228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>24875.000000</td>\n",
       "      <td>24875.750000</td>\n",
       "      <td>24875.750000</td>\n",
       "      <td>24875.750000</td>\n",
       "      <td>24875.750000</td>\n",
       "      <td>24875.750000</td>\n",
       "      <td>24875.750000</td>\n",
       "      <td>24875.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>49750.500000</td>\n",
       "      <td>49750.750000</td>\n",
       "      <td>49750.500000</td>\n",
       "      <td>49750.500000</td>\n",
       "      <td>49750.500000</td>\n",
       "      <td>49750.500000</td>\n",
       "      <td>49750.500000</td>\n",
       "      <td>49750.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>74625.250000</td>\n",
       "      <td>74625.250000</td>\n",
       "      <td>74625.250000</td>\n",
       "      <td>74625.250000</td>\n",
       "      <td>74625.375000</td>\n",
       "      <td>74625.375000</td>\n",
       "      <td>74625.250000</td>\n",
       "      <td>74625.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>99500.000000</td>\n",
       "      <td>99500.000000</td>\n",
       "      <td>99500.000000</td>\n",
       "      <td>99500.000000</td>\n",
       "      <td>99500.000000</td>\n",
       "      <td>99500.000000</td>\n",
       "      <td>99500.000000</td>\n",
       "      <td>99500.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         cplfw_rank  market1501_rank  dukemtmc_rank   msmt17_rank  \\\n",
       "count  99500.000000     99500.000000   99500.000000  99500.000000   \n",
       "mean   49750.500000     49750.500000   49750.500000  49750.500000   \n",
       "std    28723.320228     28723.320228   28723.320228  28723.320228   \n",
       "min        1.000000         1.000000       1.000000      1.500000   \n",
       "25%    24875.000000     24875.750000   24875.750000  24875.750000   \n",
       "50%    49750.500000     49750.750000   49750.500000  49750.500000   \n",
       "75%    74625.250000     74625.250000   74625.250000  74625.250000   \n",
       "max    99500.000000     99500.000000   99500.000000  99500.000000   \n",
       "\n",
       "          veri_rank  vehicleid_rank  veriwild_rank      sop_rank  \n",
       "count  99500.000000    99500.000000   99500.000000  99500.000000  \n",
       "mean   49750.500000    49750.500000   49750.500000  49750.500000  \n",
       "std    28723.320228    28723.320228   28723.320228  28723.320228  \n",
       "min        1.000000        1.000000       1.000000      1.000000  \n",
       "25%    24875.750000    24875.750000   24875.750000  24875.750000  \n",
       "50%    49750.500000    49750.500000   49750.500000  49750.500000  \n",
       "75%    74625.375000    74625.375000   74625.250000  74625.375000  \n",
       "max    99500.000000    99500.000000   99500.000000  99500.000000  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df[target_cols].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df[target_cols] = test_df[target_cols].astype(int)-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cplfw_rank</th>\n",
       "      <th>market1501_rank</th>\n",
       "      <th>dukemtmc_rank</th>\n",
       "      <th>msmt17_rank</th>\n",
       "      <th>veri_rank</th>\n",
       "      <th>vehicleid_rank</th>\n",
       "      <th>veriwild_rank</th>\n",
       "      <th>sop_rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>99500.000000</td>\n",
       "      <td>99500.000000</td>\n",
       "      <td>99500.000000</td>\n",
       "      <td>99500.000000</td>\n",
       "      <td>99500.000000</td>\n",
       "      <td>99500.000000</td>\n",
       "      <td>99500.000000</td>\n",
       "      <td>99500.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>49749.419427</td>\n",
       "      <td>49749.418402</td>\n",
       "      <td>49749.419116</td>\n",
       "      <td>49749.418804</td>\n",
       "      <td>49749.418382</td>\n",
       "      <td>49749.419226</td>\n",
       "      <td>49749.417889</td>\n",
       "      <td>49749.419749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>28723.319720</td>\n",
       "      <td>28723.320380</td>\n",
       "      <td>28723.318907</td>\n",
       "      <td>28723.321470</td>\n",
       "      <td>28723.320690</td>\n",
       "      <td>28723.320862</td>\n",
       "      <td>28723.320015</td>\n",
       "      <td>28723.320291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>24874.000000</td>\n",
       "      <td>24874.750000</td>\n",
       "      <td>24874.750000</td>\n",
       "      <td>24874.750000</td>\n",
       "      <td>24874.750000</td>\n",
       "      <td>24874.750000</td>\n",
       "      <td>24874.750000</td>\n",
       "      <td>24874.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>49749.500000</td>\n",
       "      <td>49749.500000</td>\n",
       "      <td>49749.500000</td>\n",
       "      <td>49749.500000</td>\n",
       "      <td>49749.500000</td>\n",
       "      <td>49749.500000</td>\n",
       "      <td>49749.500000</td>\n",
       "      <td>49749.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>74624.250000</td>\n",
       "      <td>74624.250000</td>\n",
       "      <td>74624.250000</td>\n",
       "      <td>74624.250000</td>\n",
       "      <td>74624.250000</td>\n",
       "      <td>74624.250000</td>\n",
       "      <td>74624.250000</td>\n",
       "      <td>74624.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>99499.000000</td>\n",
       "      <td>99499.000000</td>\n",
       "      <td>99499.000000</td>\n",
       "      <td>99499.000000</td>\n",
       "      <td>99499.000000</td>\n",
       "      <td>99499.000000</td>\n",
       "      <td>99499.000000</td>\n",
       "      <td>99499.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         cplfw_rank  market1501_rank  dukemtmc_rank   msmt17_rank  \\\n",
       "count  99500.000000     99500.000000   99500.000000  99500.000000   \n",
       "mean   49749.419427     49749.418402   49749.419116  49749.418804   \n",
       "std    28723.319720     28723.320380   28723.318907  28723.321470   \n",
       "min        0.000000         0.000000       0.000000      0.000000   \n",
       "25%    24874.000000     24874.750000   24874.750000  24874.750000   \n",
       "50%    49749.500000     49749.500000   49749.500000  49749.500000   \n",
       "75%    74624.250000     74624.250000   74624.250000  74624.250000   \n",
       "max    99499.000000     99499.000000   99499.000000  99499.000000   \n",
       "\n",
       "          veri_rank  vehicleid_rank  veriwild_rank      sop_rank  \n",
       "count  99500.000000    99500.000000   99500.000000  99500.000000  \n",
       "mean   49749.418382    49749.419226   49749.417889  49749.419749  \n",
       "std    28723.320690    28723.320862   28723.320015  28723.320291  \n",
       "min        0.000000        0.000000       0.000000      0.000000  \n",
       "25%    24874.750000    24874.750000   24874.750000  24874.750000  \n",
       "50%    49749.500000    49749.500000   49749.500000  49749.500000  \n",
       "75%    74624.250000    74624.250000   74624.250000  74624.250000  \n",
       "max    99499.000000    99499.000000   99499.000000  99499.000000  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df[target_cols].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'transformer_encoder_decoder_hardtanh'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelname = 'transformer_encoder_decoder_hardtanh'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\45928\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f44c3dd0f0534b1d8c95ef6b20b419c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/99500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#输出\n",
    "for i in tqdm(test_df[['id']+target_cols].values):\n",
    "    id_ = i[0]\n",
    "    for k,v in enumerate(target_cols):\n",
    "        k += 1\n",
    "        test_data[id_][v] = i[k]\n",
    "        \n",
    "with open(f'./sub/{modelname}_20220509.json', 'w') as f:\n",
    "    json.dump(test_data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'transformer_encoder_decoder_hardtanh'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CVPRModel(\n",
       "  (MLP): Sequential(\n",
       "    (0): Linear(in_features=1, out_features=128, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=128, out_features=256, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=256, out_features=256, bias=True)\n",
       "    (5): ReLU()\n",
       "  )\n",
       "  (encoder_layer): TransformerEncoderLayer(\n",
       "    (self_attn): MultiheadAttention(\n",
       "      (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "    )\n",
       "    (linear1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "    (dropout): Dropout(p=0, inplace=False)\n",
       "    (linear2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "    (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "    (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "    (dropout1): Dropout(p=0, inplace=False)\n",
       "    (dropout2): Dropout(p=0, inplace=False)\n",
       "  )\n",
       "  (encoder): TransformerEncoder(\n",
       "    (layers): ModuleList(\n",
       "      (0): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0, inplace=False)\n",
       "        (linear2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0, inplace=False)\n",
       "        (dropout2): Dropout(p=0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder_layer): TransformerDecoderLayer(\n",
       "    (self_attn): MultiheadAttention(\n",
       "      (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "    )\n",
       "    (multihead_attn): MultiheadAttention(\n",
       "      (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "    )\n",
       "    (linear1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "    (dropout): Dropout(p=0, inplace=False)\n",
       "    (linear2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "    (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "    (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "    (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "    (dropout1): Dropout(p=0, inplace=False)\n",
       "    (dropout2): Dropout(p=0, inplace=False)\n",
       "    (dropout3): Dropout(p=0, inplace=False)\n",
       "  )\n",
       "  (decoder): TransformerDecoder(\n",
       "    (layers): ModuleList(\n",
       "      (0): TransformerDecoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "        )\n",
       "        (multihead_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0, inplace=False)\n",
       "        (linear2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0, inplace=False)\n",
       "        (dropout2): Dropout(p=0, inplace=False)\n",
       "        (dropout3): Dropout(p=0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (Logits): Sequential(\n",
       "    (0): Flatten(start_dim=1, end_dim=-1)\n",
       "    (1): Linear(in_features=9472, out_features=2048, bias=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "    (4): ReLU()\n",
       "    (5): Linear(in_features=1024, out_features=256, bias=True)\n",
       "    (6): ReLU()\n",
       "    (7): Linear(in_features=256, out_features=8, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
